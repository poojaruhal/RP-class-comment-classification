fileName,className,classComment,commentStart,commentEnd,classCommentSymbolLength,classCommentLineLength
C:\Users\vaano\python_projects\pytorch\setup.py,build_ext,,,,,
C:\Users\vaano\python_projects\pytorch\setup.py,install,,,,,
C:\Users\vaano\python_projects\pytorch\setup.py,clean,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\generate_config_yml.py,File,"
Verbatim copy the contents of a file into config.yml
",21,22,52,1
C:\Users\vaano\python_projects\pytorch\.circleci\generate_config_yml.py,FunctionGen,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\generate_config_yml.py,Treegen,"
Insert the content of a YAML tree into config.yml
",37,38,49,1
C:\Users\vaano\python_projects\pytorch\.circleci\generate_config_yml.py,Listgen,"
Insert the content of a YAML list into config.yml
",48,49,49,1
C:\Users\vaano\python_projects\pytorch\.circleci\generate_config_yml.py,Header,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\binary_build_data.py,TopLevelNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\binary_build_data.py,OSConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\binary_build_data.py,PackageFormatConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\binary_build_data.py,LinuxGccConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\binary_build_data.py,ArchConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\binary_build_data.py,PyVersionConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\binary_build_data.py,LinkingVariantConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\binary_build_data.py,DependencyInclusionConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\binary_build_definitions.py,Conf,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\caffe2_build_data.py,TreeConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\caffe2_build_data.py,TopLevelNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\caffe2_build_data.py,DistroConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\caffe2_build_data.py,CompilerConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\caffe2_build_data.py,LanguageConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\caffe2_build_data.py,ImportantConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\caffe2_build_definitions.py,Conf,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,TreeConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,TopLevelNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,DistroConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,PyVerConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,ExperimentalFeatureConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,XlaConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,ParallelTBBConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,ParallelNativeConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,LibTorchConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,AndroidAbiConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,ImportantConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,XenialCompilerConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_data.py,XenialCompilerVersionConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_definitions.py,Conf,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\data\pytorch_build_definitions.py,HiddenConf,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\lib\conf_tree.py,Ver,"
Represents a product with a version number
",18,19,42,1
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\lib\conf_tree.py,ConfigNode,,,,,
C:\Users\vaano\python_projects\pytorch\.circleci\cimodel\lib\visualization.py,FakeGraph,,,,,
C:\Users\vaano\python_projects\pytorch\android\pytorch_android\generate_test_torchscripts.py,Test,,,,,
C:\Users\vaano\python_projects\pytorch\aten\src\ATen\code_template.py,CodeTemplate,"Python 2.7.5 has a bug where the leading (^[^\n\S]*)? does not work,
    workaround via appending another [^\n\S]? inside
 ",14,15,1,1
C:\Users\vaano\python_projects\pytorch\aten\src\ATen\common_with_cwrap.py,Function,,,,,
C:\Users\vaano\python_projects\pytorch\aten\src\ATen\common_with_cwrap.py,Argument,,,,,
C:\Users\vaano\python_projects\pytorch\aten\src\ATen\function_wrapper.py,NYIError,"
Indicates we don't support this declaration yet
",254,255,47,1
C:\Users\vaano\python_projects\pytorch\aten\src\ATen\function_wrapper.py,nested_dict,,,,,
C:\Users\vaano\python_projects\pytorch\aten\src\ATen\gen.py,FileManager,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\fastrnns\custom_lstms.py,LSTMCell,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\fastrnns\custom_lstms.py,LayerNorm,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\fastrnns\custom_lstms.py,LayerNormLSTMCell,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\fastrnns\custom_lstms.py,LSTMLayer,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\fastrnns\custom_lstms.py,ReverseLSTMLayer,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\fastrnns\custom_lstms.py,BidirLSTMLayer,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\fastrnns\custom_lstms.py,StackedLSTM,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\fastrnns\custom_lstms.py,StackedLSTM2,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\fastrnns\custom_lstms.py,StackedLSTMWithDropout,"Necessary for iterating through self.layers and dropout support
 ",306,306,40,1
C:\Users\vaano\python_projects\pytorch\benchmarks\fastrnns\runner.py,DisableCuDNN,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\fastrnns\runner.py,DummyContext,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\fastrnns\runner.py,AssertNoJIT,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\framework_overhead_benchmark\C2Module.py,C2SimpleNet,"
This module constructs a net with 'op_name' operator. The net consist
a series of such operator.
It intializes the workspace with input blob equal to the number of parameters
needed for the op.
Provides forward method to run the net niter times.
",14,19,245,5
C:\Users\vaano\python_projects\pytorch\benchmarks\framework_overhead_benchmark\pt_wrapper_module.py,WrapperModule,"
Wraps the instance of wrapped_type.
For graph_mode traces the instance of wrapped_type.
Randomaly initializes num_params tensors with single float element.
Args:
    wrapped_type:
        - Object type to be wrapped.
            Expects the wrapped_type to:
               - be constructed with pt_fn specified in module_config.
               - provide forward method that takes module_config.num_params args.
    module_config:
        - Specified pt_fn to construct wrapped_type with, whether graph_mode
          is enabled, and number of parameters wrapped_type's forward method
          takes.
    debug:
        - Whether debug mode is enabled.
    save:
        - In graph mode, whether graph is to be saved.
",5,22,717,17
C:\Users\vaano\python_projects\pytorch\benchmarks\framework_overhead_benchmark\SimpleAddModule.py,SimpleAddModule,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\benchmark_caffe2.py,Caffe2BenchmarkBase,"
This is a base class used to create Caffe2 operator benchmark
    
",21,22,61,1
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\benchmark_caffe2.py,Caffe2OperatorTestCase,"
This class includes all the information needed to benchmark an operator.
op_bench: it's a user-defined class (child of Caffe2BenchmarkBase)
which includes input and operator, .etc
test_config: a namedtuple includes test_name, input_shape, tag, run_backward.
When run_backward is false, the run_forward method will be executed, otherwise
run_backward method will be executed.
",103,109,374,6
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\benchmark_core.py,BenchmarkRunner,"
BenchmarkRunner is responsible for benchmarking all the registered
benchmark test groups.

Attributes:
    tag_filter (str): control the benchmarks which matches the tag.
    operator (str): only run benchmark test cases that contains
this filter string in the test case's id.
    test_name (str): only run benchmark test cases that matches this filter,
    this is a case-sensitive substring match and it happens in
    the _keep_test method.
",153,163,443,10
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\benchmark_pytorch.py,TorchBenchmarkBase,"
This is a base class used to create Pytorch operator benchmark.
module_name is the name of the operator being benchmarked.
test_name is the name (it's created by concatenating all the
inputs) of a specific test
",19,23,210,4
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\benchmark_pytorch.py,PyTorchOperatorTestCase,"
This class includes all the information needed to benchmark an operator.
op_bench: it's a user-defined class (child of TorchBenchmarkBase)
which includes input and operator, .etc
test_config: a namedtuple includes test_name, input_shape, tag, run_backward.
When run_backward is false, the run_forward method will be executed,
When run_backward is true, run_forward_eager and _output_mean will be
executed to generate output. Then, run_backward will be executed.
",115,122,461,7
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\benchmark_utils.py,RandomSample,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\c2\add_test.py,AddBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\c2\matmul_test.py,MatMulBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\common\tests\add_ops_list_test.py,UnaryOpBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\common\tests\c2_cpu_gpu_forward_backward_test.py,AddBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\common\tests\jit_forward_test.py,TorchSumBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\common\tests\pt_backward_test.py,AddBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\common\tests\pt_configs_list_test.py,AddBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\common\tests\pt_cpu_gpu_forward_backward_test.py,AddBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\common\tests\random_sample_test.py,AddBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\add_test.py,AddBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\add_test.py,AddmmBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\as_strided_test.py,As_stridedBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\batchnorm_test.py,BatchNormBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\binary_test.py,BinaryOpBcastBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\binary_test.py,BinaryOpBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\cat_test.py,CatBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\chunk_test.py,ChunkBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\conv_test.py,Conv1dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\conv_test.py,ConvTranspose1dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\conv_test.py,Conv2dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\conv_test.py,ConvTranspose2dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\conv_test.py,Conv3dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\conv_test.py,ConvTranspose3dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\embeddingbag_test.py,EmbeddingBagBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\fill_test.py,Fill_Benchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\gather_test.py,GatherBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\linear_test.py,LinearBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\matmul_test.py,MatMulBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\pool_test.py,Pool1dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\pool_test.py,Pool2dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\pool_test.py,Pool3dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qactivation_test.py,QActivationBenchmarkBase,"
Base class for all the activations.
",53,54,35,1
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qarithmetic_test.py,_QFunctionalBinaryArithmeticBenchmarkBase,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qarithmetic_test.py,QFunctionalAddBenchmarkBase,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qcat_test.py,QCatBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qcomparators_test.py,QComparatorBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qconv_test.py,QConv2dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qconv_test.py,QConv2dChainedBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qinterpolate_test.py,QInterpolateBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qlinear_test.py,_QLinearBenchmarkBase,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qlinear_test.py,QLinearBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qlinear_test.py,QDynamicLinearBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qobserver_test.py,QObserverBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qpool_test.py,_QPool2dBenchmarkBase,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qpool_test.py,QMaxPool2dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qpool_test.py,QAvgPool2dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qpool_test.py,QAdaptiveAvgPool2dBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qrnn_test.py,LSTMBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qtensor_method_test.py,_QMethodBenchmarkBase,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qtensor_method_test.py,QMethodTensorInputBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qtensor_method_test.py,QMethodNoInputBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\quantization_test.py,QuantizePerTensorBenchmark,"
Benchmarks both quantization and dequantization.
",47,48,48,1
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\quantization_test.py,QuantizePerChannelBenchmark,"
Benchmarks both quantization and dequantization.
",83,84,48,1
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\quantization_test.py,FakeQuantizeBenchmark,"
Benchmarks fake quantization with default parameters.
",136,137,53,1
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qunary_test.py,QUnaryOpBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\qunary_test.py,QTopkOpBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\softmax_test.py,SoftmaxBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\split_test.py,SplitBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt\unary_test.py,UnaryOpBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\benchmarks\operator_benchmark\pt_extension\cpp_extension_test.py,TestConsumeOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\aten\aten_test.py,TestATen,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\aten\docs\sample.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\aten\docs\sample.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\gloo\gloo_test.py,TemporaryDirectory,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\gloo\gloo_test.py,TestCase,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\nccl\nccl_ops_test.py,NCCLOpsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\nnpack\nnpack_ops_test.py,NNPackOpsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\playground\AnyExp.py,AnyExpTrainer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\playground\compute_loss.py,ComputeLoss,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\playground\compute_topk_accuracy.py,ComputeTopKAccuracy,"Python default arguments are evaluated once when the function is
    defined, not each time the function is called
    This means that if you use a mutable default argument and mutate it,
    you will and have mutated that object for
    all future calls to the function as well.
    def __init__(self, blob_name=['softmax', 'label'], opts=None, topk=1):
 ",12,17,54,1
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\playground\meter.py,Meter,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\playground\resnetdemo\explicit_resnet_forward.py,ResNetModelHelper,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\prof\cuda_profile_ops_test.py,CudaProfileOpsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\tensorboard\tensorboard.py,Config,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\tensorboard\tensorboard_exporter_test.py,TensorboardExporterTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\tensorboard\tensorboard_test.py,TensorboardTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\contrib\warpctc\ctc_ops_test.py,CTCOpsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\distributed\file_store_handler_op_test.py,TestFileStoreHandlerOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\distributed\redis_store_handler_op_test.py,TestRedisStoreHandlerOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\distributed\store_ops_test_util.py,StoreOpsTests,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\experiments\python\device_reduce_sum_bench.py,BenchmarkMeta,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\experiments\python\device_reduce_sum_bench.py,Benchmark,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\experiments\python\device_reduce_sum_bench.py,SumElements,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\experiments\python\device_reduce_sum_bench.py,SumSqrElements,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\experiments\python\device_reduce_sum_bench.py,SoftMaxWithLoss,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\experiments\python\funhash_op_test.py,TestFunHash,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\experiments\python\SparseTransformer.py,NetDefNode,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\experiments\python\sparse_funhash_op_test.py,TestFunHash,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\experiments\python\sparse_reshape_op_test.py,TestSparseMatrixReshapeOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\experiments\python\tt_contraction_op_test.py,TestTTContraction,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\experiments\python\tt_pad_op_test.py,TestTTPad,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\allcompare_test.py,TemporaryDirectory,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\allcompare_test.py,TestAllCompare,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\attention.py,AttentionType,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\binarysize.py,Trie,"
A simple class that represents a Trie.
",28,29,38,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\brew.py,HelperWrapper,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\brew_test.py,BrewTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\brew_test.py,BrewGPUTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\cached_reader.py,CachedReader,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\caffe_translator.py,TranslatorRegistry,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\caffe_translator_test.py,TestNumericalEquivalence,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\checkpoint.py,Job,"
A Job defines three TaskGroups: the `init_group`, the `epoch_group` and the
`exit_group` which will be run by a JobRunner.

The `init_group` will be run only once at startup. Its role is to
initialize globally persistent blobs such as model weights, accumulators
and data file lists.

The `epoch_group` will be run in a loop after init_group. The loop will
exit when any of the stop signals added with `add_stop_condition` is True
at the end of an epoch.

The download_group will be run only once, after all the executions of
epoch_group finish. Its role is to collect the distribute scattered
parameters back after training.

The `exit_group` will be run only once at the very end of the job, the
role of this group is to save the results of training in the end of the job.

Jobs are context-driven, so that Tasks can be added to the active Job
without having to explicitly pass the job object around.

Example of usage:

def build_reader(partitions):
    with Job.current().init_group:
        reader = HiveReader(init_reader, ..., partitions)
        Task(step=init_reader)
    with Job.current().epoch_group:
        limited_reader = ReaderWithLimit(reader, num_iter=10000)
        data_queue = pipe(limited_reader, num_threads=8)
        Job.current().add_stop_condition(limited_reader.data_finished())
    return data_queue

def build_hogwild_trainer(reader, model):
    with Job.current().init_group:
        Task(step=model.param_init_net)
    with Job.current().epoch_group:
        pipe(reader, processor=model, num_threads=8)
    with Job.current().exit_group:
        Task(step=model.save_model_net)

with Job() as job:
    reader = build_reader(partitions)
    model = build_model(params)
    build_hogwild_trainer(reader, model)
",26,71,1742,45
C:\Users\vaano\python_projects\pytorch\caffe2\python\checkpoint.py,CheckpointManager,"
Controls saving and loading of workspaces on every epoch boundary of a job.
If a CheckpointManager instance is passed to JobRunner, then JobRunner will
call `init`, `read` and `save` at different moments in between epoch runs.

Args:
    db_prefix: The prefix used to construct full db name. Since `absolute_path`
        is set to True, this will be used as db_name in SaveOp.
    node_name: Name of the node where this checkpoint_manager is used.
    db_type: Type of database to use for storing checkpoint.
    metadata_handler: An optional object capable of reading/writing
        checkpoint info in storage of choice.
",149,160,623,11
C:\Users\vaano\python_projects\pytorch\caffe2\python\checkpoint.py,MultiNodeCheckpointManager,"
Coordinates checkpointing and checkpointing across multiple nodes.
Each of `init`, `load` and `save` will build TaskGroups which will
trigger checkpointing on each of the nodes involved in a distributed job.

Args:
    db_prefix: The prefix used to construct full db name. Since `absolute_path`
        is set to True, this will be used as db_name in SaveOp.
    db_type: Type of database to use for storing checkpoint.
    metadata_handler: An optional object capable of reading/writing
        checkpoint info in storage of choice.
",432,442,533,10
C:\Users\vaano\python_projects\pytorch\caffe2\python\checkpoint.py,UploadTaskGroupBuilder,"
A simple class to upload checkpoints.
",637,638,37,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\checkpoint.py,JobRunner,"
Implement the runtime logic for jobs with checkpointing at the level of
epoch. Can be used to run either single-host or distributed jobs. Job
runner is a callable to be called once from the master, passing a session
as an argument. This call will block until the Job execution is complete.

If a checkpoint_manager is passed, checkpoints will be taken after
initialization and after each epoch execution. If, in addition,
`resume_from_epoch` is an epoch number, the corresponding checkpoint will
be loaded and job execution will continue from the given epoch. In
this case, the job's init_group will not be run.

Refer to checkpoint_test.py for an example.
",655,667,656,12
C:\Users\vaano\python_projects\pytorch\caffe2\python\checkpoint_test.py,UploadToLocalFile,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\checkpoint_test.py,TestCheckpoint,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\cnn.py,CNNModelHelper,"
A helper model so we can write CNN models more easily, without having to
manually define parameter initializations and operators separately.
",15,17,140,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\context.py,_ContextInfo,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\context.py,_ContextRegistry,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\context.py,define_context,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\context_test.py,MyContext,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\context_test.py,TestContext,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\control_ops_grad_test.py,TestControl,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\control_test.py,TestControl,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\convert_test.py,TestOperator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\convnet_benchmarks_test.py,TestConvnetBenchmarks,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core.py,DataType,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core.py,BlobReference,"
A wrapper around a blob in a net.

BlobReference gives us a way to refer to the network that the blob is
generated from. Note that blobs are, essentially, just strings in the
current workspace.
",180,185,193,5
C:\Users\vaano\python_projects\pytorch\caffe2\python\core.py,IR,"
A simple IR class to keep track of all intermediate representations used
in the gradient computation.
",464,466,101,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\core.py,GradientRegistry,"
GradientRegistry holds the mapping from operators to their gradients.
",1062,1063,69,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\core.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core.py,RemapEntry,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core.py,ExecutionStep,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core.py,Plan,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_gradients_test.py,TestGradientCalculation,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_gradients_test.py,TestSparseGradientsAccumulation,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_gradients_test.py,TestGradientsAccumulationWithNoGradientOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_gradients_test.py,TestGradientsAccumulationWithPassThroughGradients,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestScopes,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestCloneNet,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestExternalInputs,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestCreateOperator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestAutoNaming,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestAppendNet,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestExtractPredictorNet,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestOperatorTraceback,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestCreatePlan,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestOpRegistryKey,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestDeviceOption,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestInferDeviceCpuOnly,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestInferDevice,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestRerouteTensor,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\core_test.py,TestRunAllOnGPU,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\crf.py,CRFWithLoss,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\crf_viterbi_test.py,TestCrfDecode,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio.py,Reader,"
Reader is an abstract class to be implemented in order to provide
operations capable of iterating through a dataset or stream of data.

A Reader must implement at least one operation, `read`, which
adds operations to a net that read the next batch of data. Readers can
optionally support the `reset` operation, which is useful when multiple
passes over the data are required.
",30,37,375,7
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio.py,Writer,"
Writer is an abstract class to be implemented in order to provide
operations capable of feeding a data stream or a dataset.

A Writer must implement 2 operations:
`write`, which adds operations to a net that write the write batch of
data, and `commit`, which adds operations to a net in order to indicate
that no more data will be written.
",147,154,339,7
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio.py,ReaderBuilder,"
Allow usage of a reader in distributed fashion. 
",211,212,47,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio.py,PipedReaderBuilder,"
ReaderBuilder that modifies underlying builder by calling `piper`
function on each new reader produced, and return the result of
the function. This way, it is possible to append data processing
pipelines that will be replicated for each reader that gets created.

E.g.:

PipedReaderBuilder(
    ReaderBuilder(...),
    lambda reader: pipe(reader, processor=my_proc))
",227,237,366,10
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio.py,Pipe,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio.py,CounterReader,"
Reader that produces increasing integers. 
",298,299,41,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio.py,ReaderWithLimitBase,"
Abstract Reader constrained by certain conditions.

Base class for Reader classes which check for certain conditions to stop
further processing (e.g. max number of iterations or time limit).
Also produces a boolean blob (data_finished) that can be used to see if
the reader exausted all input data (true) or stopped for another reason
(false).
",317,324,343,7
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio.py,ReaderWithLimit,"
Reader that stops after `num_iter` batches.

If `num_iter` <= 0 or is None, reverts to an unconstrained reader that
exports a boolean blob indicating that the reader has exhausted
the data steam.
",411,416,195,5
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio.py,ReaderWithTimeLimit,"
Reader that stops after `duration` seconds.

If `duration` <= 0 or is None, reverts to an unconstrained reader that
exports a boolean blob indicating that the reader has exhausted
the data steam.
",453,458,195,5
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio.py,ReaderWithDelay,"
Test reader class that inserts a delay between reading batches.
",499,500,63,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio.py,CompositeReader,"
Base class for a reader that wrap multiple readers, e.g., reading from
multiple sources simultaneously.
",520,522,103,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio.py,CompositeReaderBuilder,"
A reader builder for CompositeReader
",577,578,36,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio_test.py,TestReaderBuilder,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio_test.py,TestCompositeReader,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio_test.py,TestReaderWithLimit,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataio_test.py,TestDBFileReader,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataset.py,_DatasetReader,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataset.py,_DatasetRandomReader,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataset.py,_DatasetWriter,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\dataset.py,Dataset,"
Represents an in-memory dataset with fixed schema.

Use this to store and iterate through datasets with complex schema that
fit in memory.

Iterating through entries of this dataset is very fast since the dataset
is stored as a set of native Caffe2 tensors, thus no type conversion or
deserialization is necessary.
",186,194,314,8
C:\Users\vaano\python_projects\pytorch\caffe2\python\data_parallel_model.py,CollectivesConcurrencyControl,"
Creates common worlds (up to max_concurrent_context) and manage the
sequential execution of collectives that shares the same context with
cyclic control inputs.
",1309,1312,160,3
C:\Users\vaano\python_projects\pytorch\caffe2\python\data_parallel_model_test.py,TemporaryDirectory,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\data_parallel_model_test.py,DataParallelModelTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\data_parallel_model_test.py,RecurrentNetworkParallelTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\data_parallel_model_test.py,SparseDataParallelModelTest,"
Create and run the model. We try with both storing indices for gather
on CPU and on GPU
",880,882,87,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\data_parallel_model_test.py,ParallelizeBMUFTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\data_parallel_model_test.py,SparseDataParallelModelTestWithSharedIndices,"
Create and run the model. We try with both storing indices for gather
on CPU and on GPU
",1225,1227,87,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\data_workers.py,BatchFeeder,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\data_workers.py,GlobalCoordinator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\data_workers.py,DataWorker,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\data_workers_test.py,DataWorkersTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\db_file_reader.py,DBFileReader,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\db_test.py,TestDB,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\device_checker.py,DeviceChecker,"
A device checker in Python to check consistency across multiple devices.

This is not the most efficient way to check devices, as the Python interface
will involve a lot of copies back and forth operations. Use at your own risk.
",11,15,228,4
C:\Users\vaano\python_projects\pytorch\caffe2\python\experiment_util.py,ExternalLogger,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\experiment_util.py,ModelTrainerLog,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\filler_test.py,TestFiller,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\functional.py,_Functional,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\functional_test.py,TestFunctional,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\fused_8bit_rowwise_conversion_ops_test.py,TestFused8BitRowwiseQuantizationConversion,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_checker.py,NetGradientChecker,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_checker.py,GradientChecker,"
A gradient checker in Python.

This is not the most efficient way to check gradients, as the Python
interface will involve a lot of copies back and forth operations. Use at your
own risk.
",156,161,187,5
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestLRN,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestFlatten,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestConcat,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestRelu,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestTanh,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestAbs,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestExp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestCos,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestSin,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestSigmoid,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestSum,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestMakeTwoClass,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestNetGradientChecker,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestIf,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gradient_check_test.py,TestWhile,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\gru_cell.py,GRUCell,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\hypothesis_test.py,TestOperators,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\hypothesis_test_util.py,HypothesisTestCase,"
A unittest.TestCase subclass with some helper functions for
utilizing the `hypothesis` (hypothesis.readthedocs.io) library.
",382,384,123,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers_test.py,TestLayers,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layer_model_helper.py,LayerModelHelper,"
Model helper for building models on top of layers abstractions.

Each layer is the abstraction that is higher level than Operator. Layer
is responsible for ownership of it's own parameters and can easily be
instantiated in multiple nets possible with different sets of ops.
As an example: one can easily instantiate predict and train nets from
the same set of layers, where predict net will have subset of the
operators from train net.
",31,39,435,8
C:\Users\vaano\python_projects\pytorch\caffe2\python\layer_parameter_sharing_test.py,ParameterSharingTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layer_test_util.py,OpSpec,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layer_test_util.py,LayersTestCase,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\lengths_reducer_fused_8bit_rowwise_ops_test.py,TestLengthsReducerOpsFused8BitRowwise,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\lengths_reducer_rowwise_8bit_ops_test.py,TestQuantize8bits,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\memonger.py,AssignmentAlgorithm,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\memonger_test.py,MemongerTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\model_device_test.py,TestMiniAlexNet,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\model_helper.py,ModelHelper,"
A helper model so we can manange models more easily. It contains net def
and parameter storages. You can add an Operator yourself, e.g.

    model = model_helper.ModelHelper(name=""train_net"")
    # init your weight and bias as w and b
    w = model.param_init_net.XavierFill(...)
    b = model.param_init_net.ConstantFill(...)
    fc1 = model.FC([input, w, b], output, **kwargs)

or you can use helper functions in brew module without manually
defining parameter initializations and operators.

    model = model_helper.ModelHelper(name=""train_net"")
    fc1 = brew.fc(model, input, output, dim_in, dim_out, **kwargs)
",77,91,616,14
C:\Users\vaano\python_projects\pytorch\caffe2\python\model_helper_test.py,ModelHelperTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\modifier_context.py,ModifierContext,"
provide context to allow param_info to have different modifiers
",13,14,63,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\modifier_context.py,UseModifierBase,"
context class to allow setting the current context.
Example usage with layer:
    modifiers = {'modifier1': modifier1, 'modifier2': modifier2}
    with Modifiers(modifiers):
        modifier = ModifierContext.current().get_modifier('modifier1')
        layer(modifier=modifier)
",44,50,277,6
C:\Users\vaano\python_projects\pytorch\caffe2\python\muji_test.py,TestMuji,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder.py,NetBuilder,"
Scope-driven mechanism for building nets, loops and conditional blocks.
Arguments:
  name: NetBuilder's name
  initial_scope: list of blobs that are available for reading/writing
Example:
    from caffe2.python.net_builder import NetBuilder, ops
    with NetBuilder() as nb:
        c = ops.Const(5)
        d = ops.Const(0)
        with ops.loop():
            ops.stop_if(ops.LE([c, ops.Const(0)]))
            ops.Add([c, ops.Const(-1)], [c])
            with ops.If(ops.GE([c, ops.Const(3)])):
                ops.Add([d, ops.Const(10)], [d])
        ops.Print(c, [])
        ops.Print(d, [])
    step = core.to_execution_step(nb)
",14,31,634,17
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder.py,Operations,"
Operations to be used in the context of a NetBuilder.
",206,207,53,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder.py,_ReporterBuilder,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder.py,_SetupBuilder,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder.py,_RunOnce,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder.py,_StopGuard,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder.py,_Loop,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder.py,_RunIf,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder.py,_RunIfNet,"
Generates a single net that uses If operator
",612,613,44,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder.py,_RunElseNet,"
Else branch for _RunIfNet builder
",645,646,33,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder.py,_RunWhileNet,"
Generates a single net that uses While operator
",677,678,47,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder.py,_RunWhileCondition,"
Computes loop's condition, used in the context of WhileNet.
Last operator must have a single scalar boolean output that will be used
as a condition value, no other blobs created in the condition net are
visible outside of it
",709,713,224,4
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder_test.py,PythonOpStats,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_builder_test.py,TestNetBuilder,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_printer.py,Visitor,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_printer.py,Analyzer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_printer.py,Text,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_printer.py,Printer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\net_printer_test.py,TestNetPrinter,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\nomnigraph.py,NNModule,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\nomnigraph_test.py,TestBindings,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\nomnigraph_transformations_test.py,TestNomnigraphTransformations,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\normalizer.py,Normalizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\normalizer.py,BatchNormalizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\normalizer.py,LayerNormalizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\normalizer_context.py,NormalizerContext,"
provide context to allow param_info to have different normalizers
",14,15,65,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\normalizer_context.py,UseNormalizer,"
context class to allow setting the current context.
Example usage with layer:
    normalizers = {'norm1': norm1, 'norm2': norm2}
    with UseNormalizer(normalizers):
        norm = NormalizerContext.current().get_normalizer('norm1')
        layer(norm=norm)
",29,35,257,6
C:\Users\vaano\python_projects\pytorch\caffe2\python\normalizer_test.py,TestNormalizerContext,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\numa_test.py,NUMATest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\observer_test.py,TestObservers,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_fp_exceptions_test.py,OperatorFPExceptionsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,Optimizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,SgdOptimizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,MultiPrecisionSgdOptimizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,FP16SgdOptimizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,WeightDecayBuilder,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,AdagradOptimizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,WngradOptimizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,AdadeltaOptimizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,FtrlOptimizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,GFtrlOptimizer,"
Group Lasso FTRL Optimizer.
",910,911,27,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,AdamOptimizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,YellowFinOptimizer,"
YellowFin: An automatic tuner for momentum SGD

See https://arxiv.org/abs/1706.03471 for more details. This implementation
has separate learning rate and momentum per each parameter.
",1073,1077,182,4
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer.py,RmsPropOptimizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_context.py,OptimizerContext,"
provide context to allow param_info to have different optimizers
",17,18,64,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_context.py,UseOptimizer,"
context class to allow setting the current context.
Example usage with brew:
    - with UseOptimizer(optim):
        brew.func
    - with UseOptimizer({'WEIGHT': weight_optim}):
        brew.func
    - with UseOptimizer({'DEFAULT': optim, 'BIAS': bias_optim,
                            'WEIGHT': weight_optim}):
        brew.func
    - with UseOptimizer(optim1):
        brew.func
        with UseOptimizer(optim2):
            brew.func

Example usage with layer:
    optimizers = {'optim1': optim1, 'optim2': optim2}
    with Optimizers(optimizers):
        optim = OptimizerContext.current().get_optimizer('optim1')
        layer(optim=optim)
",32,51,646,19
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestLars,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestMomentumSgd,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestSgd,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestMultiPrecisionSgd,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestFtrl,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestGFtrl,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestAdagrad,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestRowWiseAdagrad,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestWngrad,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestAdadelta,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestAdam,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestSparseRAdam,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestYellowFin,"YellowFin: An automatic tuner for momentum SGD
    (https://arxiv.org/abs/1706.03471)
 ",223,224,33,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestRmsProp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestMultiOptimizers,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestWeightDecay,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test.py,TestOptimizerContext,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test_util.py,OptimizerTestBase,"
This is an abstract base class.
Don't inherit from unittest.TestCase, and don't name it 'Test*'.
Do, however, do these things in classes which inherit from this.
",19,22,161,3
C:\Users\vaano\python_projects\pytorch\caffe2\python\optimizer_test_util.py,LRModificationTestBase,"
This is an abstract base class.
Don't inherit from unittest.TestCase, and don't name it 'Test*'.
Do, however, do these things in classes which inherit from this.
",153,156,161,3
C:\Users\vaano\python_projects\pytorch\caffe2\python\parallelize_bmuf_distributed_test.py,DistributedTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\parallel_workers.py,Metrics,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\parallel_workers.py,State,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\parallel_workers.py,WorkerCoordinator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\parallel_workers.py,GlobalWorkerCoordinator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\parallel_workers.py,Worker,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\parallel_workers_test.py,ParallelWorkersTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\pipeline.py,Output,"
Represents the result of a processor function. A processor can either
return an Output, or it can return a record, in which case an Output will be
created for it afterwards.
",16,19,173,3
C:\Users\vaano\python_projects\pytorch\caffe2\python\pipeline.py,ProcessingReader,"
Reader that reads from an upstream reader, calls the processor, and returns
the processed record.
",354,356,97,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\pipeline.py,NetProcessor,"
Processor that clones a core.Net each time it's called, executing
the cloned net as the processor. It requires the Net to have input
and (optionally) output records set, with net.set_input_record() and
net.set_output_record().
",398,402,226,4
C:\Users\vaano\python_projects\pytorch\caffe2\python\pipeline_test.py,TestPipeline,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\python_op_test.py,PythonOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\queue_util.py,_QueueReader,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\queue_util.py,_QueueWriter,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\queue_util.py,QueueWrapper,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\queue_util.py,Queue,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\record_queue.py,_QueueReader,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\record_queue.py,_QueueWriter,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\record_queue.py,RecordQueue,"
The class is used to feed data with some process from a reader into a
queue and provider a reader interface for data fetching from the queue.
",49,51,141,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,RegularizationBy,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,Regularizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,L1Norm,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,LpNorm,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,L0ApproxNorm,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,L1NormTrimmed,"
The Trimmed Lasso: Sparsity and Robustness. https://arxiv.org/abs/1708.04527
",203,204,76,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,L2Norm,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,ElasticNet,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,ElasticNetL1NormTrimmed,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,MaxNorm,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,ConstantNorm,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,LogBarrier,"
Wright, S., & Nocedal, J. (1999). Numerical optimization. Springer Science,
35(67-68), 7. Chapter 19
",322,324,100,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,BoundedGradientProjection,"
Wright, S., & Nocedal, J. (1999). Numerical optimization. Springer Science,
35(67-68), 7. Chapter 16
",368,370,100,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer.py,GroupL1Norm,"
Scardapane, Simone, et al. ""Group sparse regularization for deep neural networks.""
Neurocomputing 241 (2017): 81-89.

This regularizer computes l1 norm of a weight matrix based on groups.
There are essentially three stages in the computation:
1. Compute the l2 norm on all the members of each group
2. Scale each l2 norm by the size of each group
3. Compute the l1 norm of the scaled l2 norms
",419,427,392,8
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer_context.py,RegularizerContext,"
provide context to allow param_info to have different regularizers
",14,15,66,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer_context.py,UseRegularizer,"
context class to allow setting the current context.
Example usage with layer:
    regularizers = {'reg1': reg1, 'reg2': reg2}
    with UseRegularizer(regularizers):
        reg = RegularizerContext.current().get_regularizer('reg1')
        layer(reg=reg)
",29,35,254,6
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer_test.py,TestRegularizerContext,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\regularizer_test.py,TestRegularizer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,RNNCell,"
Base class for writing recurrent / stateful operations.

One needs to implement 2 methods: apply_override
and get_state_names_override.

As a result base class will provice apply_over_sequence method, which
allows you to apply recurrent operations over a sequence of any length.

As optional you could add input and output preparation steps by overriding
corresponding methods.
",49,59,377,10
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,LSTMInitializer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,BasicRNNCell,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,LSTMCell,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,LayerNormLSTMCell,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,MILSTMCell,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,LayerNormMILSTMCell,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,DropoutCell,"
Wraps arbitrary RNNCell, applying dropout to its output (but not to the
recurrent connection for the corresponding state).
",817,819,122,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,MultiRNNCellInitializer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,MultiRNNCell,"
Multilayer RNN via the composition of RNNCell instance.

It is the resposibility of calling code to ensure the compatibility
of the successive layers in terms of input/output dimensiality, etc.,
and to ensure that their blobs do not have name conflicts, typically by
creating the cells with names that specify layer number.

Assumes first state (recurrent output) for each layer should be the input
to the next layer.
",912,921,417,9
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,AttentionCell,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,LSTMWithAttentionCell,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,MILSTMWithAttentionCell,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\rnn_cell.py,UnrolledCell,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\schema.py,Metadata,"
Represents additional information associated with a scalar in schema.

`categorical_limit` - for fields of integral type that are guaranteed to be
non-negative it specifies the maximum possible value plus one. It's often
used as a size of an embedding table.

`expected_value` - anticipated average value of elements in the field.
Usually makes sense for length fields of lists.

`feature_specs` - information about the features that contained in this
field. For example if field have more than 1 feature it can have list of
feature names contained in this field.
",75,87,563,12
C:\Users\vaano\python_projects\pytorch\caffe2\python\schema.py,Field,"
Represents an abstract field type in a dataset.
    
",98,99,47,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\schema.py,List,"
Represents a variable-length list.

Values of a list can also be complex fields such as Lists and Structs.
In addition to the fields exposed by its `values` field, a List exposes an
additional `lengths` field, which will contain the size of each list under
the parent domain.
",199,205,275,6
C:\Users\vaano\python_projects\pytorch\caffe2\python\schema.py,ListWithEvicted,"
This class is similar with List, but containing extra field evicted_values for
LRU Hashing.
",280,282,91,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\schema.py,Struct,"
Represents a named list of fields sharing the same domain.
    
",362,363,58,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\schema.py,Scalar,"
Represents a typed scalar or tensor of fixed shape.

A Scalar is a leaf in a schema tree, translating to exactly one tensor in
the dataset's underlying storage.

Usually, the tensor storing the actual values of this field is a 1D tensor,
representing a series of values in its domain. It is possible however to
have higher rank values stored as a Scalar, as long as all entries have
the same shape.

E.g.:

    Scalar(np.float64)

        Scalar field of type float64. Caffe2 will expect readers and
        datasets to expose it as a 1D tensor of doubles (vector), where
        the size of the vector is determined by this fields' domain.

    Scalar((np.int32, 5))

        Tensor field of type int32. Caffe2 will expect readers and
        datasets to implement it as a 2D tensor (matrix) of shape (L, 5),
        where L is determined by this fields' domain.

    Scalar((str, (10, 20)))

        Tensor field of type str. Caffe2 will expect readers and
        datasets to implement it as a 3D tensor of shape (L, 10, 20),
        where L is determined by this fields' domain.

If the field type is unknown at construction time, call Scalar(), that will
default to np.void as its dtype.

It is an error to pass a structured dtype to Scalar, since it would contain
more than one field. Instead, use from_dtype, which will construct
a nested `Struct` field reflecting the given dtype's structure.

A Scalar can also contain a blob, which represents the value of this
Scalar. A blob can be either a numpy.ndarray, in which case it contain the
actual contents of the Scalar, or a BlobReference, which represents a
blob living in a caffe2 Workspace. If blob of different types are passed,
a conversion to numpy.ndarray is attempted.
",669,711,1733,42
C:\Users\vaano\python_projects\pytorch\caffe2\python\schema.py,_SchemaNode,"
This is a private class used to represent a Schema Node
",971,972,55,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\schema_test.py,TestDB,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\schema_test.py,Subclass,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\schema_test.py,Subclass,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\schema_test.py,Subclass,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\scope_test.py,TestScope,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\session.py,CompiledRunnable,"
Wrapper for compiled runnable returned from session.compile() 
",14,15,61,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\session.py,Session,"
Allows to run Nets, ExecutionSteps, Plans, Tasks and TaskGroups.
A session can potentially run in multiple nodes concurrently.


Example:
    from core import Net
    from caffe2.python.task import Task, TaskGroup, WorkspaceType

    net = Net('test1')
    net.Add([net.Const(1), net.Const(2)])

    net2 = net.Clone()
    step = core.execution_step('step1', [net2])

    with TaskGroup(WorkspaceType.GLOBAL) as init_tg:
        with Node('node1'):
            n1setup = net.Net('n1setup')
            n1msg = n1setup.Const('Hello from node 1.')
            Task(step=n1setup)

    with TaskGroup() as private_tg:
        with Node('node1'):
            n1 = net.Net('n1')
            n1.Print(n1msg, 0)
            Task(step=n1)
        with Node('node2'):
            n2 = net.Net('n2')
            n2.Print(n2.Const('Hello from node 2.'), 0)
            Task(step=n2)

    session = LocalSession()
    session.run(net)
    session.run(step)
    session.run(init_tg)
    session.run(private_tg)


Global Workspace:
    At the beginning of the session, a global workspace is created and kept
    alive for the duration of the session.


Private Workspace:
    Tasks can be run either directly on the global workspace, or they can
    instantiate a private child workspace that is released after each run.

Blob visibility:
    Tasks running in different nodes in parallel will always run under
    different workspaces, so it must be assumed that they won't be able to
    access each other's blobs. Tasks running on the same node will follow
    Workspace hierarchy rules: tasks running on separate private workspaces
    will only be able to share blobs defined on a common parent Workspace.
",21,73,1694,52
C:\Users\vaano\python_projects\pytorch\caffe2\python\session.py,LocalSession,"
Session that runs in a single node.
Tasks are all remapped to run in parallel in the 'local' node.

Currently, LocalSession runs all parallel tasks in the same workspace,
but this behavior may change in the future. Only tasks pointing to the
same logical node are guaranteed to always run in the same workspace.
",177,183,311,6
C:\Users\vaano\python_projects\pytorch\caffe2\python\session_test.py,TestLocalSession,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\sparse_to_dense_mask_test.py,TestSparseToDenseMask,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\sparse_to_dense_test.py,TestSparseToDense,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\task.py,Cluster,"
Context that keeps track of all the node names used.
Users shouldn't have to use them directly, since a Cluster is automatically
generated at the first usage of 'Node'.
",27,30,168,3
C:\Users\vaano\python_projects\pytorch\caffe2\python\task.py,Node,"
A Node context is used to indicate that all Tasks instantiated within will
run on the given node name. (Only the name of the node actually counts.)
Example:

    with TaskGroup() as tg:
        with Node('node1'):
            s1 = execution_step(...)
            Task(step=s1)
        with Node('node2'):
            s2 = execution_step(...)
        with Node('node1'):
            s3 = execution_step(...)

    In this example, all three execution steps will run in parallel.
    Moreover, s1 and s3 will run on the same node, and can see each
    others blobs.

    Additionally, a Node can be passed implementation-specific kwargs,
    in order to specify properties of the node.
",61,80,682,19
C:\Users\vaano\python_projects\pytorch\caffe2\python\task.py,WorkspaceType,"
Determines whether tasks of a TaskGroup will run directly at the global
workspace, which is kept alive across runs, or whether a new child
workspace will be created for the run and destroyed afterwards.
",100,103,202,3
C:\Users\vaano\python_projects\pytorch\caffe2\python\task.py,TaskGroup,"
Context that gathers tasks which will run concurrently, potentially on
multiple nodes. All tasks in the same node will share the same workspace
and thus can share blobs, while tasks running in different nodes won't
be able to directly share data.

All tasks of the task group will start concurrently, and the task group
will finish execution when the last task of the group finishes.

Example:
    # suppose that s1 ... s5 are execution steps or nets.
    with TaskGroup() as tg:
        # these tasks go to default node 'local'
        Task(step=s1)
        Task(step=s2)

        with Node('n2'):
            Task(step=s3)
        with Node('n1'):
            Task(step=s4)
        with Node('n2'):
            Task(step=s5)

    # this will run all steps in parallel.
    # s1 and s2 will run at default node 'local'
    # s3 and s5 will run at node 'n2'
    # s4 will run at node 'n1'
    session.run(tg)
",166,193,908,27
C:\Users\vaano\python_projects\pytorch\caffe2\python\task.py,TaskOutput,"
Represents the output of a task. An output can be a blob,
a list of blob, or a record.
",361,363,86,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\task.py,TaskOutputList,"
Keeps a list of outputs for a task 
",419,420,34,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\task.py,Task,"
A Task is composed of an execution step and zero or more outputs.
Tasks are executed in the context of a TaskGroup, which, in turn, can
be run by a Session.

Task outputs are fetched by the session at the end of the run.

The recommended way of creating a task is by using `net_builder.ops`.
Example:

    from net_builder import ops
    with Node('trainer'), Task(name='my_task', num_instances=2):
        with ops.task_init():
            globl = ops.Const(0)
        with ops.task_instance_init():
            local = ops.Const(0)
        with ops.loop(100):
            ops.Copy(globl, local)
        with ops.task_instance_exit():
            ops.Add([globl, local], [globl])
        with ops.task_exit():
            ops.Mul([globl, globl], [globl])

The task above will create 2 instances that will run in parallel.
Each instance will copy `local` to `globl` 100 times, Then Add `local`
to `globl` once. The `Mul` will only execute once, after all the instances
of the task have finished.
",446,472,995,26
C:\Users\vaano\python_projects\pytorch\caffe2\python\task.py,SetupNets,"
Allow to register a list of nets to be run at initialization
and finalization of Tasks or TaskGroups.
For example, let's say you have the following:

    init_net = core.Net('init')
    my_val = init_net.ConstantFill([], 'my_val', value=0)

    net = core.Net('counter')
    net.Add([my_val, net.Const(1),], [my_val])

    with TaskGroup() as task_group:
        with Node('trainer'):
            my_task = Task(step=[net])

In order to have `init_net` run once before `net` runs for the
first time, you can do one of the following:

    net.add_attribute(Task.TASK_SETUP, SetupNets([init_net]))

or

    net.add_attribute(TaskGroup.LOCAL_SETUP, SetupNets([init_net]))

- With Task.TASK_SETUP, init_net will run once at my_task startup.
- With TaskGroup.LOCAL_SETUP, init_net will run once on node 'trainer',
  before any task of the task group is run on that node.

The same SetupNets object can be added to multiple nets. It will only
run once per Task/TaskGroup run.
",651,680,969,29
C:\Users\vaano\python_projects\pytorch\caffe2\python\task_test.py,TestTask,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\test_util.py,TestCase,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\text_file_reader.py,TextFileReader,"
Wrapper around operators for reading from text files.
",13,14,53,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\timeout_guard.py,WatcherThread,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\toy_regression_test.py,TestToyRegression,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\transformations.py,Transformer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\transformations_test.py,TestTransformations,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\tt_core_test.py,TestTTSVD,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\utils.py,DebugMode,"
This class allows to drop you into an interactive debugger
if there is an unhandled exception in your python script

Example of usage:

def main():
    # your code here
    pass

if __name__ == '__main__':
    from caffe2.python.utils import DebugMode
    DebugMode.run(main)
",280,292,275,12
C:\Users\vaano\python_projects\pytorch\caffe2\python\utils_test.py,TestUtils,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\visualize.py,PatchVisualizer,"
PatchVisualizer visualizes patches.
  
",29,30,35,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\visualize.py,NHWC,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\visualize.py,NCHW,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace.py,_BlobDict,"
Provides python dict compatible way to do fetching and feeding
",519,520,62,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace_test.py,TestWorkspace,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace_test.py,TestMultiWorkspaces,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace_test.py,TestWorkspaceGPU,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace_test.py,TestWorkspaceIDEEP,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace_test.py,TestImmedibate,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace_test.py,TestCppEnforceAsException,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace_test.py,TestCWorkspace,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace_test.py,TestPredictor,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace_test.py,TestTransform,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace_test.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace_test.py,TestScriptModule,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\workspace_test.py,TestScriptModuleFromString,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\formatter.py,Formatter,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\formatter.py,Markdown,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\generator.py,DocUploader,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\generator.py,DocGenerator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\generator.py,OpDocGenerator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\generator.py,OperatorEngine,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\generator.py,OperatorDoc,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\github.py,GHOpDocUploader,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\github.py,GHMarkdown,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\github.py,GHOperatorEngine,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\github.py,GHOperatorDoc,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\github.py,GHOpDocGenerator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\docs\parser.py,Parser,"List of tuples (regex_str, lambda(regex_match, formatter))
    If a lambda returns True it will be called repeatedly with replacement
    otherwise it will only be called on text that hasn't been parsed yet.
 ",11,13,11,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\examples\char_rnn.py,CharRNN,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\adam_op_test.py,TestAdamOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\blobs_queue_db_test.py,BlobsQueueDBTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\channel_shuffle_op_test.py,ChannelShuffleTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\concat_split_op_test.py,TestConcatSplitOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\convfusion_op_test.py,ConvFusionTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\conv_op_test.py,ConvTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\conv_transpose_test.py,ConvTransposeTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\copy_op_test.py,CopyTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\dropout_op_test.py,DropoutTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\elementwise_sum_op_test.py,ElementwiseSumTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\expanddims_squeeze_op_test.py,ExpandDimsSqueezeTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\fc_op_test.py,FcTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\leaky_relu_op_test.py,LeakyReluTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\LRN_op_test.py,LRNTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\moment_sgd_op_test.py,TestMomentumSGDUpdateOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\operator_fallback_op_test.py,TestFallbackOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\order_switch_op_test.py,OrderSwitchTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\pool_op_test.py,PoolTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\pre_convert_test.py,PreConvertTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\relu_op_test.py,ReluTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\reshape_op_test.py,TestReShapeOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\shape_op_test.py,ShapeTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\sigmoid_op_test.py,SigmoidTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\softmax_op_test.py,SoftmaxTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\spatial_bn_op_test.py,TestSpatialBN,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\transpose_op_test.py,TransposeTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\ideep\weightedsum_op_test.py,TestWeightedSumOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\adaptive_weight.py,AdaptiveWeight,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\add_bias.py,AddBias,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\arc_cosine_feature_map.py,ArcCosineFeatureMap,"
A general version of the arc-cosine kernel feature map (s = 1 restores
the original arc-cosine kernel feature map).

Applies H(x) * x^s, where H is the Heaviside step function and x is the
input after applying FC (such that x = w * x_orig + b).

For more information, see the original paper:
    http://cseweb.ucsd.edu/~saul/papers/nips09_kernel.pdf

Inputs :
    output_dims -- dimensions of the output vector
    s -- degree to raise transformed features
    scale -- amount to scale the standard deviation
    weight_init -- initialization distribution for weight parameter
    bias_init -- initialization distribution for bias pararmeter
    weight_optim -- optimizer for weight params; None for random features
    bias_optim -- optimizer for bias param; None for random features
    set_weight_as_global_constant -- if True, initialized random parameters
                                     will be constant across all distributed
                                     instances of the layer
    initialize_output_schema -- if True, initialize output schema as Scalar
                                from Arc Cosine; else output schema is None
",12,34,1149,22
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\batch_huber_loss.py,BatchHuberLoss,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\batch_lr_loss.py,BatchLRLoss,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\batch_mse_loss.py,BatchMSELoss,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\batch_normalization.py,BatchNormalization,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\batch_sigmoid_cross_entropy_loss.py,BatchSigmoidCrossEntropyLoss,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\batch_softmax_loss.py,BatchSoftmaxLoss,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\blob_weighted_sum.py,BlobWeightedSum,"
This layer implements the weighted sum:
weighted element-wise sum of input blobs.
",13,15,81,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\bpr_loss.py,BPRLoss,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\bucket_weighted.py,BucketWeighted,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\build_index.py,MapToRange,"
This layer aims to build a mapping from raw keys to indices within [0, max_index).
The mapping is continuously built during training. The mapping will be frozen during
evaluation and prediction. Unseen keys will be assigned to index 0.
",13,16,235,3
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\concat.py,Concat,"
Construct Concat layer
Assume that first dimension is batch,

Example:

    embedding_dim = 64
    input_record = self.new_record(schema.Struct(
        ('input1', schema.Scalar((np.float32, (embedding_dim, )))),
        ('input2', schema.Scalar((np.float32, (embedding_dim, )))),
        ('input3', schema.Scalar((np.float32, (embedding_dim, )))),
    ))

    output = self.model.Concat(input_record)
    self.assertEqual(
        schema.Scalar((np.float32, ((len(input_record.fields) * embedding_dim, )))),
        output
    )

    # Note that in Concat layer we assume first dimension is batch.
    # so input is B * embedding_dim
    # add_axis=1 make it B * 1 * embedding_dim
    # Concat on axis=1 make it B * N * embedding_dim

    output = self.model.Concat(input_record, axis=1, add_axis=1)
    self.assertEqual(
        schema.Scalar((np.float32, ((len(input_record.fields), embedding_dim)))),
        output
    )
",36,64,925,28
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\constant_weight.py,ConstantWeight,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\conv.py,Conv,"
Convolutional layer
Input:
- input_record: at least has the shape info of C (num_channels)
- output_dim: number of convolutional filters
- kernel_h, kernel_w: kernel size for h and w
- stride_h, stride_w: stride for h and w
- pad_b, pad_l, pad_r, pad_t: padding sizes, if stride == 1,
                              'None' value will do auto padding
- order: either 'NHWC' or 'NCHW'
",16,25,381,9
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\dropout.py,Dropout,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\fc.py,FC,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\fc_without_bias.py,FCWithoutBias,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\fc_with_bootstrap.py,FCWithBootstrap,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\feature_sparse_to_dense.py,FeatureSparseToDense,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\functional.py,Functional,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\gather_record.py,GatherRecord,"
Given 1-D `indices` tensor, gather elements at `i` in `indices` from all the
blobs in `record`. If a blob is a values blob of a list, all the elements
included by the list's lengths blob are gathered. For example,

Input:
    indices = [0, 2]
    record:a = [[0, 1], [2, 3], [4, 5], [6, 7]]
    record:b:lengths = [0, 1, 2, 3]
    record:b:items = [0, 1, 2, 3, 4, 5]

Output:
    a = [[0, 1], [4, 5]]
    b:lengths = [0, 2]
    b:items = [1, 2]

This supports nested list.
",13,29,472,16
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\homotopy_weight.py,HomotopyWeight,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\label_smooth.py,LabelSmooth,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\last_n_window_collector.py,LastNWindowCollector,"
Collect last-N samples from input record. If you have complex data,
use PackRecords to pack it before using this layer.

This layer is not thread safe.
",13,17,151,4
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\layers.py,InstantiationContext,"
List of contexts where layer could be instantitated
",123,124,51,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\layers.py,LayerParameter,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\layers.py,ModelLayer,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\layer_normalization.py,LayerNormalization,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\margin_rank_loss.py,MarginRankLoss,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\merge_id_lists.py,MergeIdLists,"
Merge multiple ID_LISTs into a single ID_LIST

Arguments:
    model: A layer model instance
    input_record: Tuple (Struct) of ID_LIST features to be
    merged

Returns:
    the merged ID_LIST feature
",17,26,202,9
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\pairwise_similarity.py,PairwiseSimilarity,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\position_weighted.py,PositionWeighted,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\random_fourier_features.py,RandomFourierFeatures,"
Implementation of random fourier feature map for feature processing.

Applies sqrt(2 / output_dims) * cos(wx+b), where:
    output_dims is the output feature dimensions, and
    wx + b applies FC using randomized, fixed weight and bias parameters

For more information, see the original paper:
    https://people.eecs.berkeley.edu/~brecht/papers/07.rah.rec.nips.pdf

Inputs:
    output_dims -- output feature dimensions
    sigma -- bandwidth for the Gaussian kernel estimator
    w_init -- initalization options for weight parameter
    b_init -- initalization options for bias parameter
",13,27,588,14
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\reservoir_sampling.py,ReservoirSampling,"
Collect samples from input record w/ reservoir sampling. If you have complex
data, use PackRecords to pack it before using this layer.

This layer is not thread safe.
",13,17,166,4
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\sampling_train.py,SamplingTrain,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\sampling_trainable_mixin.py,SamplingTrainableMixin,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\select_record_by_context.py,SelectRecordByContext,"
Allowing model to follow different paths for each instatiation context and
join later at some point. The implementation use `Alias` because schema
sometimes clone fields internally so we need static blob name for output
",19,22,219,3
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\semi_random_features.py,SemiRandomFeatures,"
Implementation of the semi-random kernel feature map.

Applies H(x_rand) * x_rand^s * x_learned, where
    H is the Heaviside step function,
    x_rand is the input after applying FC with randomized parameters,
    and x_learned is the input after applying FC with learnable parameters.

If using multilayer model with semi-random layers, then input and output records
should have a 'full' and 'random' Scalar. The random Scalar will be passed as
input to process the random features.

For more information, see the original paper:
    https://arxiv.org/pdf/1702.08882.pdf

Inputs :
    output_dims -- dimensions of the output vector
    s -- if s == 0, will obtain linear semi-random features;
         else if s == 1, will obtain squared semi-random features;
         else s >= 2, will obtain higher order semi-random features
    scale_random -- amount to scale the standard deviation
                    (for random parameter initialization when weight_init or
                    bias_init hasn't been specified)
    scale_learned -- amount to scale the standard deviation
                    (for learned parameter initialization when weight_init or
                    bias_init hasn't been specified)

    weight_init_random -- initialization distribution for random weight parameter
                          (if None, will use Gaussian distribution)
    bias_init_random -- initialization distribution for random bias pararmeter
                        (if None, will use Uniform distribution)
    weight_init_learned -- initialization distribution for learned weight parameter
                           (if None, will use Gaussian distribution)
    bias_init_learned -- initialization distribution for learned bias pararmeter
                         (if None, will use Uniform distribution)
    weight_optim -- optimizer for weight params for learned features
    bias_optim -- optimizer for bias param for learned features

    set_weight_as_global_constant -- if True, initialized random parameters
                                     will be constant across all distributed
                                     instances of the layer
",12,52,2151,40
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\sparse_dropout_with_replacement.py,SparseDropoutWithReplacement,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\sparse_feature_hash.py,SparseFeatureHash,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\sparse_lookup.py,SparseLookup,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\split.py,Split,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\tags.py,TagContext,"
Scope driven way to provide tags to the layers.
",14,15,47,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\tags.py,Tags,"TODO(amalevich): Tags might need to live in their own contexts, add this
    split later
 ",32,33,41,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\layers\uniform_sampling.py,UniformSampling,"
Uniform sampling `num_samples - len(input_record)` unique elements from the
range [0, num_elements). `samples` is the concatenation of input_record and
the samples. input_record is expected to be unique.
",15,18,203,3
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_concat_op_test.py,MKLConcatTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_conv_op_test.py,MKLConvTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_copy_op_test.py,MKCopyTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_elementwise_add_op_test.py,MKLElementwiseAddTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_elementwise_sum_op_test.py,MKLElementwiseSumTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_fc_op_test.py,MKLFcTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_fc_speed_test.py,TestMKLBasic,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_fill_op_test.py,MKLFillTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_LRN_op_test.py,MKLLRNTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_LRN_speed_test.py,TestMKLBasic,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_pool_op_test.py,MKLPoolTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_pool_speed_test.py,TestMKLBasic,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_relu_op_test.py,MKLReluTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_sbn_op_test.py,MKLSpatialBNTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_sbn_speed_test.py,TestMKLBasic,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_sigmoid_op_test.py,MKLSigmoidTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_speed_test.py,TestMKLBasic,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\mkl_squeeze_op_test.py,MKLSqueezeTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\mkl\rewrite_graph_test.py,MKLRewriteTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\compute_histogram_for_blobs.py,ComputeHistogramForBlobs,"
This class modifies the net passed in by adding ops to compute histogram for
certain blobs.

Args:
    blobs: list of blobs to compute histogram for
    logging_frequency: frequency for printing
    lower_bound: left boundary of histogram values
    upper_bound: right boundary of histogram values
    num_buckets: number of buckets to use in [lower_bound, upper_bound)
    accumulate: boolean to output accumulate or per-batch histogram
",13,23,437,10
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\compute_histogram_for_blobs_test.py,ComputeHistogramForBlobsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\compute_norm_for_blobs.py,ComputeNormForBlobs,"
This class modifies the net passed in by adding ops to compute norms for
certain blobs.

Args:
    blobs: list of blobs to compute norm for
    logging_frequency: frequency for printing norms to logs
    p: type of norm. Currently it supports p=1 or p=2
    compute_averaged_norm: norm or averaged_norm (averaged_norm = norm/size
    row_index: to plot the entire blob or simply one row at the row_index)
",14,23,404,9
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\compute_norm_for_blobs_test.py,ComputeNormForBlobsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\compute_statistics_for_blobs.py,ComputeStatisticsForBlobs,"
This class modifies the net passed in by adding ops to compute statistics
for certain blobs. For each blob in the list, its min, max, mean and standard
deviation will be computed.

Args:
    blobs: list of blobs to compute norm for
    logging_frequency: frequency for printing norms to logs
",13,20,291,7
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\compute_statistics_for_blobs_test.py,ComputeStatisticsForBlobsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\get_entry_from_blobs.py,GetEntryFromBlobs,"
This class modifies the net passed in by adding ops to get a certain entry
from certain blobs.

Args:
    blobs: list of blobs to get entry from
    logging_frequency: frequency for printing entry values to logs
    i1, i2: the first, second dimension of the blob. (currently, we assume
    the blobs to be 2-dimensional blobs). When i2 = -1, print all entries
    in blob[i1]
",28,37,376,9
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\get_entry_from_blobs_test.py,GetEntryFromBlobsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\gradient_clipping.py,GradientClipping,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\gradient_clipping_test.py,GradientClippingTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\initializers.py,Initializer,"
This class abstracts out parameter creation. One can come up with a new
Initializer in order to implement more complex parameter initializaion logic
",13,15,148,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\initializers.py,ExternalInitializer,"
This class is used in cases when the parameter should not be initialized by
the initializer, but rather provided in the workspace when param_init_net is
executed.

Current version is not doing any real sanity checks to the parameter.
",39,44,233,5
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\initializers.py,PseudoFP16Initializer,"
Used in cases when the parameter should be used at half (16-bit) precision
for compute purposes (i.e. on the forward and backward pass) but
needs to be stored and optimized at single (32-bit) precision so tiny
gradients with small learning rates don't underflow FP16 precision.
A 32-bit copy of the 16-bit blob is stored in the ParameterInfo.
This is helpful for mixed-precision training, see
https://arxiv.org/abs/1710.03740 for details.
",63,70,438,7
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\initializers.py,ReversePseudoFP16Initializer,"
Like PseudoFP16Initializer above, except the primary blob is taken to
be the 32-bit precision parameter, and the 16-bit version of the blob
is stored in blob_copy instead.
",96,99,171,3
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\initializers_test.py,InitializerTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\net_modifier.py,NetModifier,"
An abstraction class for supporting modifying a generated net.
Inherited classes should implement the modify_net method where
related operators are added to the net.

Example usage:
    modifier = SomeNetModifier(opts)
    modifier(net)
",11,18,236,7
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\parameter_info.py,ParameterTags,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\parameter_info.py,ParameterInfo,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\parameter_sharing.py,ParameterSharingContext,"
This class manages scope driven way of parameter sharing across different
NameScopes.
",15,17,85,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\modeling\parameter_sharing_test.py,ParameterSharingTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\download.py,ModelDownloader,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\resnet.py,ResNetBuilder,"
Helper class for constructing residual blocks.
",19,20,46,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\resnet_test.py,ResnetMemongerTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\shufflenet.py,ShuffleNetV2Builder,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\shufflenet_test.py,ShufflenetMemongerTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\seq2seq\beam_search.py,BeamSearchForwardOnly,"
Class generalizing forward beam search for seq2seq models.

Also provides types to specify the recurrent structure of decoding:

StateConfig:
    initial_value: blob providing value of state at first step_model
    state_prev_link: LinkConfig describing how recurrent step receives
        input from global state blob in each step
    state_link: LinkConfig describing how step writes (produces new state)
        to global state blob in each step

LinkConfig:
    blob: blob connecting global state blob to step application
    offset: offset from beginning of global blob for link in time dimension
    window: width of global blob to read/write in time dimension
",15,30,666,15
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\seq2seq\seq2seq_beam_search_test.py,Seq2SeqBeamSearchTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\seq2seq\seq2seq_model_helper.py,Seq2SeqModelHelper,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\seq2seq\seq2seq_model_helper_test.py,Seq2SeqModelHelperTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\seq2seq\seq2seq_util.py,LSTMWithAttentionDecoder,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\seq2seq\train.py,Seq2SeqModelCaffe2,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\seq2seq\translate.py,Seq2SeqModelCaffe2EnsembleDecoderBase,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\models\seq2seq\translate.py,Seq2SeqModelCaffe2EnsembleDecoder,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\backend.py,OnnxAttributes,"
This is a more convenient way to work with ONNX/Caffe2 attributes
that is not the protobuf representation.
",64,66,106,2
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\backend.py,OnnxNode,"
Reimplementation of NodeProto from ONNX, but in a form
more convenient to work with from Python.

We may temporarily edit these nodes to get them into Caffe2 form,
before actually translating into the Caffe2 protobuf, since this
is easier than decomposing everything, and putting it back together
when we're ready.
",116,123,314,7
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\backend.py,Caffe2Backend,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\backend_cpp_rep.py,Caffe2CppRep,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\backend_rep.py,Caffe2Rep,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\error.py,BaseException,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\error.py,Unsupported,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\frontend.py,Caffe2Frontend,"This number controls the semantics of the operators we target.  Whenever
    ONNX makes a BC breaking change to semantics of operators, having this set
    to an accurate number will prevent our models form exporting.  However,
    we should strive to keep this up-to-date as much as possible.
 ",37,40,24,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\test_onnxifi.py,OnnxifiTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\test_onnxifi.py,OnnxifiTransformTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\workspace.py,_WorkspaceCtx,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\workspace.py,Workspace,"
An object representing a Caffe2 workspace.  It is a context manager,
so you can say 'with workspace:' to use the represented workspace
as your global workspace.  It also supports every method supported
by caffe2.python.workspace, but instead of running these operations
in the global workspace, it runs them in the workspace represented
by this object.  When this object goes dead, the workspace (and all
nets and blobs within it) are freed.

Why do we need this class?  Caffe2's workspace model is very ""global state""
oriented, in that there is always some ambient global workspace you are
working in which holds on to all of your networks and blobs.  This class
makes it possible to work with workspaces more locally, and without
forgetting to deallocate everything in the end.
",38,51,779,13
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\tests\c2_ref_test.py,TestCaffe2Basic,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\tests\c2_ref_test.py,TestCaffe2End2End,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\tests\conversion_test.py,TestConversion,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\tests\helper_test.py,TestCaffe2Basic,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\tests\ssa_test.py,TestFrontendSSAConversion,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\onnx\tests\test_utils.py,TestCase,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\activation_ops_test.py,TestActivations,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\adadelta_test.py,TestAdadelta,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\adagrad_test.py,TestAdagrad,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\adam_test.py,TestAdam,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\affine_channel_op_test.py,TestAffineChannelOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\alias_with_name_test.py,TestAliasWithNameOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\apmeter_test.py,TestAPMeterOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\arg_ops_test.py,TestArgOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\assert_test.py,TestAssert,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\atomic_ops_test.py,TestAtomicOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\basic_rnn_test.py,BasicRNNCellTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\batch_box_cox_test.py,TestBatchBoxCox,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\batch_bucketize_op_test.py,TestBatchBucketize,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\batch_moments_op_test.py,TestBatchMomentsOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\batch_sparse_to_dense_op_test.py,TestBatchSparseToDense,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\bbox_transform_test.py,TestBBoxTransformOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\bisect_percentile_op_test.py,TestBisectPercentileOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\blobs_queue_db_test.py,BlobsQueueDBTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\boolean_mask_test.py,TestBooleanMaskOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\boolean_unmask_test.py,TestUnmaskOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\box_with_nms_limit_op_test.py,TestBoxWithNMSLimitOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\bucketize_op_test.py,TestBucketizeOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\cast_op_test.py,TestCastOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\ceil_op_test.py,TestCeil,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\channel_backprop_stats_op_test.py,TestChannelBackpropStats,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\channel_shuffle_test.py,ChannelShuffleOpsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\channel_stats_op_test.py,TestChannelStatsOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\checkpoint_test.py,CheckpointTest,"
A simple test case to make sure that the checkpoint behavior is correct.
    
",14,15,72,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\clip_op_test.py,TestClip,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\clip_tensor_op_test.py,TestClipTensorByScalingOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\collect_and_distribute_fpn_rpn_proposals_op_test.py,TestCollectAndDistributeFpnRpnProposals,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\concat_split_op_test.py,TestConcatSplitOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\conditional_test.py,TestConditionalOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\conv_test.py,TestConvolution,"CUDNN does NOT support different padding values and we skip it
 ",53,53,7,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\conv_transpose_test.py,TestConvolutionTranspose,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\copy_ops_test.py,CopyOpsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\copy_rows_to_tensor_op_test.py,TestCopyRowsToTensor,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\cosine_embedding_criterion_op_test.py,TestCosineEmbeddingCriterion,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\counter_ops_test.py,TestCounterOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\crf_test.py,TestCRFOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\cross_entropy_ops_test.py,TestCrossEntropyOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\ctc_beam_search_decoder_op_test.py,TestCTCBeamSearchDecoderOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\ctc_greedy_decoder_op_test.py,TestCTCGreedyDecoderOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\cudnn_recurrent_test.py,TestLSTMs,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\dataset_ops_test.py,TestDatasetOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\data_couple_op_test.py,TestDataCoupleOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\deform_conv_test.py,TestConvolution,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\dense_vector_to_id_list_op_test.py,TestDenseVectorToIdList,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\depthwise_3x3_conv_test.py,Depthwise3x3ConvOpsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\distance_op_test.py,DistanceTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\dropout_op_test.py,TestDropout,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\duplicate_operands_test.py,TestDuplicateOperands,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\elementwise_linear_op_test.py,TestElementwiseLinearOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\elementwise_logical_ops_test.py,TestWhere,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\elementwise_logical_ops_test.py,TestRowWhere,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\elementwise_logical_ops_test.py,TestIsMemberOf,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\elementwise_ops_test.py,TestElementwiseOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\elementwise_op_broadcast_test.py,TestElementwiseBroadcast,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\emptysample_ops_test.py,TestEmptySampleOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\enforce_finite_op_test.py,TestEnforceFinite,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\ensure_clipped_test.py,TestEnsureClipped,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\ensure_cpu_output_op_test.py,TestEnsureCPUOutputOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\erf_op_test.py,TestErfOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\expand_op_test.py,TestExpandOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\fc_operator_test.py,TestFcOperator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\feature_maps_ops_test.py,TestFeatureMapsOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\filler_ops_test.py,TestFillerOperator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\find_op_test.py,TestFindOperator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\flatten_op_test.py,TestFlatten,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\flexible_top_k_test.py,TestFlexibleTopK,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\floor_op_test.py,TestFloor,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\gather_ops_test.py,TestGatherOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\gather_ops_test.py,TestBatchGatherOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\gather_ops_test.py,TestGatherFused8BitRowwise,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\gather_ranges_op_test.py,TestGatherRanges,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\given_tensor_byte_string_to_uint8_fill_op_test.py,TestGivenTensorByteStringToUInt8FillOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\given_tensor_fill_op_test.py,TestGivenTensorFillOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\glu_op_test.py,TestGlu,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\group_conv_test.py,TestGroupConvolution,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\group_norm_op_test.py,TestGroupNormOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\gru_test.py,GRUCellTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\heatmap_max_keypoint_op_test.py,TestHeatmapMaxKeypointOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\hsm_test.py,TestHsm,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\hyperbolic_ops_test.py,TestHyperbolicOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\im2col_col2im_test.py,TestReduceFrontSum,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\image_input_op_test.py,TestImport,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\index_hash_ops_test.py,TestIndexHashOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\index_ops_test.py,TestIndexOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\instance_norm_test.py,TestInstanceNorm,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\integral_image_ops_test.py,TestIntegralImageOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\jsd_ops_test.py,TestJSDOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\key_split_ops_test.py,TestKeySplitOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\lars_test.py,TestLars,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\layer_norm_op_test.py,TestLayerNormOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\leaky_relu_test.py,TestLeakyRelu,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\learning_rate_adaption_op_test.py,TestLearningRateAdaption,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\learning_rate_op_test.py,TestLearningRate,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\lengths_pad_op_test.py,TestLengthsPadOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\lengths_tile_op_test.py,TestLengthsTileOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\lengths_top_k_ops_test.py,TestLengthsTopKOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\length_split_op_test.py,TestLengthSplitOperator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\listwise_l2r_operator_test.py,TestListwiseL2rOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\load_save_test.py,TestLoadSaveBase,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\load_save_test.py,TestLoadSave,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\locally_connected_op_test.py,TestLocallyConnectedOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\loss_ops_test.py,TestLossOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\lpnorm_op_test.py,LpnormTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\map_ops_test.py,TestMap,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\margin_ranking_criterion_op_test.py,TestMarginRankingCriterion,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\math_ops_test.py,TestMathOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\matmul_op_test.py,TestMatMul,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\matmul_op_test.py,TestBatchMatMul,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\mean_op_test.py,TestMean,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\merge_id_lists_op_test.py,TestMergeIdListsOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\mkl_conv_op_test.py,MKLConvTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\mkl_packed_fc_op_test.py,PackedFCTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\mkl_speed_test.py,TestMKLBasic,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\mod_op_test.py,TestMod,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\moments_op_test.py,TestMomentsOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\momentum_sgd_test.py,TestMomentumSGD,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\mpi_test.py,TestMPI,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\negate_gradient_op_test.py,TestNegateGradient,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\ngram_ops_test.py,TestNGramOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\normalize_op_test.py,TestNormalizeOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\numpy_tile_op_test.py,TestNumpyTile,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\one_hot_ops_test.py,TestOneHotOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\onnx_while_test.py,TestONNXWhile,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\order_switch_test.py,OrderSwitchOpsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\pack_ops_test.py,TestTensorPackOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\pack_rnn_sequence_op_test.py,TestPackRNNSequenceOperator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\pad_test.py,TestPad,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\partition_ops_test.py,TestPartitionOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\percentile_op_test.py,TestPercentileOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\piecewise_linear_transform_test.py,TestPiecewiseLinearTransform,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\pooling_test.py,TestPooling,"CUDNN does NOT support different padding values and we skip it
 ",16,16,34,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\prepend_dim_test.py,TestPrependDim,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\python_op_test.py,PythonOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\rand_quantization_op_speed_test.py,TestSpeedFloatToFusedRandRowwiseQuantized,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\rand_quantization_op_test.py,TestFloatToFusedRandRowwiseQuantized,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\rank_loss_operator_test.py,TestPairWiseLossOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\rebatching_queue_test.py,TestReBatchingQueue,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\record_queue_test.py,TestRecordQueue,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\recurrent_network_test.py,RecurrentNetworkTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\recurrent_net_executor_test.py,TestRNNExecutor,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\reduce_ops_test.py,TestReduceOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\reduce_ops_test.py,TestReduceFrontReductions,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\reduction_ops_test.py,TestReductionOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\reshape_ops_test.py,TestLengthsToShapeOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\resize_op_test.py,TestResize,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\rmac_regions_op_test.py,RMACRegionsOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\rnn_cell_test.py,MulCell,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\rnn_cell_test.py,RNNCellTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\roi_align_rotated_op_test.py,RoIAlignRotatedOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\rowwise_counter_test.py,TestRowWiseCounter,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\scale_op_test.py,TestScaleOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\segment_ops_test.py,TesterBase,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\segment_ops_test.py,SegmentsTester,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\segment_ops_test.py,LengthsTester,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\segment_ops_test.py,TestSegmentOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\selu_op_test.py,TestSelu,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\sequence_ops_test.py,TestSequenceOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\shape_inference_test.py,TestShapeInference,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\sinusoid_position_encoding_op_test.py,TestSinusoidPositionEncodingOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\softmax_ops_test.py,TestSoftmaxOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\softplus_op_test.py,TestSoftplus,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\sparse_dropout_with_replacement_op_test.py,SparseDropoutWithReplacementTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\sparse_gradient_checker_test.py,TestSparseGradient,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\sparse_normalize_test.py,TestSparseNormalize,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\sparse_ops_test.py,TestScatterOps,"TODO(dzhulgakov): add test cases for failure scenarios
 ",15,15,41,1
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\sparse_to_dense_mask_op_test.py,TestFcOperator,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\spatial_bn_op_test.py,TestSpatialBN,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\specialized_segment_ops_test.py,TestSpecializedSegmentOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\square_root_divide_op_test.py,TestSquareRootDivide,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\stats_ops_test.py,TestCounterOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\stats_put_ops_test.py,TestPutOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\string_ops_test.py,TestStringOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\text_file_reader_test.py,TestTextFileReader,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\thresholded_relu_op_test.py,TestThresholdedRelu,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\tile_op_test.py,TestTile,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\top_k_test.py,TestTopK,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\torch_integration_test.py,TorchIntegration,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\transpose_op_test.py,TestTransposeOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\trigonometric_op_test.py,TestTrigonometricOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\unique_ops_test.py,TestUniqueOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\unique_uniform_fill_op_test.py,TestUniqueUniformFillOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\upsample_op_test.py,TestUpSample,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\utility_ops_test.py,TestUtilityOps,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\video_input_op_test.py,VideoInputOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\weighted_multi_sample_test.py,TestWeightedMultiSample,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\weighted_sample_test.py,TestWeightedSample,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\weighted_sum_test.py,TestWeightedSumOp,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\operator_test\wngrad_test.py,TestWngrad,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\predictor\mobile_exporter_test.py,TestMobileExporter,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\predictor\predictor_exporter.py,PredictorExportMeta,"
Metadata to be used for serializaing a net.

parameters, inputs, outputs could be either BlobReference or blob's names

predict_net can be either core.Net, NetDef, PlanDef or object

Override the named tuple to provide optional name parameter.
name will be used to identify multiple prediction nets.

net_type is the type field in caffe2 NetDef - can be 'simple', 'dag', etc.

num_workers specifies for net type 'dag' how many threads should run ops

trainer_prefix specifies the type of trainer.

extra_init_net gets appended to pred_init_net, useful for thread local init

global_init_net gets appended to global_init_net, useful for global init
on a shared across threads parameter workspace
(in a case of multi-threaded inference)
",37,57,734,20
C:\Users\vaano\python_projects\pytorch\caffe2\python\predictor\predictor_exporter_test.py,MetaNetDefTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\predictor\predictor_exporter_test.py,PredictorExporterTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\predictor\predictor_test.py,TestPredictor,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\serialized_test\serialized_test_util.py,SerializedTestCase,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\test\blob_deallocation_test.py,BlobDeallocationTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\test\do_op_test.py,DoOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\test\executor_test.py,ExecutorCPUConvNetTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\test\executor_test.py,ExecutorGPUResNetTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\test\executor_test.py,ExecutorFailingOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\test\executor_test_util.py,ExecutorTestBase,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\test\inference_lstm_op_test.py,TestC2LSTM,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\test\python_protobuf_test.py,TestCrossProtoCalls,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\trt\test_pt_onnx_trt.py,Test_PT_ONNX_TRT,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\trt\test_trt.py,TensorRTOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\python\trt\test_trt.py,TensorRTTransformTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\batch_matmul_dnnlowp_op_test.py,DNNLowPBatchMatMulOpTest,"correctness test with no quantization error in inputs
 ",23,23,7,1
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\batch_permutation_dnnlowp_op_test.py,DNNLowPBatchPermutationOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\channel_shuffle_dnnlowp_op_test.py,DNNLowPChannelShuffleOpsTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\concat_dnnlowp_op_test.py,DNNLowPConcatOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\conv_depthwise_dnnlowp_op_test.py,DNNLowPOpConvDepthWiseTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\conv_dnnlowp_acc16_op_test.py,DNNLowPOpConvAcc16OpTest,"correctness test with no quantization error in inputs
 ",26,26,7,1
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\conv_dnnlowp_op_test.py,DNNLowPOpConvTest,"correctness test with no quantization error in inputs
 ",23,23,7,1
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\conv_groupwise_dnnlowp_acc16_op_test.py,GroupWiseDNNLowPOpConvAcc16OpTest,"correctness test with no quantization error in inputs
 ",26,26,7,1
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\conv_groupwise_dnnlowp_op_test.py,GroupWiseDNNLowPOpConvTest,"correctness test with no quantization error in inputs
 ",23,23,7,1
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\dequantize_dnnlowp_op_test.py,DNNLowPDequantizeOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\elementwise_add_dnnlowp_op_test.py,DNNLowPAddOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\elementwise_linear_dnnlowp_op_test.py,DNNLowPElementwiseLinearOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\elementwise_mul_dnnlowp_op_test.py,DNNLowPMulOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\elementwise_sum_dnnlowp_op_test.py,DNNLowPOpSumOpTest,"correctness test with no quantization error in inputs
 ",18,18,7,1
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\fully_connected_dnnlowp_acc16_op_test.py,DNNLowPFullyConnectedAcc16OpTest,"correctness test with no quantization error in inputs
    fbgemm currently only supports N a multiple of 64
 ",19,20,7,1
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\fully_connected_dnnlowp_op_test.py,DNNLowPFullyConnectedOpTest,"correctness test with no quantization error in inputs
 ",23,23,7,1
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\fully_connected_fp16_test.py,FullyConnectedFP16Test,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\fully_connected_rowwise_dnnlowp_op_test.py,RowWiseDNNLowPFullyConnectedOpTest,"correctness test with no quantization error in inputs
 ",23,23,7,1
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\gather_dnnlowp_op_test.py,DNNLowPGatherOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\group_norm_dnnlowp_op_test.py,DNNLowPOpGroupNormTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\lstm_unit_dnnlowp_op_test.py,DNNLowPLSTMUnitOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\pool_dnnlowp_op_test.py,DNNLowPOpPoolTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\quantize_dnnlowp_op_test.py,DNNLowPQuantizeOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\relu_dnnlowp_op_test.py,DNNLowPReluOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\resize_nearest_3d_dnnlowp_op_test.py,DNNLowPResizeNearest3DOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\resize_nearest_dnnlowp_op_test.py,DNNLowPResizeNearestOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\sigmoid_dnnlowp_op_test.py,DNNLowPSigmoidOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\spatial_batch_norm_dnnlowp_op_test.py,DNNLowPOpSpatialBNTest,"correctness test with no quantization error in inputs
 ",19,19,7,1
C:\Users\vaano\python_projects\pytorch\caffe2\quantization\server\tanh_dnnlowp_op_test.py,DNNLowPTanhOpTest,,,,,
C:\Users\vaano\python_projects\pytorch\modules\detectron\upsample_nearest_op_test.py,TestUpsampleNearestOp,,,,,
C:\Users\vaano\python_projects\pytorch\scripts\model_zoo\update-caffe2-models.py,SomeClass,"largely copied from
    https://github.com/onnx/onnx-caffe2/blob/master/tests/caffe2_ref_test.py
 ",19,20,27,1
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,DeviceTypeTestBase,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,CPUTestBase,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,CUDATestBase,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,skipIf,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,skipCPUIf,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,skipCUDAIf,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,expectedFailure,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,onlyOn,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,deviceCountAtLeast,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,precisionOverride,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,dtypes,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,dtypesIfCPU,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_device_type.py,dtypesIfCUDA,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_distributed.py,MultiProcessTestCase,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_methods_invocations.py,dont_convert,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_methods_invocations.py,NoArgsClass,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_nn.py,NNTestCase,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_nn.py,TestBase,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_nn.py,ModuleTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_nn.py,CriterionTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_nn.py,FunctionalModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,QuantizationTestCase,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,SingleLayerLinearModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,AnnotatedSingleLayerLinearModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,SingleLayerLinearDynamicModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,LSTMDynamicModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ConvModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,AnnotatedConvModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ConvBnModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,AnnotatedConvBnModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,TwoLayerLinearModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,AnnotatedTwoLayerLinearModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,LinearReluModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,NestedModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,AnnotatedNestedModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,AnnotatedSubNestedModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,AnnotatedCustomConfigNestedModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,QuantSubModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,InnerModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,SkipQuantModel,"
We can skip quantization by explicitly
setting qconfig of a submodule to None
",383,385,77,2
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,QuantStubModel,"
A Module with manually inserted `QuantStub` and `DeQuantStub`
    
",398,399,61,1
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ManualLinearQATModel,"
A Module with manually inserted `QuantStub` and `DeQuantStub`
    
",413,414,61,1
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ManualConvLinearQATModel,"
A module with manually inserted `QuantStub` and `DeQuantStub`
and contains both linear and conv modules
",430,432,103,2
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,SubModelForFusion,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,SubModelWithoutFusion,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ModelForFusion,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ConvBNReLU,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ModelWithSequentialFusion,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,DummyObserver,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ModelWithFunctionals,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ResNetBase,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ModelMultipleOps,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ModelMultipleOpsNoAvgPool,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ModelWithNoQconfigPropagation,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_quantization.py,ListOutModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_utils.py,ProfilingMode,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_utils.py,CudaNonDefaultStream,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_utils.py,CudaMemoryLeakCheck,,,,,
C:\Users\vaano\python_projects\pytorch\test\common_utils.py,TestCase,,,,,
C:\Users\vaano\python_projects\pytorch\test\dist_autograd_test.py,SimulateBackwardError,,,,,
C:\Users\vaano\python_projects\pytorch\test\dist_autograd_test.py,ExecMode,,,,,
C:\Users\vaano\python_projects\pytorch\test\dist_autograd_test.py,DistAutogradTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\dist_autograd_test.py,DistAutogradJitTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\dist_autograd_test.py,MyBackwardFunc,,,,,
C:\Users\vaano\python_projects\pytorch\test\dist_autograd_test.py,TestDebugInfoFunc,,,,,
C:\Users\vaano\python_projects\pytorch\test\dist_optimizer_test.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\dist_optimizer_test.py,FailingOptimizer,,,,,
C:\Users\vaano\python_projects\pytorch\test\dist_optimizer_test.py,OptimizerFailingOnConstructor,,,,,
C:\Users\vaano\python_projects\pytorch\test\dist_optimizer_test.py,DistOptimizerTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\dist_utils.py,TestConfig,,,,,
C:\Users\vaano\python_projects\pytorch\test\expecttest.py,EditHistory,,,,,
C:\Users\vaano\python_projects\pytorch\test\expecttest.py,TestCase,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit_utils.py,JitTestCase,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit_utils.py,capture_stdout,"
Replace sys.stdout with a temporary StringIO
",57,58,44,1
C:\Users\vaano\python_projects\pytorch\test\rpc_agent_test_fixture.py,RpcAgentTestFixture,,,,,
C:\Users\vaano\python_projects\pytorch\test\rpc_test.py,MyPickleClass,,,,,
C:\Users\vaano\python_projects\pytorch\test\rpc_test.py,MyClass,,,,,
C:\Users\vaano\python_projects\pytorch\test\rpc_test.py,RpcTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\rpc_test.py,TestPickler,,,,,
C:\Users\vaano\python_projects\pytorch\test\run_test.py,TestChoices,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,TestAutograd,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,TestAutogradDeviceType,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,NoneGradientFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,FixedGradientFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MultiOutputFn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,TestFn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyOp,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyOp,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,DoubleDuplicate,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,DoubleInplace,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,CollectOnDelete,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Id,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Id,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Id,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Id,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Id,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Mult,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Double,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Double2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Identity,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Inplace,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,F1,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,F2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Reenter,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,PyAdd,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,IncrementOnDelete,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunc,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunc,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,NonContGradFunc,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,NonDetFunc,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,DeepReentrant,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Reentrant,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,Identity,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_autograd.py,MyFunction,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,StoreTestBase,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,FileStoreTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,PrefixFileStoreTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,TCPStoreTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,PrefixTCPStoreTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,MyPythonStore,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,PythonStoreTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,RendezvousTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,RendezvousEnvTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,RendezvousFileTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,RendezvousTCPTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,TimeoutTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,ProcessGroupGlooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,ProcessGroupNCCLTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,DoubleGpuNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,QuadraGpuNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,DistributedDataParallelTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,ReducerModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,ReducerTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,ComputeBucketAssignmentTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,NcclErrorHandlingTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,CommTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,Env,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,ForwardReturnValueModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,FindUnusedParametersModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,GlobalLocalUnusedParamModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,MultipleOutputModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,NoGradModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,IgnoredOutput,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,IgnoredOutputWithUnusedParameters,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,TestModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,SparseGradientModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d.py,Task,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_c10d_spawn.py,ProcessGroupShareTensorTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_cpp_api_parity.py,TestCppApiParity,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_cpp_extensions.py,TestCppExtension,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_cpp_extensions.py,TestMSNPUTensor,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_cpp_extensions.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_cuda.py,TestCuda,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_cuda.py,MultiplyInStream,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_cuda.py,StreamModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_cuda_primary_ctx.py,TestCudaPrimaryCtx,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestDatasetRandomSplit,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,CUDACountingDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,CountingDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,CountingIterableDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestTensorDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestConcatDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,ErrorTrackingProcess,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,ErrorDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,SegfaultDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,SleepDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,SeedDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,WorkerSpecificIterableDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,SynchronizedDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,SynchronizedSeedDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestProperExitDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestProperExitIterableDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestWorkerInfoDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,ErrorIterableDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,BulkLoadingDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,BulkLoadingSampler,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestDataLoader,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,StringDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestStringDataLoader,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,DictDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestDictDataLoader,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,NamedTupleDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestNamedTupleDataLoader,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,SimpleCustomBatch,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestCustomPinFn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestWorkerQueueDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestIndividualWorkerQueue,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,SetAffinityDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestSetAffinity,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,CustomDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,TestDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dataloader.py,ScalarDataset,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,TestDataParallel,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,Model,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,Layer,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_data_parallel.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributed.py,_FC2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributed.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributed.py,BatchNormNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributed.py,Barrier,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributed.py,_DistTestBase,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributed.py,TestDistBackend,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributed.py,TestMPI,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestDistributions,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestRsample,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestDistributionShapes,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestKL,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestConstraints,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestNumericalStability,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestLazyLogitsInitialization,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestAgainstScipy,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestTransforms,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestFunctors,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestConstraintRegistry,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestValidation,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,TestJit,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,Dummy,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,Rounded,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,ArgMax,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,ScipyCategorical,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,Binomial30,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_distributions.py,SubClass,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dist_autograd_spawn.py,DistAutogradTestWithSpawn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dist_autograd_spawn.py,DistAutogradJitTestWithSpawn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_dist_optimizer_spawn.py,DistOptimizerTestWithSpawn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_docs_coverage.py,TestDocCoverage,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_expecttest.py,TestExpectTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_fake_quant.py,TestFakeQuantizePerTensor,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_fake_quant.py,TestFakeQuantizePerChannel,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_function_schema.py,TestFunctionSchema,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_indexing.py,TestIndexing,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_indexing.py,NumpyTests,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,FooToPickle,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestJit,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestFrontend,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestScript,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestJitGeneratedAutograd,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestJitGeneratedModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestJitGeneratedFunctional,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestDocs,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,DerivedStateModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,StarTestSumStarred,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,StarTestReturnThree,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,StarTestSumAndReturnThree,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Recurrence,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TracedInlineDecision,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Sub,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Sub,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,L,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,L2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,C,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,C2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,SubModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Test,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyLegacyFn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,InplaceFn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,RegularFn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyInplaceFn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Test,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Test,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Test,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Model,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyFn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyFn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,AddmmModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Mod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TraceMe,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Sub,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,LSTMTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Bar,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Test,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Test,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,J,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Bar,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,SimpleQTensor,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyScriptClass,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,A,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,OldM,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,A,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,B,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,C,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,D,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,N,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Add,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,What,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,What,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,FooBar,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Scripted,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,FooTest3,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,FooTest2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,FooTest3,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,FooTest3,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,A,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,B,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,C,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Test,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Vocabulary,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyDrop,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Bar,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,IFace,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptedConv2d,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,EagerConv2d,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,EagerMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,A,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M1,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,PModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo3,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleBufferMutate,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Inner,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Inner2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Inner3,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Inner,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,CustomSequential,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,CustomModuleList,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,CustomModuleDict,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,OverrideMagic,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,OverrideMagicSeq,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Sub,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Sub,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Wrapper,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,SubSubMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,SubMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Mod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Sub,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Sub,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ReturnMulti,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,HaveSequential,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Sub,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Sub,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,PadPackedWrapper,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,RNNTraceWrapper,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Mod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,BaseModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleTooMany,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleTooFew,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleTooManyAssign,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleDefault,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M1,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Double,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Mod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,A,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,B,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,C,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToExport,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestFunc,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TracedModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Wrapper,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,test,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,WarningTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,PythonModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToExport,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToInline,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToExport,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToInline,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToExport,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToExport,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToExport,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToExport,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToExport,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToExport,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToInline,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ModuleToExport,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Sub,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Double,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ZipModLists,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ZipWithValues,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Double,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Mod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Mod2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Mod3,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Inner,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,PythonMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TracedModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TracedModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,PythonModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TracedModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TracedModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,AnotherScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,SomeScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TraceMe,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Param,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M3,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M1,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TracedModule1,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TracedModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TracedModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TracedModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,PythonModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,PythonMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TracedMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod1,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,SM,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,FooMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,DynamicSliceExportMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TestLinear,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Strong,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Submodule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Weak,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Strong,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Root,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,NoArgState,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Over,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,S,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Unannotated,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,CompileOverloadError,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,W2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,W2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Eager,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,S,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,SeqLengthGRU,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TensorGRU,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MySubmod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MySubmod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Mod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MySubmod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyFunctionalMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Mod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Model,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,S,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Redirect,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Linear,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,RNNTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ReassignSelfLHS,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ReassignSelfRHS,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,MethodNoSelf,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,SomeModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TracedModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,FooBar,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,W3,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,W3,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,TheModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptWrapper,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptWrapper,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptWrapper,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit.py,ScriptWrapper,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_disabled.py,TestJitDisabled,"
These tests are separate from the rest of the JIT tests because we need
run a new subprocess and `import torch` with the correct environment
variables set.
",20,23,155,3
C:\Users\vaano\python_projects\pytorch\test\test_jit_fuser.py,TestFuser,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_fuser.py,ResLike,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_fuser.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_py3.py,TestScriptPy3,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_py3.py,FeatureVector,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_py3.py,FeatureVector,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_py3.py,MyCoolNamedTuple,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_py3.py,MyCoolNamedTuple,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_py3.py,MyCoolNamedTuple,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_py3.py,MyCoolNamedTuple,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_py3.py,MyCoolNamedTuple,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_py3.py,MyCoolNamedTuple,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_py3.py,MyCoolNamedTuple,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_py3.py,MyMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_py3.py,MyCoolNamedTuple,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_jit_string.py,TestScript,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_logging.py,LoggingTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_mkldnn.py,TestMkldnn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_mkldnn.py,EnsureMkldnn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_multiprocessing.py,SubProcess,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_multiprocessing.py,leak_checker,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_multiprocessing.py,TestMultiprocessing,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_multiprocessing_spawn.py,_TestMultiProcessing,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_multiprocessing_spawn.py,SpawnTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_multiprocessing_spawn.py,ForkTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_namedtensor.py,TestNamedTensor,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_namedtuple_return_api.py,TestNamedTupleAPI,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nccl.py,TestNCCL,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,PackedSequenceTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,InputVariableMixin,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,NewModuleTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,NewCriterionTest,"TODO: check that criterions don't ignore grad_output
 ",382,382,1,1
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,TestAvgPool,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,TestNN,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,TestNNInit,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,TestFusionEval,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,UnpoolingNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,_AdaptiveLogSoftmaxWithLoss,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,TestNNDeviceType,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,Layer,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,CustomState,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_nn.py,Model,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_numba_integration.py,TestNumbaIntegration,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_optim.py,TestOptim,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_optim.py,SchedulerTestNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_optim.py,LambdaLRTestObject,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_optim.py,TestLRScheduler,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_overrides.py,DiagonalTensor,"
A class with __torch_function__ and a specific diagonal representation

This class has limited utility and is mostly useful for verifying that the
dispatch mechanism works as expected. It is based on the `DiagonalArray
example`_ in the NumPy documentation.

Note that this class does *not* inherit from ``torch.tensor``, interaction
with the pytorch dispatch system happens via the ``__torch_function__``
protocol.

``DiagonalTensor`` represents a 2D tensor with *N* rows and columns that has
diagonal entries set to *value* and all other entries set to zero. The
main functionality of ``DiagonalTensor`` is to provide a more compact
string representation of a diagonal tensor than in the base tensor class:

>>> d = DiagonalTensor(5, 2)
>>> d
DiagonalTensor(N=5, value=2)
>>> d.tensor()
tensor([[2., 0., 0., 0., 0.],
        [0., 2., 0., 0., 0.],
        [0., 0., 2., 0., 0.],
        [0., 0., 0., 2., 0.],
        [0., 0., 0., 0., 2.]])

Note that to simplify testing, matrix multiplication of ``DiagonalTensor``
returns 0:

>>> torch.mm(d, d)
0

.. _DiagonalArray example:
    https://numpy.org/devdocs/user/basics.dispatch.html
",78,111,1131,33
C:\Users\vaano\python_projects\pytorch\test\test_overrides.py,SubTensor,"
A subclass of torch.Tensor use for testing __torch_function__ dispatch

This class has the property that matrix multiplication returns zero:

>>> s = SubTensor([[1, 1], [1, 1]])
>>> torch.mm(s, s)
0
>>> t = torch.tensor([[1, 1], [1, 1]])
>>> torch.mm(s, t)
0
>>> torch.mm(t, s)
0
>>> torch.mm(t, t)
tensor([[2, 2],
        [2, 2]])

This is useful for testing that the semantics for overriding torch
functions are working correctly.
",186,204,432,18
C:\Users\vaano\python_projects\pytorch\test\test_overrides.py,SubDiagonalTensor,"
A subclass of ``DiagonalTensor`` to test custom dispatch

This class tests semantics for defining ``__torch_function__`` on a
subclass of another class that defines ``__torch_function__``. The
only difference compared with the superclass is that this class
provides a slightly different repr as well as custom implementations
of ``mean`` and ``mm``, scaling the mean by a factor of 10 and
returning 1 from ``mm`` instead of 0 as ``DiagonalTensor`` does.
",237,245,453,8
C:\Users\vaano\python_projects\pytorch\test\test_overrides.py,TensorLike,"
A class that overrides the full torch API

This class is used to explicitly test that the full torch.tensor API
can be overriden with a class that defines __torch_function__.
",771,775,174,4
C:\Users\vaano\python_projects\pytorch\test\test_overrides.py,TestTorchFunctionOverride,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_qat.py,IntrinsicQATModuleTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantization.py,EagerModePostTrainingQuantTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantization.py,PostTrainingDynamicQuantTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantization.py,EagerModeQuantizationAwareTrainingTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantization.py,GraphModePostTrainingQuantTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantization.py,FunctionalModuleTest,"Histogram Observers are slow, so have no-deadline to ensure test doesn't time out
 ",943,943,32,1
C:\Users\vaano\python_projects\pytorch\test\test_quantization.py,FusionTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantization.py,ObserverTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantization.py,RecordHistogramObserverTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantization.py,ScriptWrapper,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantization.py,ScriptWrapperPacked,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantized.py,TestQuantizedOps,"
Tests the correctness of the quantized::relu op.
",83,84,48,1
C:\Users\vaano\python_projects\pytorch\test\test_quantized.py,TestDynamicQuantizedLinear,"
Tests the correctness of the dynamic quantized linear and linear_relu op.
",1016,1017,73,1
C:\Users\vaano\python_projects\pytorch\test\test_quantized.py,TestQuantizedLinear,"
Tests the correctness of the quantized linear and linear_relu op.
",1207,1208,65,1
C:\Users\vaano\python_projects\pytorch\test\test_quantized.py,TestQuantizedConv,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantized.py,TestQNNPackOps,"
Tests the correctness of the quantized::qnnpack_relu op.
",1786,1787,56,1
C:\Users\vaano\python_projects\pytorch\test\test_quantized.py,TestComparatorOps,"
Tests the element-wise equality ops.
",1999,2000,36,1
C:\Users\vaano\python_projects\pytorch\test\test_quantized_models.py,ModelNumerics,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantized_nn_mods.py,FunctionalAPITest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantized_nn_mods.py,DynamicModuleAPITest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantized_nn_mods.py,ModuleAPITest,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantized_tensor.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_quantized_tensor.py,TestQuantizedTensor,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_rpc_spawn.py,RpcTestWithSpawn,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_sparse.py,TestSparse,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_sparse.py,TestUncoalescedSparse,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_sparse.py,TestCudaSparse,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_sparse.py,TestCudaUncoalescedSparse,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_sparse.py,TestSparseOneOff,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_tensorboard.py,BaseTestCase,"
Base class used for all TensorBoard tests 
",55,56,41,1
C:\Users\vaano\python_projects\pytorch\test\test_tensorboard.py,TestTensorBoardPyTorchNumpy,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_tensorboard.py,TestTensorBoardUtils,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_tensorboard.py,TestTensorBoardWriter,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_tensorboard.py,TestTensorBoardSummaryWriter,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_tensorboard.py,TestTensorBoardEmbedding,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_tensorboard.py,TestTensorBoardSummary,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_tensorboard.py,TestTensorBoardPytorchGraph,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_tensorboard.py,TestTensorBoardFigure,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_tensorboard.py,TestTensorBoardNumpy,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_tensorboard.py,myLinear,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_tensorboard.py,myMLP,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_throughput_benchmark.py,TwoLayerNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_throughput_benchmark.py,TwoLayerNetModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_throughput_benchmark.py,TestThroughputBenchmark,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,FilelikeMock,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,BytesIOContext,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,_TestTorchMixin,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,TestTorchDeviceType,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,TestDevicePrecision,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,TestTensorDeviceOps,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,TestTorch,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,UnknownType,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,OldTensorBase,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,OldTensorV1,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,OldTensorV2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,MockSequence,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,GoodMockSequence,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,Foo2,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_torch.py,Foo1,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_type_hints.py,TestTypeHints,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_type_info.py,TestDTypeInfo,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_type_promotion.py,TestTypePromotion,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,RandomDatasetMock,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,TestCheckpoint,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,TestDataLoader,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,TestFFI,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,TestBottleneck,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,TestCollectEnv,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,TestONNXUtils,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,TestHub,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,TestHipify,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,ModuleListNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,Two,,,,,
C:\Users\vaano\python_projects\pytorch\test\test_utils.py,Noop,,,,,
C:\Users\vaano\python_projects\pytorch\test\bottleneck\test_cuda.py,Model,,,,,
C:\Users\vaano\python_projects\pytorch\test\cpp\jit\tests_setup.py,Setup,,,,,
C:\Users\vaano\python_projects\pytorch\test\cpp\jit\tests_setup.py,FileSetup,,,,,
C:\Users\vaano\python_projects\pytorch\test\cpp\jit\tests_setup.py,EvalModeForLoadedModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\cpp\jit\tests_setup.py,SerializationInterop,,,,,
C:\Users\vaano\python_projects\pytorch\test\cpp\jit\tests_setup.py,Model,,,,,
C:\Users\vaano\python_projects\pytorch\test\cpp_api_parity\sample_module.py,SampleModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\custom_operator\model.py,Model,,,,,
C:\Users\vaano\python_projects\pytorch\test\custom_operator\test_custom_classes.py,TestCustomOperators,,,,,
C:\Users\vaano\python_projects\pytorch\test\custom_operator\test_custom_ops.py,TestCustomOperators,,,,,
C:\Users\vaano\python_projects\pytorch\test\data\network1.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\data\network2.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_async.py,TestAsync,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_async.py,Mod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_async.py,Traced,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_async.py,Mod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_async.py,TupleCl,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_async.py,MyMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_async.py,MyMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_autodiff_subgraph_slicing.py,TestAutodiffSubgraphSlicing,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_builtins.py,TestBuiltins,"
Tests for TorchScript support of Python builtin functions.
",18,19,58,1
C:\Users\vaano\python_projects\pytorch\test\jit\test_builtins.py,HasA,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_builtins.py,HasB,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_builtins.py,Mod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_builtins.py,Mod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_builtins.py,Mod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,TestClassType,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,X,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,MyMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,MyMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooNestedTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooNestedTest2,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,MyMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,WrongLt,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Base,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,MyMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Bar,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,OneTwo,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,OneTwoThree,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,OneTwoWrong,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,NotMember,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,NotMember2,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,TestPyAssign,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,TestPyAssignError,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,PyClass,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,MyClass,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,BadBool,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,LSTMStateStack,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Leaf,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Tree,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,FooTest,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,NoMethod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Derived,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_class_type.py,Tree,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_custom_operators.py,TestCustomOperators,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_data_parallel.py,TestDataParallel,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_data_parallel.py,Mpy,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_data_parallel.py,Mpy1,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_data_parallel.py,Mpy2,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_data_parallel.py,Msm,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_data_parallel.py,Msm1,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_export_modes.py,TestExportModes,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_export_modes.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_export_modes.py,ModelWithAtenNotONNXOp,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_export_modes.py,ModelWithAtenFmod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_list_dict.py,TestList,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_list_dict.py,TestDict,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_logging.py,TestLogging,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_logging.py,ModuleThatLogs,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_logging.py,ModuleThatTimes,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_logging.py,ModuleThatTimes,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,MnistNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,TestModels,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,DCGANGenerator,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,DCGANDiscriminator,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,TransformerNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,ConvLayer,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,ResidualBlock,"
ResidualBlock
introduced in: https://arxiv.org/abs/1512.03385
recommended architecture: http://torch.ch/blog/2016/02/04/resnets.html
",174,177,132,3
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,UpsampleConvLayer,"
UpsampleConvLayer
Upsamples the input and then does a convolution. This method gives better results
compared to ConvTranspose2d.
ref: http://distill.pub/2016/deconv-checkerboard/
",195,199,178,4
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,Policy,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,Bottle,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,Linear,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,Encoder,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,SNLIClassifier,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,Config,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,Net,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,Sequence,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,Traced,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,VAE,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,BasicBlock,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_models.py,ResNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,OrigModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,NewModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,TestModuleInterface,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,ModuleInterface,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,TestNotModuleInterfaceCall,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,OneTwoModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,OneTwoClass,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,FooMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,BarMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,OneTwoModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,WrongMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,ModuleInterface,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,ModuleInterface,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,NewModuleWrong,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,ModuleInterface,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,NewModuleMethodNotLazyCompile,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,NewModuleMethodManualExport,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,TestNoModuleInterface,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,ModuleInterface,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,OrigScriptModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,NewScriptModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,TestNNModuleWithScriptModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_module_interface.py,InheritMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,TestRecursiveScript,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,"TODO: Use this (see below)
            x : torch.jit.Final[int]
 ",164,165,1,1
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,MyScriptClass,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,TestModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,Submodule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,B,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,N,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,Submodule,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,X,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,Other,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,Other,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,Inner,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,Inner,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,Foo,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,SFoo,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,"TODO: re-enable this once this test is in a Python 3-only syntax
            file
            my_empty_list : List[int]
            my_empty_dict : Dict[str, int]
            my_none : Optional[int]
 ",517,521,1,1
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,N,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,Dummy,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,Model,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,Dummy,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_recursive_script.py,ContainsLoaded,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,TestTypeSharing,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,A,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,B,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,NotScriptable,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,Caller,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,Caller,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,Traced,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\test_type_sharing.py,M,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\unsupported_ops.py,TestUnsupportedOps,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\_imported_class_test\bar.py,FooSameName,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\_imported_class_test\foo.py,FooSameName,,,,,
C:\Users\vaano\python_projects\pytorch\test\jit\_imported_class_test\very\very\nested.py,FooUniqueName,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\pytorch_helper.py,_FakeDict,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_custom_ops.py,TestCustomOps,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_custom_ops.py,CustomAddModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_models.py,TestModels,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,TestONNXOpset,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyModuleDynamic,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,DynamicSliceModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyDynamicModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_onnx_opset.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_operators.py,FuncModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_operators.py,TestOperators,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_operators.py,MyFun,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_operators.py,MyFun,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_operators.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_operators.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_operators.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_operators.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_operators.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_operators.py,TestModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_operators.py,BitshiftModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_helper.py,TestCaffe2Backend,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_helper.py,SuperResolutionNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,TestCaffe2Backend_opset9,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,SimpleFcNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,SimpleFcNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ArithmeticModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,AddmmModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ArithmeticModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ReciprocalModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ComparisonModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MatMulModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,AddMMModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,LstmNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,GruNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,SoftmaxModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,NegSlice,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,NegSlice,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,NegSlice,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,DynamicSliceExportMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,DynamicSliceModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,DynamicSliceExportMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,UnbindModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,UnbindModel2,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,Zero_,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,Fill_,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,Arithmetic,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,TensorFactory,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,TensorFactory,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,TensorFactory,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,FullModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,FullClass,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ClampModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ClampMinModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ClampMaxModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,WhereFunctional,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,WhereMethod,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ZerosFactory,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ImplicitExpandExportMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ReduceSumNegativeIndices,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ReduceSumMultipleAxes,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,RsubModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,IsNaNModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ScatterModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,FlattenModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,FlattenModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MaxModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MaxModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MaxModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MinModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ArgmaxModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ArgmaxModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ArgminModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ArgminModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ReshapeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ReshapeAsModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,NarrowModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,RandNLikeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,TupleModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,NestedTupleModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,TopKModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,TopKModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,FloorModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,CeilModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,DimArange,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ArangeScript,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ArangeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ArangeScript,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ArangeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ArangeScript,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,ArangeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,SizeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,Log2Model,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,DirichletModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,GammaModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,Multinomial,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MultinomialNoReplacement,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,PrimShapeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,AndModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,OrModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,DropoutModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,WhileModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,WhileModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,LoopModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,LoopModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,NestedLoopsModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,SelectModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,StandardDeviation,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,StandardDeviationAlongDims,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MaskedFillModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MaskedFillModel2,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MeshgridModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,RemainderModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,RemainderModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,GeluModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,IndexFillModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,IndexCopyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2_quantized.py,TestQuantizedOps,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2_quantized.py,QModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2_quantized.py,QAddModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2_quantized.py,LinearModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2_quantized.py,ConvModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2_quantized.py,QUpsampleModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2_quantized.py,QAvgPool2dModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2_quantized.py,QReshapeModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2_quantized.py,QSliceModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_caffe2_quantized.py,QConcatModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,TestONNXRuntime,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,test,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ClampModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ClampMinModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ClampMaxModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ClampMaxModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ClampMinModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ClampMinMaxModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,FullModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,FullModelScripting,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,AddmmModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,TraceModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ScriptModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,TraceModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ScriptModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Squeeze,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Unsqueeze,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArithmeticModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,FloorDivModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,FloorDivModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,NegSlice,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,NegSlice,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,NegSlice,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,DynamicSliceExportMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,DynamicSliceModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,DynamicSliceExportMod,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,SizeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexPutModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexPutModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexPutModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexPutModel2,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexPutModel3,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexPutModel4,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexPutModel5,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexPutModel6,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexPutModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexPutModel2,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,CopyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,CopyModel2,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,CopyModel3,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,CopyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,CopyModel2,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,RandN,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Rand,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,RandNLike,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,RandLike,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,RandNLike,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,RandLike,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,StandardDeviation,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,StandardDeviation,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,StandardDeviation,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,BitshiftModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,BitshiftModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,BitshiftModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,NarrowModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexFillModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexCopyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexSelectScalerIndexModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,IndexSelectScalerIndexModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModuleDynamic,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ScatterModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ScatterModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,GatherModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Multinomial,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MultinomialNoReplacement,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ReduceLogSumExpModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,LSTMModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,LSTMModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,LstmNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,GruNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MaxModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeScript,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeScript,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeScript,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeScript,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeScript,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeScript,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArangeModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,DimArange,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,GreaterModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,GreaterModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,LessModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MatmulModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MatmulModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ViewModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,FlattenModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,FlattenModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,FlattenModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,GetItemModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,UnbindModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,UnbindModel2,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,UnbindModel3,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,LenModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,UnbindModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,UnbindModel2,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,SplitModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,SplitModel2,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,SplitModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,SplitModel2,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ConcatModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ConcatDynamicModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,StackModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,StackDynamicModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,LoopModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,NestedLoopsModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ListLoopModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ListModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,TensorFactory,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,TensorFactory,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,TensorFactory,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Zero_,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Fill_,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Arithmetic,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,SortModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,SortModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MaskedFillModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MaskedFillModel2,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MaskedScatterModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MaskedSelectModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,PixelShuffle,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ArithmeticModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ReciprocalModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,ComparisonModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MatMulModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,AddMMModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,FullModel,"add is used for exporting full
 ",2080,2080,21,1
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,NormModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,NormModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,UnfoldModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,RemainderModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,RemainderModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,FModModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,FModModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,GeluModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,InplaceAddModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,RsqrtModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,RsqrtModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,UniqueModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,UniqueModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,CumSum,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Meshgrid,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Meshgrid,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Log,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Log1p,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Round,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Pad,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Unfold,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,Det,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,CenterCrop,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_pytorch_onnx_onnxruntime.py,LogDet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_utility_funs.py,TestUtilityFuns,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_utility_funs.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_utility_funs.py,TransposeModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_utility_funs.py,NarrowModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_utility_funs.py,SliceIndexExceedsDimModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_utility_funs.py,SliceNegativeIndexModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_utility_funs.py,UnsqueezeModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_utility_funs.py,ConcatModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_utility_funs.py,GruNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_utility_funs.py,MatMulNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_utility_funs.py,MyModule,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_verify.py,TestVerify,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_verify.py,BrokenAdd,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_verify.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_verify.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_verify.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_verify.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_verify.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\test_verify.py,MyModel,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\verify.py,Errors,"
An error-collecting object which supports error recovery.

It is intended to be used like a context manager:

>>> with Errors(""Top-level error message"") as errs:
>>>     ...
",23,29,173,6
C:\Users\vaano\python_projects\pytorch\test\onnx\verify.py,ShortCircuit,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\verify.py,Recover,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\verify.py,AddContext,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\dcgan.py,_netG,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\dcgan.py,_netD,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\lstm_flattening_result.py,LstmFlatteningResult,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\mnist.py,MNIST,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\op_test.py,DummyNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\op_test.py,ConcatNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\op_test.py,PermuteNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\op_test.py,PReluNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\rnn_model_with_packed_sequence.py,RnnModelWithPackedSequence,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\squeezenet.py,Fire,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\squeezenet.py,SqueezeNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\srresnet.py,ResidualBlock,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\srresnet.py,UpscaleBlock,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\srresnet.py,SRResNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\super_resolution.py,SuperResolutionNet,,,,,
C:\Users\vaano\python_projects\pytorch\test\onnx\model_defs\word_language_model.py,RNNModel,"
Container module with an encoder, a recurrent module, and a decoder.
",9,10,68,1
C:\Users\vaano\python_projects\pytorch\test\scripts\cuda_memcheck_common.py,ParseError,"
Whenever the simple parser is unable to parse the report, this exception will be raised
",5,6,87,1
C:\Users\vaano\python_projects\pytorch\test\scripts\cuda_memcheck_common.py,Report,"
A report is a container of errors, and a summary on how many errors are found
",10,11,77,1
C:\Users\vaano\python_projects\pytorch\test\scripts\cuda_memcheck_common.py,Error,"
Each error is a section in the output of cuda-memcheck.
Each error in the report has an error message and a backtrace. It looks like:

========= Program hit cudaErrorInvalidValue (error 1) due to ""invalid argument"" on CUDA API call to cudaGetLastError.
=========     Saved host backtrace up to driver entry point at error
=========     Host Frame:/usr/lib/x86_64-linux-gnu/libcuda.so.1 [0x38c7b3]
=========     Host Frame:/usr/local/cuda/lib64/libcudart.so.10.1 (cudaGetLastError + 0x163) [0x4c493]
=========     Host Frame:/home/xgao/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch.so [0x5b77a05]
=========     Host Frame:/home/xgao/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch.so [0x39d6d1d]
=========     .....
",29,39,734,10
C:\Users\vaano\python_projects\pytorch\test\scripts\run_cuda_memcheck.py,ProgressbarStub,,,,,
C:\Users\vaano\python_projects\pytorch\tools\autograd\nested_dict.py,nested_dict,"
A nested dict is a dictionary with a parent.  If key lookup fails,
it recursively continues into the parent.  Writes always happen to
the top level dict.
",3,6,153,3
C:\Users\vaano\python_projects\pytorch\tools\setup_helpers\cmake.py,CMake,"
Manages cmake.
",95,96,14,1
C:\Users\vaano\python_projects\pytorch\tools\setup_helpers\env.py,BuildType,"
Checks build type. The build type will be given in :attr:`cmake_build_type_env`. If :attr:`cmake_build_type_env`
is ``None``, then the build type will be inferred from ``CMakeCache.txt``. If ``CMakeCache.txt`` does not exist,
os.environ['CMAKE_BUILD_TYPE'] will be used.

Arguments:
  cmake_build_type_env (str): The value of os.environ['CMAKE_BUILD_TYPE']. If None, the actual build type will be
    inferred.
",76,83,410,7
C:\Users\vaano\python_projects\pytorch\torch\hub.py,tqdm,,,,,
C:\Users\vaano\python_projects\pytorch\torch\quasirandom.py,SobolEngine,"
The :class:`torch.quasirandom.SobolEngine` is an engine for generating
(scrambled) Sobol sequences. Sobol sequences are an example of low
discrepancy quasi-random sequences.

This implementation of an engine for Sobol sequences is capable of
sampling sequences up to a maximum dimension of 1111. It uses direction
numbers to generate these sequences, and these numbers have been adapted
from `here <http://web.maths.unsw.edu.au/~fkuo/sobol/joe-kuo-old.1111>`_.

References:
  - Art B. Owen. Scrambling Sobol and Niederreiter-Xing points.
    Journal of Complexity, 14(4):466-489, December 1998.

  - I. M. Sobol. The distribution of points in a cube and the accurate
    evaluation of integrals.
    Zh. Vychisl. Mat. i Mat. Phys., 7:784-802, 1967.

Args:
    dimension (Int): The dimensionality of the sequence to be drawn
    scramble (bool, optional): Setting this to ``True`` will produce
                               scrambled Sobol sequences. Scrambling is
                               capable of producing better Sobol
                               sequences. Default: ``False``.
    seed (Int, optional): This is the seed for the scrambling. The seed
                          of the random number generator is set to this,
                          if specified. Otherwise, it uses a random seed.
                          Default: ``None``

Examples::

    >>> soboleng = torch.quasirandom.SobolEngine(dimension=5)
    >>> soboleng.draw(3)
    tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
            [0.7500, 0.2500, 0.7500, 0.2500, 0.7500],
            [0.2500, 0.7500, 0.2500, 0.7500, 0.2500]])
",5,40,1617,35
C:\Users\vaano\python_projects\pytorch\torch\serialization.py,SourceChangeWarning,,,,,
C:\Users\vaano\python_projects\pytorch\torch\serialization.py,_opener,,,,,
C:\Users\vaano\python_projects\pytorch\torch\serialization.py,_open_file,,,,,
C:\Users\vaano\python_projects\pytorch\torch\serialization.py,_open_buffer_reader,,,,,
C:\Users\vaano\python_projects\pytorch\torch\serialization.py,_open_buffer_writer,,,,,
C:\Users\vaano\python_projects\pytorch\torch\serialization.py,_open_zipfile_reader,,,,,
C:\Users\vaano\python_projects\pytorch\torch\serialization.py,_open_zipfile_writer_file,,,,,
C:\Users\vaano\python_projects\pytorch\torch\serialization.py,_open_zipfile_writer_buffer,,,,,
C:\Users\vaano\python_projects\pytorch\torch\storage.py,_StorageBase,,,,,
C:\Users\vaano\python_projects\pytorch\torch\tensor.py,Tensor,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_classes.py,_Classes,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,FunctionModifiers,"
Used to denote the behavior of a function in TorchScript. See export() and
ignore() for details.
",212,214,96,2
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,BroadcastingListCls,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,TupleCls,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,TupleInstance,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,ListInstance,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,ListCls,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,DictInstance,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,DictCls,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,OptionalInstance,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,OptionalCls,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,AnyCls,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,FinalInstance,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_jit_internal.py,FinalCls,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_ops.py,_OpNamespace,"
An op namespace to dynamically bind Operators into Python.

Say a user has created a custom Operator called ""my_namespace::my_op"". To
call this op, the user will write torch.ops.my_namespace.my_op(...).
At startup, this operation will not yet be bound into Python. Instead, the
following sequence of magic tricks will occur:
1. `torch.ops.my_namespace` will invoke the `__getattr__` magic method
   on the `torch.ops` object, which will create a new `_OpNamespace`
   object called `my_namespace` and set it as an attribute on the `ops`
   object.
2. `torch.ops.my_namespace.my_op` will then invoke `__getattr__` on
   the `my_namespace` object, which will retrieve the operation via
   `torch.get_operation`, a function bound from C++, and then in a similar
   fashion bind this new object onto the `my_namespace` object.
3. `torch.ops.my_namespace.my_op(...)` then calls this new operation
    and subsequent accesses will incur no further lookup (the namespace and
    operation will already exist).
",34,51,1002,17
C:\Users\vaano\python_projects\pytorch\torch\_ops.py,_Ops,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_six.py,metaclass,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_tensor_str.py,__PrinterOptions,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_tensor_str.py,_Formatter,,,,,
C:\Users\vaano\python_projects\pytorch\torch\_utils.py,KeyErrorMessage,"
str subclass that returns itself in repr
",367,368,40,1
C:\Users\vaano\python_projects\pytorch\torch\_utils.py,ExceptionWrapper,"
Wraps an exception plus traceback to communicate across threads
",373,374,63,1
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,DoubleStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,FloatStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,HalfStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,LongStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,IntStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,ShortStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,CharStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,ByteStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,BoolStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,BFloat16Storage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,QUInt8Storage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,QInt8Storage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\__init__.py,QInt32Storage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\autograd\anomaly_mode.py,detect_anomaly,"
Context-manager that enable anomaly detection for the autograd engine.

This does two things:
- Running the forward pass with detection enabled will allow the backward
pass to print the traceback of the forward operation that created the failing
backward function.
- Any backward computation that generate ""nan"" value will raise an error.

.. warning::
    This mode should be enabled only for debugging as the different tests
    will slow down your program execution.

Example:

    >>> import torch
    >>> from torch import autograd
    >>> class MyFunc(autograd.Function):
    ...     @staticmethod
    ...     def forward(ctx, inp):
    ...         return inp.clone()
    ...     @staticmethod
    ...     def backward(ctx, gO):
    ...         # Error during the backward pass
    ...         raise RuntimeError(""Some error in backward"")
    ...         return gO.clone()
    >>> def run_fn(a):
    ...     out = MyFunc.apply(a)
    ...     return out.sum()
    >>> inp = torch.rand(10, 10, requires_grad=True)
    >>> out = run_fn(inp)
    >>> out.backward()
        Traceback (most recent call last):
          File ""<stdin>"", line 1, in <module>
          File ""/your/pytorch/install/torch/tensor.py"", line 93, in backward
            torch.autograd.backward(self, gradient, retain_graph, create_graph)
          File ""/your/pytorch/install/torch/autograd/__init__.py"", line 90, in backward
            allow_unreachable=True)  # allow_unreachable flag
          File ""/your/pytorch/install/torch/autograd/function.py"", line 76, in apply
            return self._forward_cls.backward(self, *args)
          File ""<stdin>"", line 8, in backward
        RuntimeError: Some error in backward
    >>> with autograd.detect_anomaly():
    ...     inp = torch.rand(10, 10, requires_grad=True)
    ...     out = run_fn(inp)
    ...     out.backward()
        Traceback of forward call that caused the error:
          File ""tmp.py"", line 53, in <module>
            out = run_fn(inp)
          File ""tmp.py"", line 44, in run_fn
            out = MyFunc.apply(a)
        Traceback (most recent call last):
          File ""<stdin>"", line 4, in <module>
          File ""/your/pytorch/install/torch/tensor.py"", line 93, in backward
            torch.autograd.backward(self, gradient, retain_graph, create_graph)
          File ""/your/pytorch/install/torch/autograd/__init__.py"", line 90, in backward
            allow_unreachable=True)  # allow_unreachable flag
          File ""/your/pytorch/install/torch/autograd/function.py"", line 76, in apply
            return self._forward_cls.backward(self, *args)
          File ""<stdin>"", line 8, in backward
        RuntimeError: Some error in backward
",5,65,2693,60
C:\Users\vaano\python_projects\pytorch\torch\autograd\anomaly_mode.py,set_detect_anomaly,"
Context-manager that sets the anomaly detection for the autograd engine on or off.

``set_detect_anomaly`` will enable or disable the autograd anomaly detection
based on its argument :attr:`mode`.
It can be used as a context-manager or as a function.

See ``detect_anomaly`` above for details of the anomaly detection behaviour.

Arguments:
    mode (bool): Flag whether to enable anomaly detection (``True``),
                 or disable (``False``).
",80,91,451,11
C:\Users\vaano\python_projects\pytorch\torch\autograd\function.py,_ContextMethodMixin,,,,,
C:\Users\vaano\python_projects\pytorch\torch\autograd\function.py,_HookMixin,,,,,
C:\Users\vaano\python_projects\pytorch\torch\autograd\function.py,BackwardCFunction,,,,,
C:\Users\vaano\python_projects\pytorch\torch\autograd\function.py,FunctionMeta,"
Function metaclass.

This metaclass sets up the following properties:
    _is_legacy: True if forward is not defined as a static method.
    _backward_cls: The Function class corresponding to the differentiated
        version of this function (which is generated on the fly by this
        metaclass).
",81,88,302,7
C:\Users\vaano\python_projects\pytorch\torch\autograd\function.py,Function,"
Records operation history and defines formulas for differentiating ops.

Every operation performed on :class:`Tensor` s creates a new function
object, that performs the computation, and records that it happened.
The history is retained in the form of a DAG of functions, with edges
denoting data dependencies (``input <- output``). Then, when backward is
called, the graph is processed in the topological ordering, by calling
:func:`backward` methods of each :class:`Function` object, and passing
returned gradients on to next :class:`Function` s.

Normally, the only way users interact with functions is by creating
subclasses and defining new operations. This is a recommended way of
extending torch.autograd.

Each function object is meant to be used only once (in the forward pass).

Examples::

    >>> class Exp(Function):
    >>>
    >>>     @staticmethod
    >>>     def forward(ctx, i):
    >>>         result = i.exp()
    >>>         ctx.save_for_backward(result)
    >>>         return result
    >>>
    >>>     @staticmethod
    >>>     def backward(ctx, grad_output):
    >>>         result, = ctx.saved_tensors
    >>>         return grad_output * result
",110,140,1170,30
C:\Users\vaano\python_projects\pytorch\torch\autograd\function.py,InplaceFunction,,,,,
C:\Users\vaano\python_projects\pytorch\torch\autograd\function.py,NestedIOFunction,,,,,
C:\Users\vaano\python_projects\pytorch\torch\autograd\grad_mode.py,no_grad,"
Context-manager that disabled gradient calculation.

Disabling gradient calculation is useful for inference, when you are sure
that you will not call :meth:`Tensor.backward()`. It will reduce memory
consumption for computations that would otherwise have `requires_grad=True`.

In this mode, the result of every computation will have
`requires_grad=False`, even when the inputs have `requires_grad=True`.

This mode has no effect when using :class:`~enable_grad` context manager .

This context manager is thread local; it will not affect computation
in other threads.

Also functions as a decorator.


Example::

    >>> x = torch.tensor([1], requires_grad=True)
    >>> with torch.no_grad():
    ...   y = x * 2
    >>> y.requires_grad
    False
    >>> @torch.no_grad()
    ... def doubler(x):
    ...     return x * 2
    >>> z = doubler(x)
    >>> z.requires_grad
    False
",6,36,877,30
C:\Users\vaano\python_projects\pytorch\torch\autograd\grad_mode.py,enable_grad,"
Context-manager that enables gradient calculation.

Enables gradient calculation, if it has been disabled via :class:`~no_grad`
or :class:`~set_grad_enabled`.

This context manager is thread local; it will not affect computation
in other threads.

Also functions as a decorator.


Example::

    >>> x = torch.tensor([1], requires_grad=True)
    >>> with torch.no_grad():
    ...   with torch.enable_grad():
    ...     y = x * 2
    >>> y.requires_grad
    True
    >>> y.backward()
    >>> x.grad
    >>> @torch.enable_grad()
    ... def doubler(x):
    ...     return x * 2
    >>> with torch.no_grad():
    ...     z = doubler(x)
    >>> z.requires_grad
    True
",54,82,666,28
C:\Users\vaano\python_projects\pytorch\torch\autograd\grad_mode.py,set_grad_enabled,"
Context-manager that sets gradient calculation to on or off.

``set_grad_enabled`` will enable or disable grads based on its argument :attr:`mode`.
It can be used as a context-manager or as a function.

When using :class:`~enable_grad` context manager, :class:`~set_grad_enabled(False)`
has no effect.

This context manager is thread local; it will not affect computation
in other threads.

Arguments:
    mode (bool): Flag whether to enable grad (``True``), or disable
                 (``False``). This can be used to conditionally enable
                 gradients.


Example::

    >>> x = torch.tensor([1], requires_grad=True)
    >>> is_train = False
    >>> with torch.set_grad_enabled(is_train):
    ...   y = x * 2
    >>> y.requires_grad
    False
    >>> torch.set_grad_enabled(True)
    >>> y = x * 2
    >>> y.requires_grad
    True
    >>> torch.set_grad_enabled(False)
    >>> y = x * 2
    >>> y.requires_grad
    False
",101,134,935,33
C:\Users\vaano\python_projects\pytorch\torch\autograd\profiler.py,EventList,"
A list of Events (for pretty printing)
",24,25,38,1
C:\Users\vaano\python_projects\pytorch\torch\autograd\profiler.py,profile,"
Context manager that manages autograd profiler state and holds a summary of results.
Under the hood it just records events of functions being executed in C++ and
exposes those events to Python. You can wrap any code into it and it will
only report runtime of PyTorch functions.

Arguments:
    enabled (bool, optional): Setting this to False makes this context manager a no-op.
        Default: ``True``.

    use_cuda (bool, optional): Enables timing of CUDA events as well using the cudaEvent API.
        Adds approximately 4us of overhead to each tensor operation.
        Default: ``False``

    record_shapes (bool, optional): If shapes recording is set, information
        about input dimensions will be collected. This allows one to see which
        dimensions have been used under the hood and further group by them
        using prof.key_averages(group_by_input_shape=True). Please note that
        shape recording might skew your profiling data. It is recommended to
        use separate runs with and without shape recording to validate the timing.
        Most likely the skew will be negligible for bottom most events (in a case
        of nested function calls). But for higher level functions the total
        self cpu time might be artificially increased because of the shape
        collection.

.. warning:
    This context managers should not be called recursively, i.e. at most one
    instance should be enabled at any given time.

.. warning:
    Due to some CUDA multiprocessing limitations (multiprocessing-cuda-note_),
    one cannot use the profiler with ``use_cuda = True`` to benchmark
    DataLoaders with ``num_workers > 0``. If you wish to benchmark data loading,
    please use ``use_cuda = False`` or ``num_workers = 0``.

Example:
    >>> x = torch.randn((1, 1), requires_grad=True)
    >>> with torch.autograd.profiler.profile() as prof:
    >>>     for _ in range(100):  # any normal python code, really!
    >>>         y = x ** 2
    >>          y.backward()
    >>> # NOTE: some columns were removed for brevity
    >>> print(prof.key_averages().table(sort_by=""self_cpu_time_total""))
    -----------------------------------  ---------------  ---------------  ---------------
    Name                                 Self CPU total   CPU time avg     Number of Calls
    -----------------------------------  ---------------  ---------------  ---------------
    mul                                  32.048ms         32.048ms         200
    pow                                  27.041ms         27.041ms         200
    PowBackward0                         9.727ms          55.483ms         100
    torch::autograd::AccumulateGrad      9.148ms          9.148ms          100
    torch::autograd::GraphRoot           691.816us        691.816us        100
    -----------------------------------  ---------------  ---------------  ---------------
",208,259,2886,51
C:\Users\vaano\python_projects\pytorch\torch\autograd\profiler.py,record_function,"
Context manager/function decorator that adds a label to a block of
Python code (or function) when running autograd profiler. It is
useful when tracing the code profile.

Arguments:
    name (str): Label assigned to the block of code.

Example:
    >>> x = torch.randn((1, 1), requires_grad=True)
    >>> with torch.autograd.profiler.profile() as prof:
    ...     y = x ** 2
    ...     with torch.autograd.profiler.record_function(""label-z""): # label the block
    ...         z = y ** 3
    ...     y.backward()
    ...
    >>> # NOTE: some columns were removed for brevity
    >>> print(prof.key_averages().table(sort_by=""self_cpu_time_total""))
    -----------------------------------  ---------------  ---------------  ---------------
    Name                                 Self CPU total %  CPU time avg     Number of Calls
    -----------------------------------  ---------------  ---------------  ---------------
    pow                                  60.77%           47.470us         3
    mul                                  21.73%           25.465us         2
    PowBackward0                         12.03%           121.891us        1
    torch::autograd::AccumulateGrad      2.70%            6.324us          1
    label-z                              2.13%            12.421us         1
    torch::autograd::GraphRoot           0.64%            1.503us          1
    -----------------------------------  ---------------  ---------------  ---------------
    Self CPU time total: 234.344us
    CUDA time total: 0.000us
",335,364,1538,29
C:\Users\vaano\python_projects\pytorch\torch\autograd\profiler.py,emit_nvtx,"
Context manager that makes every autograd operation emit an NVTX range.

It is useful when running the program under nvprof::

    nvprof --profile-from-start off -o trace_name.prof -- <regular command here>

Unfortunately, there's no way to force nvprof to flush the data it collected
to disk, so for CUDA profiling one has to use this context manager to annotate
nvprof traces and wait for the process to exit before inspecting them.
Then, either NVIDIA Visual Profiler (nvvp) can be used to visualize the timeline, or
:func:`torch.autograd.profiler.load_nvprof` can load the results for inspection
e.g. in Python REPL.

.. warning:
    This context manager should not be called recursively, i.e. at most one
    instance should be enabled at any given time.

Arguments:
    enabled (bool, optional, default=True): Setting ``enabled=False`` makes this context manager a no-op.
        Default: ``True``.
    record_shapes (bool, optional, default=False): If ``record_shapes=True``, the nvtx range wrapping
        each autograd op will append information about the sizes of Tensor arguments received
        by that op, in the following format:
        ``[[arg0.size(0), arg0.size(1), ...], [arg1.size(0), arg1.size(1), ...], ...]``
        Non-tensor arguments will be represented by ``[]``.
        Arguments will be listed in the order they are received by the backend op.
        Please note that this order may not match the order in which those arguments were passed
        on the Python side.  Also note that shape recording may increase the overhead of nvtx range creation.

Example:
    >>> with torch.cuda.profiler.profile():
    ...     model(x) # Warmup CUDA memory allocator and profiler
    ...     with torch.autograd.profiler.emit_nvtx():
    ...         model(x)

**Forward-backward correlation**

When viewing a profile created using :class:`emit_nvtx` in the Nvidia Visual Profiler,
correlating each backward-pass op with the corresponding forward-pass op can be difficult.
To ease this task, :class:`emit_nvtx` appends sequence number information to the ranges it
generates.

During the forward pass, each function range is decorated with ``seq=<N>``.  ``seq`` is a running
counter, incremented each time a new backward Function object is created and stashed for backward.
Thus, the ``seq=<N>`` annotation associated with each forward function range tells you that
if a backward Function object is created by this forward function,
the backward object will receive sequence number N.
During the backward pass, the top-level range wrapping each C++ backward Function's
``apply()`` call is decorated with ``stashed seq=<M>``.  ``M`` is the sequence number that
the backward object was created with.  By comparing ``stashed seq`` numbers in backward with ``seq``
numbers in forward, you can track down which forward op created each backward Function.

Any functions executed during the backward pass are also decorated with ``seq=<N>``.  During
default backward (with ``create_graph=False``) this information is irrelevant, and in fact,
``N`` may simply be 0 for all such functions.  Only the top-level ranges associated with
backward Function objects' ``apply()`` methods are useful, as a way to correlate these Function
objects with the earlier forward pass.

**Double-backward**

If, on the other hand, a backward pass with ``create_graph=True`` is underway (in other words,
if you are setting up for a double-backward), each function's execution during backward
is given a nonzero, useful ``seq=<N>``.  Those functions may themselves create Function objects
to be executed later during double-backward, just as the original functions in the forward pass did.
The relationship between backward and double-backward is conceptually the same as the relationship
between forward and backward: The functions still emit current-sequence-number-tagged ranges,
the Function objects they create still stash those sequence numbers, and during the eventual
double-backward, the Function objects' ``apply()`` ranges are still tagged with ``stashed seq``
numbers, which can be compared to `seq` numbers from the backward pass.

.. warning:
    The sequence number is thread-local, and some forward functions don't create an associated
    backward Function object (instead delegating that to sub-functions further down the call chain).
    For these reasons, the correspondence of stashed sequence numbers in
    backward Function ``apply()`` ranges with `seq` numbers in forward-pass ranges is
    not guaranteed to be 1 to 1.  The sequence numbers alone may not be enough to fully
    disambiguate which forward function created which
    backward Function object.  You may need to make a judgment based on analytic knowledge of what
    the expected correspondence should be.
",378,457,4788,79
C:\Users\vaano\python_projects\pytorch\torch\autograd\profiler.py,FormattedTimesMixin,"
Helpers for FunctionEvent and FunctionEventAvg.

The subclass should define `*_time_total` and `count` attributes.
",522,525,114,3
C:\Users\vaano\python_projects\pytorch\torch\autograd\profiler.py,Interval,,,,,
C:\Users\vaano\python_projects\pytorch\torch\autograd\profiler.py,FunctionEvent,"
Profiling information about a single function.
",555,556,46,1
C:\Users\vaano\python_projects\pytorch\torch\autograd\profiler.py,FunctionEventAvg,"
Used to average stats over multiple FunctionEvent objects.
",614,615,58,1
C:\Users\vaano\python_projects\pytorch\torch\autograd\profiler.py,StringTable,,,,,
C:\Users\vaano\python_projects\pytorch\torch\autograd\profiler.py,EnforceUnique,"
Raises an error if a key is seen more than once.
",728,729,48,1
C:\Users\vaano\python_projects\pytorch\torch\autograd\profiler.py,ContextDecorator,,,,,
C:\Users\vaano\python_projects\pytorch\torch\autograd\variable.py,VariableMeta,,,,,
C:\Users\vaano\python_projects\pytorch\torch\autograd\variable.py,Variable,,,,,
C:\Users\vaano\python_projects\pytorch\torch\autograd\_functions\tensor.py,Type,,,,,
C:\Users\vaano\python_projects\pytorch\torch\autograd\_functions\tensor.py,Resize,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\__init__.py,ContextProp,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\__init__.py,PropModule,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\cuda\__init__.py,cuFFTPlanCacheAttrContextProp,"Like regular ContextProp, but uses the `.device_index` attribute from the
    calling object as the first argument to the getter and setter.
 ",14,15,35,1
C:\Users\vaano\python_projects\pytorch\torch\backends\cuda\__init__.py,cuFFTPlanCache,"
Represents a specific plan cache for a specific `device_index`. The
attributes `size` and `max_size`, and method `clear`, can fetch and/ or
change properties of the C++ cuFFT plan cache.
",30,33,186,3
C:\Users\vaano\python_projects\pytorch\torch\backends\cuda\__init__.py,cuFFTPlanCacheManager,"
Represents all cuFFT plan caches. When indexed with a device object/index,
this object returns the `cuFFTPlanCache` corresponding to that device.

Finally, this object, when used directly as a `cuFFTPlanCache` object (e.g.,
setting the `.max_size`) attribute, the current device's cuFFT plan cache is
used.
",51,57,306,6
C:\Users\vaano\python_projects\pytorch\torch\backends\cuda\__init__.py,CUDAModule,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\cudnn\rnn.py,Unserializable,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\cudnn\__init__.py,CuDNNHandle,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\cudnn\__init__.py,CuDNNError,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\cudnn\__init__.py,TensorDescriptor,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\cudnn\__init__.py,TensorDescriptorArray,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\cudnn\__init__.py,FilterDescriptor,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\cudnn\__init__.py,DropoutDescriptor,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\cudnn\__init__.py,RNNDescriptor,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\cudnn\__init__.py,CudnnModule,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\mkldnn\__init__.py,MkldnnModule,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\quantized\__init__.py,_QEngineProp,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\quantized\__init__.py,_SupportedQEnginesProp,,,,,
C:\Users\vaano\python_projects\pytorch\torch\backends\quantized\__init__.py,QuantizedEngine,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\profiler.py,cudaOutputMode,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\streams.py,Stream,"
Wrapper around a CUDA stream.

A CUDA stream is a linear sequence of execution that belongs to a specific
device, independent from other streams.  See :ref:`cuda-semantics` for
details.

Arguments:
    device(torch.device or int, optional): a device on which to allocate
        the stream. If :attr:`device` is ``None`` (default) or a negative
        integer, this will use the current device.
    priority(int, optional): priority of the stream. Lower numbers
                             represent higher priorities.
",6,18,520,12
C:\Users\vaano\python_projects\pytorch\torch\cuda\streams.py,Event,"
Wrapper around a CUDA event.

CUDA events are synchronization markers that can be used to monitor the
device's progress, to accurately measure timing, and to synchronize CUDA
streams.

The underlying CUDA events are lazily initialized when the event is first
recorded or exported to another process. After creation, only streams on the
same device may record the event. However, streams on any device can wait on
the event.

Arguments:
    enable_timing (bool, optional): indicates if the event should measure time
        (default: ``False``)
    blocking (bool, optional): if ``True``, :meth:`wait` will be blocking (default: ``False``)
    interprocess (bool): if ``True``, the event can be shared between processes
        (default: ``False``)

.. _CUDA Event Documentation:
   https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html
",103,123,853,20
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,DeferredCudaCallError,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,cudaStatus,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,CudaError,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,device,"
Context-manager that changes the selected device.

Arguments:
    device (torch.device or int): device index to select. It's a no-op if
        this argument is a negative integer or ``None``.
",240,245,192,5
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,device_of,"
Context-manager that changes the current device to that of given object.

You can use both tensors and storages as arguments. If a given object is
not allocated on a GPU, this is a no-op.

Arguments:
    obj (Tensor or Storage): object allocated on the selected device.
",266,273,269,7
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,_CudaBase,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,DoubleStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,FloatStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,LongStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,IntStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,ShortStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,CharStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,ByteStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,HalfStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,BoolStorage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\cuda\__init__.py,BFloat16Storage,,,,,
C:\Users\vaano\python_projects\pytorch\torch\distributed\distributed_c10d.py,Backend,"
An enum-like class of available backends: GLOO, NCCL, and MPI.

The values of this class are lowercase strings, e.g., ``""gloo""``. They can
be accessed as attributes, e.g., ``Backend.NCCL``.

This class can be directly called to parse the string, e.g.,
``Backend(backend_str)`` will check if ``backend_str`` is valid, and
return the parsed lowercase string if so. It also accepts uppercase strings,
e.g., ``Backend(""GLOO"")`` returns ``""gloo""``.

.. note:: The entry ``Backend.UNDEFINED`` is present but only used as
          initial value of some fields. Users should neither use it directly
          nor assume its existence.
",45,58,627,13
C:\Users\vaano\python_projects\pytorch\torch\distributed\distributed_c10d.py,reduce_op,"
Deprecated enum-like class for reduction operations: ``SUM``, ``PRODUCT``,
``MIN``, and ``MAX``.

:class:`~torch.distributed.ReduceOp` is recommended to use instead.
",87,91,165,4
C:\Users\vaano\python_projects\pytorch\torch\distributed\distributed_c10d.py,group,,,,,
C:\Users\vaano\python_projects\pytorch\torch\distributed\distributed_c10d.py,GroupMember,"Alias to group.WORLD for backward compatibility
 ",113,113,19,1
C:\Users\vaano\python_projects\pytorch\torch\distributed\autograd\__init__.py,context,"
Context object to wrap forward and backward passes when using
distributed autograd. The ``context_id`` generated in the ``with``
statement  is required to uniquely identify a distributed backward pass
on all workers. Each worker stores metadata associated with this
``context_id``, which is required to correctly execute a distributed
autograd pass.

Example::

    >> import torch.distributed.autograd as dist_autograd
    >> with dist_autograd.context() as context_id:
    >>   t1 = torch.rand((3, 3), requires_grad=True)
    >>   t2 = torch.rand((3, 3), requires_grad=True)
    >>   loss = rpc.rpc_sync(""worker1"", torch.add, args=(t1, t2)).sum()
    >>   dist_autograd.backward([loss])
",16,31,688,15
C:\Users\vaano\python_projects\pytorch\torch\distributed\optim\optimizer.py,_LocalOptimizer,"Ideally we would only need to share a lock for instances of
    _LocalOptimizer that deal with the same parameters. We are
    making a simplifying assumption here that if there is more
    than one instance of _LocalOptimizer per worker, they will
    be optimizing the same parameters (e.g. each data parallel
    trainer will create its own instance of _LocalOptimizer but
    they will all optimize the same parameters on each worker)
 ",9,15,20,1
C:\Users\vaano\python_projects\pytorch\torch\distributed\optim\optimizer.py,DistributedOptimizer,"
DistributedOptimizer takes remote references to parameters scattered
across workers and applies the given optimizer locally for each parameter.

This class uses :meth:`~torch.distributed.autograd.get_gradients` in order
to retrieve the gradients for specific parameters.

Concurrent calls to
:meth:`~torch.distributed.optim.DistributedOptimizer.step`,
either from the same or different clients, will
be serialized on each worker -- as each worker's optimizer can only work
on one set of gradients at a time. However, there is no guarantee that
the full forward-backward-optimizer sequence will execute for one client
at a time. This means that the gradients being applied may not correspond
to the latest forward pass executed on a given worker. Also, there is no
guaranteed ordering across workers.

Args:
    optimizer_class (optim.Optimizer): the class of optimizer to
        instantiate on each worker.
    params_rref (list[RRef]): list of RRefs to local or remote parameters
        to optimize.
    args: arguments to pass to the optimizer constructor on each worker.
    kwargs: arguments to pass to the optimizer constructor on each worker.

Example::

    >> import torch.distributed.autograd as dist_autograd
    >> import torch.distributed.rpc as rpc
    >> from torch import optim
    >> from torch.distributed.optim import DistributedOptimizer
    >>
    >> with dist_autograd.context() as context_id:
    >>   # Forward pass.
    >>   rref1 = rpc.remote(""worker1"", torch.add, args=(torch.ones(2), 3))
    >>   rref2 = rpc.remote(""worker1"", torch.add, args=(torch.ones(2), 1))
    >>   loss = rref1.to_here() + rref2.to_here()
    >>
    >>   # Backward pass.
    >>   dist_autograd.backward([loss.sum()])
    >>
    >>   # Optimizer.
    >>   dist_optim = DistributedOptimizer(
    >>      optim.SGD,
    >>      [rref1, rref2],
    >>      lr=0.05,
    >>   )
    >>   dist_optim.step()
",59,106,1903,47
C:\Users\vaano\python_projects\pytorch\torch\distributed\rpc\internal.py,_InternalRPCPickler,"
This class provides serialize() and deserialize() interfaces to serialize
data to be ""binary string + tensor table"" format
So for RPC python UDF function and args, non tensor data will be serialized
into regular binary string, tensor data will be put into thread local tensor
tables, this serialization format is consistent with builtin operator and args
using JIT pickler. This format will make tensor handling in C++ much easier,
e.g. attach tensor to distributed autograd graph in C++
",16,23,487,7
C:\Users\vaano\python_projects\pytorch\torch\distributions\bernoulli.py,Bernoulli,"
Creates a Bernoulli distribution parameterized by :attr:`probs`
or :attr:`logits` (but not both).

Samples are binary (0 or 1). They take the value `1` with probability `p`
and `0` with probability `1 - p`.

Example::

    >>> m = Bernoulli(torch.tensor([0.3]))
    >>> m.sample()  # 30% chance 1; 70% chance 0
    tensor([ 0.])

Args:
    probs (Number, Tensor): the probability of sampling `1`
    logits (Number, Tensor): the log-odds of sampling `1`
",11,26,453,15
C:\Users\vaano\python_projects\pytorch\torch\distributions\beta.py,Beta,"
Beta distribution parameterized by :attr:`concentration1` and :attr:`concentration0`.

Example::

    >>> m = Beta(torch.tensor([0.5]), torch.tensor([0.5]))
    >>> m.sample()  # Beta distributed with concentration concentration1 and concentration0
    tensor([ 0.1046])

Args:
    concentration1 (float or Tensor): 1st concentration parameter of the distribution
        (often referred to as alpha)
    concentration0 (float or Tensor): 2nd concentration parameter of the distribution
        (often referred to as beta)
",11,24,522,13
C:\Users\vaano\python_projects\pytorch\torch\distributions\binomial.py,Binomial,"
Creates a Binomial distribution parameterized by :attr:`total_count` and
either :attr:`probs` or :attr:`logits` (but not both). :attr:`total_count` must be
broadcastable with :attr:`probs`/:attr:`logits`.

Example::

    >>> m = Binomial(100, torch.tensor([0 , .2, .8, 1]))
    >>> x = m.sample()
    tensor([   0.,   22.,   71.,  100.])

    >>> m = Binomial(torch.tensor([[5.], [10.]]), torch.tensor([0.5, 0.8]))
    >>> x = m.sample()
    tensor([[ 4.,  5.],
            [ 7.,  6.]])

Args:
    total_count (int or Tensor): number of Bernoulli trials
    probs (Tensor): Event probabilities
    logits (Tensor): Event log-odds
",14,33,629,19
C:\Users\vaano\python_projects\pytorch\torch\distributions\categorical.py,Categorical,"
Creates a categorical distribution parameterized by either :attr:`probs` or
:attr:`logits` (but not both).

.. note::
    It is equivalent to the distribution that :func:`torch.multinomial`
    samples from.

Samples are integers from :math:`\{0, \ldots, K-1\}` where `K` is ``probs.size(-1)``.

If :attr:`probs` is 1D with length-`K`, each element is the relative
probability of sampling the class at that index.

If :attr:`probs` is 2D, it is treated as a batch of relative probability
vectors.

.. note:: :attr:`probs` must be non-negative, finite and have a non-zero sum,
          and it will be normalized to sum to 1.

See also: :func:`torch.multinomial`

Example::

    >>> m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))
    >>> m.sample()  # equal probability of 0, 1, 2, 3
    tensor(3)

Args:
    probs (Tensor): event probabilities
    logits (Tensor): event log-odds
",9,38,890,29
C:\Users\vaano\python_projects\pytorch\torch\distributions\cauchy.py,Cauchy,"
Samples from a Cauchy (Lorentz) distribution. The distribution of the ratio of
independent normally distributed random variables with means `0` follows a
Cauchy distribution.

Example::

    >>> m = Cauchy(torch.tensor([0.0]), torch.tensor([1.0]))
    >>> m.sample()  # sample from a Cauchy distribution with loc=0 and scale=1
    tensor([ 2.3214])

Args:
    loc (float or Tensor): mode or median of the distribution.
    scale (float or Tensor): half width at half maximum.
",12,25,475,13
C:\Users\vaano\python_projects\pytorch\torch\distributions\chi2.py,Chi2,"
Creates a Chi2 distribution parameterized by shape parameter :attr:`df`.
This is exactly equivalent to ``Gamma(alpha=0.5*df, beta=0.5)``

Example::

    >>> m = Chi2(torch.tensor([1.0]))
    >>> m.sample()  # Chi2 distributed with shape df=1
    tensor([ 0.1046])

Args:
    df (float or Tensor): shape parameter of the distribution
",6,17,332,11
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,Constraint,"
Abstract base class for constraints.

A constraint object represents a region over which a variable is valid,
e.g. within which a variable can be optimized.
",53,57,156,4
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_Dependent,"
Placeholder for variables whose support depends on other variables.
These variables obey no simple coordinate-wise constraints.
",71,73,127,2
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_DependentProperty,"
Decorator that extends @property to act like a `Dependent` constraint when
called on a class and act like a property when called on an object.

Example::

    class Uniform(Distribution):
        def __init__(self, low, high):
            self.low = low
            self.high = high
        @constraints.dependent_property
        def support(self):
            return constraints.interval(self.low, self.high)
",84,96,410,12
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_Boolean,"
Constrain to the two values `{0, 1}`.
",102,103,37,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_IntegerInterval,"
Constrain to an integer interval `[lower_bound, upper_bound]`.
",110,111,62,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_IntegerLessThan,"
Constrain to an integer interval `(-inf, upper_bound]`.
",127,128,55,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_IntegerGreaterThan,"
Constrain to an integer interval `[lower_bound, inf)`.
",143,144,54,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_Real,"
Trivially constrain to the extended real line `[-inf, inf]`.
",159,160,60,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_GreaterThan,"
Constrain to a real half line `(lower_bound, inf]`.
",167,168,51,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_GreaterThanEq,"
Constrain to a real half line `[lower_bound, inf)`.
",183,184,51,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_LessThan,"
Constrain to a real half line `[-inf, upper_bound)`.
",199,200,52,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_Interval,"
Constrain to a real interval `[lower_bound, upper_bound]`.
",215,216,58,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_HalfOpenInterval,"
Constrain to a real interval `[lower_bound, upper_bound)`.
",232,233,58,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_Simplex,"
Constrain to the unit simplex in the innermost (rightmost) dimension.
Specifically: `x >= 0` and `x.sum(-1) == 1`.
",249,251,114,2
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_LowerTriangular,"
Constrain to lower-triangular square matrices.
",258,259,46,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_LowerCholesky,"
Constrain to lower-triangular square matrices with positive diagonals.
",267,268,70,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_PositiveDefinite,"
Constrain to positive-definite matrices.
",279,280,40,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_RealVector,"
Constrain to real-valued vectors. This is the same as `constraints.real`,
but additionally reduces across the `event_shape` dimension.
",293,295,134,2
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_Cat,"
Constraint functor that applies a sequence of constraints
`cseq` at the submatrices at dimension `dim`,
each of size `lengths[dim]`, in a way compatible with :func:`torch.cat`.
",302,305,176,3
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraints.py,_Stack,"
Constraint functor that applies a sequence of constraints
`cseq` at the submatrices at dimension `dim`,
in a way compatible with :func:`torch.stack`.
",328,331,149,3
C:\Users\vaano\python_projects\pytorch\torch\distributions\constraint_registry.py,ConstraintRegistry,"
Registry to link constraints to transforms.
",80,81,43,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\dirichlet.py,_Dirichlet,,,,,
C:\Users\vaano\python_projects\pytorch\torch\distributions\dirichlet.py,Dirichlet,"
Creates a Dirichlet distribution parameterized by concentration :attr:`concentration`.

Example::

    >>> m = Dirichlet(torch.tensor([0.5, 0.5]))
    >>> m.sample()  # Dirichlet distributed with concentrarion concentration
    tensor([ 0.1046,  0.8954])

Args:
    concentration (Tensor): concentration parameter of the distribution
        (often referred to as alpha)
",30,41,370,11
C:\Users\vaano\python_projects\pytorch\torch\distributions\distribution.py,Distribution,"
Distribution is the abstract base class for probability distributions.
",8,9,70,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\exponential.py,Exponential,"
Creates a Exponential distribution parameterized by :attr:`rate`.

Example::

    >>> m = Exponential(torch.tensor([1.0]))
    >>> m.sample()  # Exponential distributed with rate=1
    tensor([ 0.1046])

Args:
    rate (float or Tensor): rate = 1 / scale of the distribution
",10,20,274,10
C:\Users\vaano\python_projects\pytorch\torch\distributions\exp_family.py,ExponentialFamily,"
ExponentialFamily is the abstract base class for probability distributions belonging to an
exponential family, whose probability mass/density function has the form is defined below

.. math::

    p_{F}(x; \theta) = \exp(\langle t(x), \theta\rangle - F(\theta) + k(x))

where :math:`\theta` denotes the natural parameters, :math:`t(x)` denotes the sufficient statistic,
:math:`F(\theta)` is the log normalizer function for a given family and :math:`k(x)` is the carrier
measure.

Note:
    This class is an intermediary between the `Distribution` class and distributions which belong
    to an exponential family mainly to check the correctness of the `.entropy()` and analytic KL
    divergence methods. We use this class to compute the entropy and KL divergence using the AD
    framework and Bregman divergences (courtesy of: Frank Nielsen and Richard Nock, Entropies and
    Cross-entropies of Exponential Families).
",6,23,920,17
C:\Users\vaano\python_projects\pytorch\torch\distributions\fishersnedecor.py,FisherSnedecor,"
Creates a Fisher-Snedecor distribution parameterized by :attr:`df1` and :attr:`df2`.

Example::

    >>> m = FisherSnedecor(torch.tensor([1.0]), torch.tensor([2.0]))
    >>> m.sample()  # Fisher-Snedecor-distributed with df1=1 and df2=2
    tensor([ 0.2453])

Args:
    df1 (float or Tensor): degrees of freedom parameter 1
    df2 (float or Tensor): degrees of freedom parameter 2
",11,22,381,11
C:\Users\vaano\python_projects\pytorch\torch\distributions\gamma.py,Gamma,"
Creates a Gamma distribution parameterized by shape :attr:`concentration` and :attr:`rate`.

Example::

    >>> m = Gamma(torch.tensor([1.0]), torch.tensor([1.0]))
    >>> m.sample()  # Gamma distributed with concentration=1 and rate=1
    tensor([ 0.1046])

Args:
    concentration (float or Tensor): shape parameter of the distribution
        (often referred to as alpha)
    rate (float or Tensor): rate = 1 / scale of the distribution
        (often referred to as beta)
",14,27,475,13
C:\Users\vaano\python_projects\pytorch\torch\distributions\geometric.py,Geometric,"
Creates a Geometric distribution parameterized by :attr:`probs`,
where :attr:`probs` is the probability of success of Bernoulli trials.
It represents the probability that in :math:`k + 1` Bernoulli trials, the
first :math:`k` trials failed, before seeing a success.

Samples are non-negative integers [0, :math:`\inf`).

Example::

    >>> m = Geometric(torch.tensor([0.3]))
    >>> m.sample()  # underlying Bernoulli has 30% chance 1; 70% chance 0
    tensor([ 2.])

Args:
    probs (Number, Tensor): the probability of sampling `1`. Must be in range (0, 1]
    logits (Number, Tensor): the log-odds of sampling `1`.
",11,27,617,16
C:\Users\vaano\python_projects\pytorch\torch\distributions\gumbel.py,Gumbel,"
Samples from a Gumbel Distribution.

Examples::

    >>> m = Gumbel(torch.tensor([1.0]), torch.tensor([2.0]))
    >>> m.sample()  # sample from Gumbel distribution with loc=1, scale=2
    tensor([ 1.0124])

Args:
    loc (float or Tensor): Location parameter of the distribution
    scale (float or Tensor): Scale parameter of the distribution
",14,25,343,11
C:\Users\vaano\python_projects\pytorch\torch\distributions\half_cauchy.py,HalfCauchy,"
Creates a half-normal distribution parameterized by `scale` where::

    X ~ Cauchy(0, scale)
    Y = |X| ~ HalfCauchy(scale)

Example::

    >>> m = HalfCauchy(torch.tensor([1.0]))
    >>> m.sample()  # half-cauchy distributed with scale=1
    tensor([ 2.3214])

Args:
    scale (float or Tensor): scale of the full Cauchy distribution
",12,25,336,13
C:\Users\vaano\python_projects\pytorch\torch\distributions\half_normal.py,HalfNormal,"
Creates a half-normal distribution parameterized by `scale` where::

    X ~ Normal(0, scale)
    Y = |X| ~ HalfNormal(scale)

Example::

    >>> m = HalfNormal(torch.tensor([1.0]))
    >>> m.sample()  # half-normal distributed with scale=1
    tensor([ 0.1046])

Args:
    scale (float or Tensor): scale of the full Normal distribution
",11,24,336,13
C:\Users\vaano\python_projects\pytorch\torch\distributions\independent.py,Independent,"
Reinterprets some of the batch dims of a distribution as event dims.

This is mainly useful for changing the shape of the result of
:meth:`log_prob`. For example to create a diagonal Normal distribution with
the same shape as a Multivariate Normal distribution (so they are
interchangeable), you can::

    >>> loc = torch.zeros(3)
    >>> scale = torch.ones(3)
    >>> mvn = MultivariateNormal(loc, scale_tril=torch.diag(scale))
    >>> [mvn.batch_shape, mvn.event_shape]
    [torch.Size(()), torch.Size((3,))]
    >>> normal = Normal(loc, scale)
    >>> [normal.batch_shape, normal.event_shape]
    [torch.Size((3,)), torch.Size(())]
    >>> diagn = Independent(normal, 1)
    >>> [diagn.batch_shape, diagn.event_shape]
    [torch.Size(()), torch.Size((3,))]

Args:
    base_distribution (torch.distributions.distribution.Distribution): a
        base distribution
    reinterpreted_batch_ndims (int): the number of batch dims to
        reinterpret as event dims
",8,32,965,24
C:\Users\vaano\python_projects\pytorch\torch\distributions\kl.py,_Match,,,,,
C:\Users\vaano\python_projects\pytorch\torch\distributions\laplace.py,Laplace,"
Creates a Laplace distribution parameterized by :attr:`loc` and :attr:'scale'.

Example::

    >>> m = Laplace(torch.tensor([0.0]), torch.tensor([1.0]))
    >>> m.sample()  # Laplace distributed with loc=0, scale=1
    tensor([ 0.1046])

Args:
    loc (float or Tensor): mean of the distribution
    scale (float or Tensor): scale of the distribution
",9,20,350,11
C:\Users\vaano\python_projects\pytorch\torch\distributions\logistic_normal.py,LogisticNormal,"
Creates a logistic-normal distribution parameterized by :attr:`loc` and :attr:`scale`
that define the base `Normal` distribution transformed with the
`StickBreakingTransform` such that::

    X ~ LogisticNormal(loc, scale)
    Y = log(X / (1 - X.cumsum(-1)))[..., :-1] ~ Normal(loc, scale)

Args:
    loc (float or Tensor): mean of the base distribution
    scale (float or Tensor): standard deviation of the base distribution

Example::

    >>> # logistic-normal distributed with mean=(0, 0, 0) and stddev=(1, 1, 1)
    >>> # of the base Normal distribution
    >>> m = distributions.LogisticNormal(torch.tensor([0.0] * 3), torch.tensor([1.0] * 3))
    >>> m.sample()
    tensor([ 0.7653,  0.0341,  0.0579,  0.1427])
",9,27,718,18
C:\Users\vaano\python_projects\pytorch\torch\distributions\log_normal.py,LogNormal,"
Creates a log-normal distribution parameterized by
:attr:`loc` and :attr:`scale` where::

    X ~ Normal(loc, scale)
    Y = exp(X) ~ LogNormal(loc, scale)

Example::

    >>> m = LogNormal(torch.tensor([0.0]), torch.tensor([1.0]))
    >>> m.sample()  # log-normal distributed with mean=0 and stddev=1
    tensor([ 0.1046])

Args:
    loc (float or Tensor): mean of log of distribution
    scale (float or Tensor): standard deviation of log of the distribution
",8,23,460,15
C:\Users\vaano\python_projects\pytorch\torch\distributions\lowrank_multivariate_normal.py,LowRankMultivariateNormal,"
Creates a multivariate normal distribution with covariance matrix having a low-rank form
parameterized by :attr:`cov_factor` and :attr:`cov_diag`::

    covariance_matrix = cov_factor @ cov_factor.T + cov_diag

Example:

    >>> m = LowRankMultivariateNormal(torch.zeros(2), torch.tensor([1, 0]), torch.tensor([1, 1]))
    >>> m.sample()  # normally distributed with mean=`[0,0]`, cov_factor=`[1,0]`, cov_diag=`[1,1]`
    tensor([-0.2102, -0.5429])

Args:
    loc (Tensor): mean of the distribution with shape `batch_shape + event_shape`
    cov_factor (Tensor): factor part of low-rank form of covariance matrix with shape
        `batch_shape + event_shape + (rank,)`
    cov_diag (Tensor): diagonal part of low-rank form of covariance matrix with shape
        `batch_shape + event_shape`

Note:
    The computation for determinant and inverse of covariance matrix is avoided when
    `cov_factor.shape[1] << cov_factor.shape[0]` thanks to `Woodbury matrix identity
    <https://en.wikipedia.org/wiki/Woodbury_matrix_identity>`_ and
    `matrix determinant lemma <https://en.wikipedia.org/wiki/Matrix_determinant_lemma>`_.
    Thanks to these formulas, we just need to compute the determinant and inverse of
    the small size ""capacitance"" matrix::

        capacitance = I + cov_factor.T @ inv(cov_diag) @ cov_factor
",47,74,1321,27
C:\Users\vaano\python_projects\pytorch\torch\distributions\multinomial.py,Multinomial,"
Creates a Multinomial distribution parameterized by :attr:`total_count` and
either :attr:`probs` or :attr:`logits` (but not both). The innermost dimension of
:attr:`probs` indexes over categories. All other dimensions index over batches.

Note that :attr:`total_count` need not be specified if only :meth:`log_prob` is
called (see example below)

.. note:: :attr:`probs` must be non-negative, finite and have a non-zero sum,
          and it will be normalized to sum to 1.

-   :meth:`sample` requires a single shared `total_count` for all
    parameters and samples.
-   :meth:`log_prob` allows different `total_count` for each parameter and
    sample.

Example::

    >>> m = Multinomial(100, torch.tensor([ 1., 1., 1., 1.]))
    >>> x = m.sample()  # equal probability of 0, 1, 2, 3
    tensor([ 21.,  24.,  30.,  25.])

    >>> Multinomial(probs=torch.tensor([1., 1., 1., 1.])).log_prob(x)
    tensor([-4.1338])

Args:
    total_count (int): number of trials
    probs (Tensor): event probabilities
    logits (Tensor): event log probabilities
",11,39,1049,28
C:\Users\vaano\python_projects\pytorch\torch\distributions\multivariate_normal.py,MultivariateNormal,"
Creates a multivariate normal (also called Gaussian) distribution
parameterized by a mean vector and a covariance matrix.

The multivariate normal distribution can be parameterized either
in terms of a positive definite covariance matrix :math:`\mathbf{\Sigma}`
or a positive definite precision matrix :math:`\mathbf{\Sigma}^{-1}`
or a lower-triangular matrix :math:`\mathbf{L}` with positive-valued
diagonal entries, such that
:math:`\mathbf{\Sigma} = \mathbf{L}\mathbf{L}^\top`. This triangular matrix
can be obtained via e.g. Cholesky decomposition of the covariance.

Example:

    >>> m = MultivariateNormal(torch.zeros(2), torch.eye(2))
    >>> m.sample()  # normally distributed with mean=`[0,0]` and covariance_matrix=`I`
    tensor([-0.2102, -0.5429])

Args:
    loc (Tensor): mean of the distribution
    covariance_matrix (Tensor): positive-definite covariance matrix
    precision_matrix (Tensor): positive-definite precision matrix
    scale_tril (Tensor): lower-triangular factor of covariance, with positive-valued diagonal

Note:
    Only one of :attr:`covariance_matrix` or :attr:`precision_matrix` or
    :attr:`scale_tril` can be specified.

    Using :attr:`scale_tril` will be more efficient: all computations internally
    are based on :attr:`scale_tril`. If :attr:`covariance_matrix` or
    :attr:`precision_matrix` is passed instead, it is only used to compute
    the corresponding lower triangular matrices using a Cholesky decomposition.
",79,110,1465,31
C:\Users\vaano\python_projects\pytorch\torch\distributions\negative_binomial.py,NegativeBinomial,"
Creates a Negative Binomial distribution, i.e. distribution
of the number of successful independent and identical Bernoulli trials
before :attr:`total_count` failures are achieved. The probability
of success of each Bernoulli trial is :attr:`probs`.

Args:
    total_count (float or Tensor): non-negative number of negative Bernoulli
        trials to stop, although the distribution is still valid for real
        valued count
    probs (Tensor): Event probabilities of success in the half open interval [0, 1)
    logits (Tensor): Event log-odds for probabilities of success
",9,20,577,11
C:\Users\vaano\python_projects\pytorch\torch\distributions\normal.py,Normal,"
Creates a normal (also called Gaussian) distribution parameterized by
:attr:`loc` and :attr:`scale`.

Example::

    >>> m = Normal(torch.tensor([0.0]), torch.tensor([1.0]))
    >>> m.sample()  # normally distributed with loc=0 and scale=1
    tensor([ 0.1046])

Args:
    loc (float or Tensor): mean of the distribution (often referred to as mu)
    scale (float or Tensor): standard deviation of the distribution
        (often referred to as sigma)
",11,24,451,13
C:\Users\vaano\python_projects\pytorch\torch\distributions\one_hot_categorical.py,OneHotCategorical,"
Creates a one-hot categorical distribution parameterized by :attr:`probs` or
:attr:`logits`.

Samples are one-hot coded vectors of size ``probs.size(-1)``.

.. note:: :attr:`probs` must be non-negative, finite and have a non-zero sum,
          and it will be normalized to sum to 1.

See also: :func:`torch.distributions.Categorical` for specifications of
:attr:`probs` and :attr:`logits`.

Example::

    >>> m = OneHotCategorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))
    >>> m.sample()  # equal probability of 0, 1, 2, 3
    tensor([ 0.,  0.,  0.,  1.])

Args:
    probs (Tensor): event probabilities
    logits (Tensor): event log probabilities
",8,28,653,20
C:\Users\vaano\python_projects\pytorch\torch\distributions\pareto.py,Pareto,"
Samples from a Pareto Type 1 distribution.

Example::

    >>> m = Pareto(torch.tensor([1.0]), torch.tensor([1.0]))
    >>> m.sample()  # sample from a Pareto distribution with scale=1 and alpha=1
    tensor([ 1.5623])

Args:
    scale (float or Tensor): Scale parameter of the distribution
    alpha (float or Tensor): Shape parameter of the distribution
",9,20,355,11
C:\Users\vaano\python_projects\pytorch\torch\distributions\poisson.py,Poisson,"
Creates a Poisson distribution parameterized by :attr:`rate`, the rate parameter.

Samples are nonnegative integers, with a pmf given by

.. math::
  \mathrm{rate}^k \frac{e^{-\mathrm{rate}}}{k!}

Example::

    >>> m = Poisson(torch.tensor([4]))
    >>> m.sample()
    tensor([ 3.])

Args:
    rate (Number, Tensor): the rate parameter
",10,25,336,15
C:\Users\vaano\python_projects\pytorch\torch\distributions\relaxed_bernoulli.py,LogitRelaxedBernoulli,"
Creates a LogitRelaxedBernoulli distribution parameterized by :attr:`probs`
or :attr:`logits` (but not both), which is the logit of a RelaxedBernoulli
distribution.

Samples are logits of values in (0, 1). See [1] for more details.

Args:
    temperature (Tensor): relaxation temperature
    probs (Number, Tensor): the probability of sampling `1`
    logits (Number, Tensor): the log-odds of sampling `1`

[1] The Concrete Distribution: A Continuous Relaxation of Discrete Random
Variables (Maddison et al, 2017)

[2] Categorical Reparametrization with Gumbel-Softmax
(Jang et al, 2017)
",11,27,587,16
C:\Users\vaano\python_projects\pytorch\torch\distributions\relaxed_bernoulli.py,RelaxedBernoulli,"
Creates a RelaxedBernoulli distribution, parametrized by
:attr:`temperature`, and either :attr:`probs` or :attr:`logits`
(but not both). This is a relaxed version of the `Bernoulli` distribution,
so the values are in (0, 1), and has reparametrizable samples.

Example::

    >>> m = RelaxedBernoulli(torch.tensor([2.2]),
                             torch.tensor([0.1, 0.2, 0.3, 0.99]))
    >>> m.sample()
    tensor([ 0.2951,  0.3442,  0.8918,  0.9021])

Args:
    temperature (Tensor): relaxation temperature
    probs (Number, Tensor): the probability of sampling `1`
    logits (Number, Tensor): the log-odds of sampling `1`
",94,110,628,16
C:\Users\vaano\python_projects\pytorch\torch\distributions\relaxed_categorical.py,ExpRelaxedCategorical,"
Creates a ExpRelaxedCategorical parameterized by
:attr:`temperature`, and either :attr:`probs` or :attr:`logits` (but not both).
Returns the log of a point in the simplex. Based on the interface to
:class:`OneHotCategorical`.

Implementation based on [1].

See also: :func:`torch.distributions.OneHotCategorical`

Args:
    temperature (Tensor): relaxation temperature
    probs (Tensor): event probabilities
    logits (Tensor): the log probability of each event.

[1] The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables
(Maddison et al, 2017)

[2] Categorical Reparametrization with Gumbel-Softmax
(Jang et al, 2017)
",11,30,646,19
C:\Users\vaano\python_projects\pytorch\torch\distributions\relaxed_categorical.py,RelaxedOneHotCategorical,"
Creates a RelaxedOneHotCategorical distribution parametrized by
:attr:`temperature`, and either :attr:`probs` or :attr:`logits`.
This is a relaxed version of the :class:`OneHotCategorical` distribution, so
its samples are on simplex, and are reparametrizable.

Example::

    >>> m = RelaxedOneHotCategorical(torch.tensor([2.2]),
                                     torch.tensor([0.1, 0.2, 0.3, 0.4]))
    >>> m.sample()
    tensor([ 0.1294,  0.2324,  0.3859,  0.2523])

Args:
    temperature (Tensor): relaxation temperature
    probs (Tensor): event probabilities
    logits (Tensor): the log probability of each event.
",88,104,622,16
C:\Users\vaano\python_projects\pytorch\torch\distributions\studentT.py,StudentT,"
Creates a Student's t-distribution parameterized by degree of
freedom :attr:`df`, mean :attr:`loc` and scale :attr:`scale`.

Example::

    >>> m = StudentT(torch.tensor([2.0]))
    >>> m.sample()  # Student's t-distributed with degrees of freedom=2
    tensor([ 0.1046])

Args:
    df (float or Tensor): degrees of freedom
    loc (float or Tensor): mean of the distribution
    scale (float or Tensor): scale of the distribution
",11,24,430,13
C:\Users\vaano\python_projects\pytorch\torch\distributions\transformed_distribution.py,TransformedDistribution,"
Extension of the Distribution class, which applies a sequence of Transforms
to a base distribution.  Let f be the composition of transforms applied::

    X ~ BaseDistribution
    Y = f(X) ~ TransformedDistribution(BaseDistribution, f)
    log p(Y) = log p(X) + log |det (dX/dY)|

Note that the ``.event_shape`` of a :class:`TransformedDistribution` is the
maximum shape of its base distribution and its transforms, since transforms
can introduce correlations among events.

An example for the usage of :class:`TransformedDistribution` would be::

    # Building a Logistic Distribution
    # X ~ Uniform(0, 1)
    # f = a + b * logit(X)
    # Y ~ f(X) ~ Logistic(a, b)
    base_distribution = Uniform(0, 1)
    transforms = [SigmoidTransform().inv, AffineTransform(loc=a, scale=b)]
    logistic = TransformedDistribution(base_distribution, transforms)

For more examples, please look at the implementations of
:class:`~torch.distributions.gumbel.Gumbel`,
:class:`~torch.distributions.half_cauchy.HalfCauchy`,
:class:`~torch.distributions.half_normal.HalfNormal`,
:class:`~torch.distributions.log_normal.LogNormal`,
:class:`~torch.distributions.pareto.Pareto`,
:class:`~torch.distributions.weibull.Weibull`,
:class:`~torch.distributions.relaxed_bernoulli.RelaxedBernoulli` and
:class:`~torch.distributions.relaxed_categorical.RelaxedOneHotCategorical`
",9,39,1351,30
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,Transform,"
Abstract class for invertable transformations with computable log
det jacobians. They are primarily used in
:class:`torch.distributions.TransformedDistribution`.

Caching is useful for tranforms whose inverses are either expensive or
numerically unstable. Note that care must be taken with memoized values
since the autograd graph may be reversed. For example while the following
works with or without caching::

    y = t(x)
    t.log_abs_det_jacobian(x, y).backward()  # x will receive gradients.

However the following will error when caching due to dependency reversal::

    y = t(x)
    z = t.inv(y)
    grad(z.sum(), [y])  # error because z is x

Derived classes should implement one or both of :meth:`_call` or
:meth:`_inverse`. Derived classes that set `bijective=True` should also
implement :meth:`log_abs_det_jacobian`.

Args:
    cache_size (int): Size of cache. If zero, no caching is done. If one,
        the latest single value is cached. Only 0 and 1 are supported.

Attributes:
    domain (:class:`~torch.distributions.constraints.Constraint`):
        The constraint representing valid inputs to this transform.
    codomain (:class:`~torch.distributions.constraints.Constraint`):
        The constraint representing valid outputs to this transform
        which are inputs to the inverse transform.
    bijective (bool): Whether this transform is bijective. A transform
        ``t`` is bijective iff ``t.inv(t(x)) == x`` and
        ``t(t.inv(y)) == y`` for every ``x`` in the domain and ``y`` in
        the codomain. Transforms that are not bijective should at least
        maintain the weaker pseudoinverse properties
        ``t(t.inv(t(x)) == t(x)`` and ``t.inv(t(t.inv(y))) == t.inv(y)``.
    sign (int or Tensor): For bijective univariate transforms, this
        should be +1 or -1 depending on whether transform is monotone
        increasing or decreasing.
    event_dim (int): Number of dimensions that are correlated together in
        the transform ``event_shape``. This should be 0 for pointwise
        transforms, 1 for transforms that act jointly on vectors, 2 for
        transforms that act jointly on matrices, etc.
",30,75,2158,45
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,_InverseTransform,"
Inverts a single :class:`Transform`.
This class is private; please instead use the ``Transform.inv`` property.
",169,171,110,2
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,ComposeTransform,"
Composes multiple transforms in a chain.
The transforms being composed are responsible for caching.

Args:
    parts (list of :class:`Transform`): A list of transforms to compose.
",214,219,179,5
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,ExpTransform,"
Transform via the mapping :math:`y = \exp(x)`.
",298,299,46,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,PowerTransform,"
Transform via the mapping :math:`y = x^{\text{exponent}}`.
",320,321,58,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,SigmoidTransform,"
Transform via the mapping :math:`y = \frac{1}{1 + \exp(-x)}` and :math:`x = \text{logit}(y)`.
",353,354,93,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,AbsTransform,"
Transform via the mapping :math:`y = |x|`.
",377,378,42,1
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,AffineTransform,"
Transform via the pointwise affine mapping :math:`y = \text{loc} + \text{scale} \times x`.

Args:
    loc (Tensor or float): Location parameter.
    scale (Tensor or float): Scale parameter.
    event_dim (int): Optional size of `event_shape`. This should be zero
        for univariate random variables, 1 for distributions over vectors,
        2 for distributions over matrices, etc.
",394,402,386,8
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,SoftmaxTransform,"
Transform from unconstrained space to the simplex via :math:`y = \exp(x)` then
normalizing.

This is not bijective and cannot be used for HMC. However this acts mostly
coordinate-wise (except for the final normalization), and thus is
appropriate for coordinate-wise optimization algorithms.
",461,467,290,6
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,StickBreakingTransform,"
Transform from unconstrained space to the simplex of one additional
dimension via a stick-breaking process.

This transform arises as an iterated sigmoid transform in a stick-breaking
construction of the `Dirichlet` distribution: the first logit is
transformed via sigmoid to the first probability and the probability of
everything else, and then the process recurses.

This is bijective and appropriate for use in HMC; however it mixes
coordinates together and is less appropriate for optimization.
",487,497,499,10
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,LowerCholeskyTransform,"
Transform from unconstrained matrices to lower-triangular matrices with
nonnegative diagonal entries.

This is useful for parameterizing positive definite matrices in terms of
their Cholesky factorization.
",533,538,205,5
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,CatTransform,"
Transform functor that applies a sequence of transforms `tseq`
component-wise to each submatrix at `dim`, of length `lengths[dim]`,
in a way compatible with :func:`torch.cat`.

Example::
   x0 = torch.cat([torch.range(1, 10), torch.range(1, 10)], dim=0)
   x = torch.cat([x0, x0], dim=0)
   t0 = CatTransform([ExpTransform(), identity_transform], dim=0, lengths=[10, 10])
   t = CatTransform([t0, t0], dim=0, lengths=[20, 20])
   y = t(x)
",555,565,438,10
C:\Users\vaano\python_projects\pytorch\torch\distributions\transforms.py,StackTransform,"
Transform functor that applies a sequence of transforms `tseq`
component-wise to each submatrix at `dim`
in a way compatible with :func:`torch.stack`.

Example::
   x = torch.stack([torch.range(1, 10), torch.range(1, 10)], dim=1)
   t = StackTransform([ExpTransform(), identity_transform], dim=1)
   y = t(x)
",633,641,308,8
C:\Users\vaano\python_projects\pytorch\torch\distributions\uniform.py,Uniform,"
Generates uniformly distributed random samples from the half-open interval
``[low, high)``.

Example::

    >>> m = Uniform(torch.tensor([0.0]), torch.tensor([5.0]))
    >>> m.sample()  # uniformly distributed in the range [0.0, 5.0)
    tensor([ 2.3418])

Args:
    low (float or Tensor): lower range (inclusive).
    high (float or Tensor): upper range (exclusive).
",10,22,367,12
C:\Users\vaano\python_projects\pytorch\torch\distributions\utils.py,lazy_property,"
Used as a decorator for lazy loading of class attributes. This uses a
non-data descriptor that calls the wrapped method to compute the property on
first call; thereafter replacing the wrapped method into an instance
attribute.
",89,93,226,4
C:\Users\vaano\python_projects\pytorch\torch\distributions\weibull.py,Weibull,"
Samples from a two-parameter Weibull distribution.

Example:

    >>> m = Weibull(torch.tensor([1.0]), torch.tensor([1.0]))
    >>> m.sample()  # sample from a Weibull distribution with scale=1, concentration=1
    tensor([ 0.4784])

Args:
    scale (float or Tensor): Scale parameter of distribution (lambda).
    concentration (float or Tensor): Concentration parameter of distribution (k/shape).
",11,22,398,11
C:\Users\vaano\python_projects\pytorch\torch\jit\annotations.py,Module,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\annotations.py,EvalEnv,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\frontend.py,FrontendError,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\frontend.py,NotSupportedError,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\frontend.py,UnsupportedNodeError,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\frontend.py,FrontendTypeError,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\frontend.py,SourceContext,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\frontend.py,Builder,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\frontend.py,StmtBuilder,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\frontend.py,ExprBuilder,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\quantized.py,QuantizedLinear,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\quantized.py,QuantizedLinearFP16,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\quantized.py,QuantizedRNNCellBase,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\quantized.py,QuantizedRNNCell,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\quantized.py,QuantizedLSTMCell,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\quantized.py,QuantizedGRUCell,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\quantized.py,QuantizedRNNBase,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\quantized.py,QuantizedLSTM,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\quantized.py,QuantizedGRU,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\_recursive.py,ConcreteTypeStore,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,ONNXTracedModule,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,TracingCheckError,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,TracerWarning,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,CompilationUnit,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,ScriptWarning,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,OrderedDictWrapper,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,OrderedModuleDict,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,ScriptMeta,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,TracedModule,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,_disable_tracing,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,_CachedForward,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,ScriptModule,"
``ScriptModule``s wrap a C++ ``torch::jit::script::Module``. ``ScriptModule``s
contain methods, attributes, parameters, and
constants. These can be accessed the same as on a normal ``nn.Module``.
",1515,1518,195,3
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,RecursiveScriptModule,"XXX: RecursiveScriptModule inherits from ScriptModule for the sole
        reason that it retains the existing isinstance(ScriptModule)
        behavior.
The core data structure in TorchScript is the ``ScriptModule``. It is an
analogue of torch's ``nn.Module`` and represents an entire model as a tree of
submodules. Like normal modules, each individual module in a ``ScriptModule`` can
have submodules, parameters, and methods. In ``nn.Module``\s methods are implemented
as Python functions, but in ``ScriptModule``\s methods are implemented as
TorchScript functions,  a statically-typed subset of Python that contains all
of PyTorch's built-in Tensor operations. This difference allows your
``ScriptModule``\s code to run without the need for a Python interpreter.

``ScriptModule``\s should not be created manually, instead use
either :func:`tracing <torch.jit.trace>` or :func:`scripting <torch.jit.script>`.
Tracing and scripting can be applied incrementally and :ref:`composed as necessary <Types>`.

* Tracing records the tensor operations as executed with a set of example inputs and uses these
  operations to construct a computation graph. You can use the full dynamic behavior of Python with tracing,
  but values other than Tensors and control flow aren't captured in the graph.

* Scripting inspects the Python code of the model
  and compiles it to TorchScript. Scripting allows the use of many `types`_ of values and supports dynamic control flow.
  Many, but not all features of Python are supported by the compiler, so changes to the source code may be necessary.
",1570,1590,1426,20
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,ScriptModule,,,,,
C:\Users\vaano\python_projects\pytorch\torch\jit\__init__.py,TopLevelTracedModule,,,,,
C:\Users\vaano\python_projects\pytorch\torch\multiprocessing\pool.py,Pool,"
Pool implementation which uses our version of SimpleQueue.
This lets us pass tensors in shared memory across processes instead of
serializing the underlying data.
",18,21,162,3
C:\Users\vaano\python_projects\pytorch\torch\multiprocessing\queue.py,ConnectionWrapper,"
Proxy class for _multiprocessing.Connection which uses ForkingPickler to
serialize objects
",9,11,90,2
C:\Users\vaano\python_projects\pytorch\torch\multiprocessing\queue.py,Queue,,,,,
C:\Users\vaano\python_projects\pytorch\torch\multiprocessing\queue.py,SimpleQueue,,,,,
C:\Users\vaano\python_projects\pytorch\torch\multiprocessing\reductions.py,StorageWeakRef,"
A weak reference to a Storage.

The cdata member is a Python number containing the integer representation of
the Storage pointer.
",23,27,129,4
C:\Users\vaano\python_projects\pytorch\torch\multiprocessing\reductions.py,SharedCache,"
dictionary from multiprocessing handles to StorageWeakRef
",42,43,57,1
C:\Users\vaano\python_projects\pytorch\torch\multiprocessing\spawn.py,ProcessContext,,,,,
C:\Users\vaano\python_projects\pytorch\torch\multiprocessing\spawn.py,SpawnContext,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\cpp.py,OrderedDictWrapper,"
A wrapper around a C++ OrderedDict that dynamically evaluates the
OrderedDict getter on a bound C++ module, such that new changes on the C++
side are picked up. Otherwise accessing e.g. ``cpp_module._parameters`` just
once would get a frozen copy of the parameters at the time of access.
``torch.nn.Module`` accesses ``_parameters`` et al. via ``self.__dict__`` so
using properties does not work.
",7,13,396,6
C:\Users\vaano\python_projects\pytorch\torch\nn\cpp.py,ModuleWrapper,"
A subclass of ``torch.nn.Module`` that wraps a C++ frontend module and
delegates all access.
",50,52,92,2
C:\Users\vaano\python_projects\pytorch\torch\nn\parameter.py,Parameter,"
A kind of Tensor that is to be considered a module parameter.

Parameters are :class:`~torch.Tensor` subclasses, that have a
very special property when used with :class:`Module` s - when they're
assigned as Module attributes they are automatically added to the list of
its parameters, and will appear e.g. in :meth:`~Module.parameters` iterator.
Assigning a Tensor doesn't have such effect. This is because one might
want to cache some temporary state, like last hidden state of the RNN, in
the model. If there was no such class as :class:`Parameter`, these
temporaries would get registered too.

Arguments:
    data (Tensor): parameter tensor.
    requires_grad (bool, optional): if the parameter requires gradient. See
        :ref:`excluding-subgraphs` for more details. Default: `True`
",6,21,789,15
C:\Users\vaano\python_projects\pytorch\torch\nn\_VF.py,VFModule,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\modules\fused.py,ConvReLU2d,"
This is a sequential container which calls the Conv 2d and ReLU modules.
During quantization this will be replaced with the corresponding fused module.
",6,8,151,2
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\modules\fused.py,ConvReLU3d,"
This is a sequential container which calls the Conv 3d and ReLU modules.
During quantization this will be replaced with the corresponding fused module.
",15,17,151,2
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\modules\fused.py,LinearReLU,"
This is a sequential container which calls the Linear and ReLU modules.
During quantization this will be replaced with the corresponding fused module.
",24,26,150,2
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\modules\fused.py,ConvBn2d,"
This is a sequential container which calls the Conv 2d and Batch Norm 2d modules.
During quantization this will be replaced with the corresponding fused module.
",33,35,160,2
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\modules\fused.py,ConvBnReLU2d,"
This is a sequential container which calls the Conv 2d, Batch Norm 2d, and ReLU modules.
During quantization this will be replaced with the corresponding fused module.
",42,44,167,2
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\qat\modules\conv_fused.py,_ConvBnNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\qat\modules\conv_fused.py,ConvBn2d,"
A ConvBn2d module is a module fused from Conv2d and BatchNorm2d,
attached with FakeQuantize modules for both output activation and weight,
used in quantization aware training.

We combined the interface of :class:`torch.nn.Conv2d` and
:class:`torch.nn.BatchNorm2d`.

Implementation details: https://arxiv.org/pdf/1806.08342.pdf section 3.2.2

Similar to :class:`torch.nn.Conv2d`, with FakeQuantize modules initialized
to default.

Attributes:
    freeze_bn:
    activation_post_process: fake quant module for output activation
    weight_fake_quant: fake quant module for weight
",157,173,578,16
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\qat\modules\conv_fused.py,ConvBnReLU2d,"
A ConvBnReLU2d module is a module fused from Conv2d, BatchNorm2d and ReLU,
attached with FakeQuantize modules for both output activation and weight,
used in quantization aware training.

We combined the interface of :class:`torch.nn.Conv2d` and
:class:`torch.nn.BatchNorm2d` and :class:`torch.nn.ReLU`.

Implementation details: https://arxiv.org/pdf/1806.08342.pdf

Similar to `torch.nn.Conv2d`, with FakeQuantize modules initialized to
default.

Attributes:
    observer: fake quant module for output activation, it's called observer
        to align with post training flow
    weight_fake_quant: fake quant module for weight
",201,217,627,16
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\qat\modules\conv_fused.py,ConvReLU2d,"
A ConvReLU2d module is a fused module of Conv2d and ReLU, attached with
FakeQuantize modules for both output activation and weight for
quantization aware training.

We combined the interface of :class:`~torch.nn.Conv2d` and
:class:`~torch.nn.BatchNorm2d`.

Attributes:
    activation_post_process: fake quant module for output activation
    weight_fake_quant: fake quant module for weight
",250,260,389,10
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\qat\modules\linear_relu.py,LinearReLU,"
A LinearReLU module fused from Linear and ReLU modules, attached with
FakeQuantize modules for output activation and weight, used in
quantization aware training.

We adopt the same interface as :class:`torch.nn.Linear`.

Similar to `torch.nn.intrinsic.LinearReLU`, with FakeQuantize modules initialized to
default.

Attributes:
    activation_post_process: fake quant module for output activation
    weight: fake quant module for weight

Examples::

    >>> m = nn.qat.LinearReLU(20, 30)
    >>> input = torch.randn(128, 20)
    >>> output = m(input)
    >>> print(output.size())
    torch.Size([128, 30])
",7,27,606,20
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\quantized\modules\conv_relu.py,ConvReLU2d,"
A ConvReLU2d module is a fused module of Conv2d and ReLU

We adopt the same interface as :class:`torch.nn.quantized.Conv2d`.

Attributes:
    Same as torch.nn.quantized.Conv2d
",12,18,175,6
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\quantized\modules\conv_relu.py,ConvReLU3d,"
A ConvReLU3d module is a fused module of Conv3d and ReLU

We adopt the same interface as :class:`torch.nn.quantized.Conv3d`.

.. note::
Attributes: Same as torch.nn.quantized.Conv3d
",53,59,181,6
C:\Users\vaano\python_projects\pytorch\torch\nn\intrinsic\quantized\modules\linear_relu.py,LinearReLU,"
A LinearReLU module fused from Linear and ReLU modules

We adopt the same interface as :class:`torch.nn.quantized.Linear`.

Attributes:
    Same as torch.nn.quantized.Linear

Examples::

    >>> m = nn.intrinsic.LinearReLU(20, 30)
    >>> input = torch.randn(128, 20)
    >>> output = m(input)
    >>> print(output.size())
    torch.Size([128, 30])
",7,21,348,14
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,Threshold,"
Thresholds each element of the input Tensor.

Threshold is defined as:

.. math::
    y =
    \begin{cases}
    x, &\text{ if } x > \text{threshold} \\
    \text{value}, &\text{ otherwise }
    \end{cases}

Args:
    threshold: The value to threshold at
    value: The value to replace with
    inplace: can optionally do the operation in-place. Default: ``False``

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

Examples::

    >>> m = nn.Threshold(0.1, 20)
    >>> input = torch.randn(2)
    >>> output = m(input)
",13,39,617,26
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,ReLU,"
Applies the rectified linear unit function element-wise:

:math:`\text{ReLU}(x)= \max(0, x)`

Args:
    inplace: can optionally do the operation in-place. Default: ``False``

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/ReLU.png

Examples::

    >>> m = nn.ReLU()
    >>> input = torch.randn(2)
    >>> output = m(input)


  An implementation of CReLU - https://arxiv.org/abs/1603.05201

    >>> m = nn.ReLU()
    >>> input = torch.randn(2).unsqueeze(0)
    >>> output = torch.cat((m(input),m(-input)))
",60,86,643,26
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,RReLU,"
Applies the randomized leaky rectified liner unit function, element-wise,
as described in the paper:

`Empirical Evaluation of Rectified Activations in Convolutional Network`_.

The function is defined as:

.. math::
    \text{RReLU}(x) =
    \begin{cases}
        x & \text{if } x \geq 0 \\
        ax & \text{ otherwise }
    \end{cases}

where :math:`a` is randomly sampled from uniform distribution
:math:`\mathcal{U}(\text{lower}, \text{upper})`.

 See: https://arxiv.org/pdf/1505.00853.pdf

Args:
    lower: lower bound of the uniform distribution. Default: :math:`\frac{1}{8}`
    upper: upper bound of the uniform distribution. Default: :math:`\frac{1}{3}`
    inplace: can optionally do the operation in-place. Default: ``False``

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

Examples::

    >>> m = nn.RReLU(0.1, 0.3)
    >>> input = torch.randn(2)
    >>> output = m(input)

.. _`Empirical Evaluation of Rectified Activations in Convolutional Network`:
    https://arxiv.org/abs/1505.00853
",102,139,1104,37
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,Hardtanh,"
Applies the HardTanh function element-wise

HardTanh is defined as:

.. math::
    \text{HardTanh}(x) = \begin{cases}
        1 & \text{ if } x > 1 \\
        -1 & \text{ if } x < -1 \\
        x & \text{ otherwise } \\
    \end{cases}

The range of the linear region :math:`[-1, 1]` can be adjusted using
:attr:`min_val` and :attr:`max_val`.

Args:
    min_val: minimum value of the linear region range. Default: -1
    max_val: maximum value of the linear region range. Default: 1
    inplace: can optionally do the operation in-place. Default: ``False``

Keyword arguments :attr:`min_value` and :attr:`max_value`
have been deprecated in favor of :attr:`min_val` and :attr:`max_val`.

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/Hardtanh.png

Examples::

    >>> m = nn.Hardtanh(-2, 2)
    >>> input = torch.randn(2)
    >>> output = m(input)
",157,191,986,34
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,ReLU6,"
Applies the element-wise function:

.. math::
    \text{ReLU6}(x) = \min(\max(0,x), 6)

Args:
    inplace: can optionally do the operation in-place. Default: ``False``

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/ReLU6.png

Examples::

    >>> m = nn.ReLU6()
    >>> input = torch.randn(2)
    >>> output = m(input)
",219,239,457,20
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,Sigmoid,"
Applies the element-wise function:

.. math::
    \text{Sigmoid}(x) = \frac{1}{1 + \exp(-x)}


Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/Sigmoid.png

Examples::

    >>> m = nn.Sigmoid()
    >>> input = torch.randn(2)
    >>> output = m(input)
",250,268,387,18
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,Tanh,"
Applies the element-wise function:

.. math::
    \text{Tanh}(x) = \tanh(x) = \frac{e^x - e^{-x}} {e^x + e^{-x}}

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/Tanh.png

Examples::

    >>> m = nn.Tanh()
    >>> input = torch.randn(2)
    >>> output = m(input)
",275,292,400,17
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,ELU,"
Applies the element-wise function:

.. math::
    \text{ELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x) - 1))

Args:
    alpha: the :math:`\alpha` value for the ELU formulation. Default: 1.0
    inplace: can optionally do the operation in-place. Default: ``False``

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/ELU.png

Examples::

    >>> m = nn.ELU()
    >>> input = torch.randn(2)
    >>> output = m(input)
",299,320,550,21
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,CELU,"
Applies the element-wise function:

.. math::
    \text{CELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x/\alpha) - 1))

More details can be found in the paper `Continuously Differentiable Exponential Linear Units`_ .

Args:
    alpha: the :math:`\alpha` value for the CELU formulation. Default: 1.0
    inplace: can optionally do the operation in-place. Default: ``False``

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/CELU.png

Examples::

    >>> m = nn.CELU()
    >>> input = torch.randn(2)
    >>> output = m(input)

.. _`Continuously Differentiable Exponential Linear Units`:
    https://arxiv.org/abs/1704.07483
",337,363,757,26
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,SELU,"
Applied element-wise, as:

.. math::
    \text{SELU}(x) = \text{scale} * (\max(0,x) + \min(0, \alpha * (\exp(x) - 1)))

with :math:`\alpha = 1.6732632423543772848170429916717` and
:math:`\text{scale} = 1.0507009873554804934193349852946`.

More details can be found in the paper `Self-Normalizing Neural Networks`_ .

Args:
    inplace (bool, optional): can optionally do the operation in-place. Default: ``False``

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/SELU.png

Examples::

    >>> m = nn.SELU()
    >>> input = torch.randn(2)
    >>> output = m(input)

.. _Self-Normalizing Neural Networks: https://arxiv.org/abs/1706.02515
",380,407,773,27
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,GLU,"
Applies the gated linear unit function
:math:`{GLU}(a, b)= a \otimes \sigma(b)` where :math:`a` is the first half
of the input matrices and :math:`b` is the second half.

Args:
    dim (int): the dimension on which to split the input. Default: -1

Shape:
    - Input: :math:`(\ast_1, N, \ast_2)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(\ast_1, M, \ast_2)` where :math:`M=N/2`

Examples::

    >>> m = nn.GLU()
    >>> input = torch.randn(4, 2)
    >>> output = m(input)
",423,440,510,17
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,GELU,"
Applies the Gaussian Error Linear Units function:

.. math::
    \text{GELU}(x) = x * \Phi(x)
where :math:`\Phi(x)` is the Cumulative Distribution Function for Gaussian Distribution.

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/GELU.png

Examples::

    >>> m = nn.GELU()
    >>> input = torch.randn(2)
    >>> output = m(input)
",455,473,470,18
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,Hardshrink,"
Applies the hard shrinkage function element-wise:

.. math::
    \text{HardShrink}(x) =
    \begin{cases}
    x, & \text{ if } x > \lambda \\
    x, & \text{ if } x < -\lambda \\
    0, & \text{ otherwise }
    \end{cases}

Args:
    lambd: the :math:`\lambda` value for the Hardshrink formulation. Default: 0.5

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/Hardshrink.png

Examples::

    >>> m = nn.Hardshrink()
    >>> input = torch.randn(2)
    >>> output = m(input)
",479,504,611,25
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,LeakyReLU,"
Applies the element-wise function:

.. math::
    \text{LeakyReLU}(x) = \max(0, x) + \text{negative\_slope} * \min(0, x)


or

.. math::
    \text{LeakyRELU}(x) =
    \begin{cases}
    x, & \text{ if } x \geq 0 \\
    \text{negative\_slope} \times x, & \text{ otherwise }
    \end{cases}

Args:
    negative_slope: Controls the angle of the negative slope. Default: 1e-2
    inplace: can optionally do the operation in-place. Default: ``False``

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/LeakyReLU.png

Examples::

    >>> m = nn.LeakyReLU(0.1)
    >>> input = torch.randn(2)
    >>> output = m(input)
",519,550,745,31
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,LogSigmoid,"
Applies the element-wise function:

.. math::
    \text{LogSigmoid}(x) = \log\left(\frac{ 1 }{ 1 + \exp(-x)}\right)

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/LogSigmoid.png

Examples::

    >>> m = nn.LogSigmoid()
    >>> input = torch.randn(2)
    >>> output = m(input)
",567,584,415,17
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,Softplus,"
Applies the element-wise function:

.. math::
    \text{Softplus}(x) = \frac{1}{\beta} * \log(1 + \exp(\beta * x))

SoftPlus is a smooth approximation to the ReLU function and can be used
to constrain the output of a machine to always be positive.

For numerical stability the implementation reverts to the linear function
for inputs above :attr:`threshold` (default ``20``).

Args:
    beta: the :math:`\beta` value for the Softplus formulation. Default: 1
    threshold: values above this revert to a linear function. Default: 20

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/Softplus.png

Examples::

    >>> m = nn.Softplus()
    >>> input = torch.randn(2)
    >>> output = m(input)
",591,618,827,27
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,Softshrink,"
Applies the soft shrinkage function elementwise:

.. math::
    \text{SoftShrinkage}(x) =
    \begin{cases}
    x - \lambda, & \text{ if } x > \lambda \\
    x + \lambda, & \text{ if } x < -\lambda \\
    0, & \text{ otherwise }
    \end{cases}

Args:
    lambd: the :math:`\lambda` value for the Softshrink formulation. Default: 0.5

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/Softshrink.png

Examples::

    >>> m = nn.Softshrink()
    >>> input = torch.randn(2)
    >>> output = m(input)
",634,659,633,25
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,MultiheadAttention,"
Allows the model to jointly attend to information
from different representation subspaces.
See reference: Attention Is All You Need

.. math::
    \text{MultiHead}(Q, K, V) = \text{Concat}(head_1,\dots,head_h)W^O
    \text{where} head_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)

Args:
    embed_dim: total dimension of the model.
    num_heads: parallel attention heads.
    dropout: a Dropout layer on attn_output_weights. Default: 0.0.
    bias: add bias as module parameter. Default: True.
    add_bias_kv: add bias to the key and value sequences at dim=0.
    add_zero_attn: add a new batch of zeros to the key and
                   value sequences at dim=1.
    kdim: total number of features in key. Default: None.
    vdim: total number of features in key. Default: None.

    Note: if kdim and vdim are None, they will be set to embed_dim such that
    query, key, and value have the same number of features.

Examples::

    >>> multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)
    >>> attn_output, attn_output_weights = multihead_attn(query, key, value)
",674,700,1078,26
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,PReLU,"
Applies the element-wise function:

.. math::
    \text{PReLU}(x) = \max(0,x) + a * \min(0,x)

or

.. math::
    \text{PReLU}(x) =
    \begin{cases}
    x, & \text{ if } x \geq 0 \\
    ax, & \text{ otherwise }
    \end{cases}

Here :math:`a` is a learnable parameter. When called without arguments, `nn.PReLU()` uses a single
parameter :math:`a` across all input channels. If called with `nn.PReLU(nChannels)`,
a separate :math:`a` is used for each input channel.


.. note::
    weight decay should not be used when learning :math:`a` for good performance.

.. note::
    Channel dim is the 2nd dim of input. When input has dims < 2, then there is
    no channel dim and the number of channels = 1.

Args:
    num_parameters (int): number of :math:`a` to learn.
        Although it takes an int as input, there is only two values are legitimate:
        1, or the number of channels at input. Default: 1
    init (float): the initial value of :math:`a`. Default: 0.25

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

Attributes:
    weight (Tensor): the learnable weights of shape (:attr:`num_parameters`).

.. image:: scripts/activation_images/PReLU.png

Examples::

    >>> m = nn.PReLU()
    >>> input = torch.randn(2)
    >>> output = m(input)
",823,870,1350,47
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,Softsign,"
Applies the element-wise function:

.. math::
    \text{SoftSign}(x) = \frac{x}{ 1 + |x|}

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/Softsign.png

Examples::

    >>> m = nn.Softsign()
    >>> input = torch.randn(2)
    >>> output = m(input)
",886,903,385,17
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,Tanhshrink,"
Applies the element-wise function:

.. math::
    \text{Tanhshrink}(x) = x - \text{Tanh}(x)

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/Tanhshrink.png

Examples::

    >>> m = nn.Tanhshrink()
    >>> input = torch.randn(2)
    >>> output = m(input)
",910,927,391,17
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,Softmin,"
Applies the Softmin function to an n-dimensional input Tensor
rescaling them so that the elements of the n-dimensional output Tensor
lie in the range `[0, 1]` and sum to 1.

Softmin is defined as:

.. math::
    \text{Softmin}(x_{i}) = \frac{\exp(-x_i)}{\sum_j \exp(-x_j)}

Shape:
    - Input: :math:`(*)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(*)`, same shape as the input

Arguments:
    dim (int): A dimension along which Softmin will be computed (so every slice
        along dim will sum to 1).

Returns:
    a Tensor of the same dimension and shape as the input, with
    values in the range [0, 1]

Examples::

    >>> m = nn.Softmin()
    >>> input = torch.randn(2, 3)
    >>> output = m(input)
",934,961,744,27
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,Softmax,"
Applies the Softmax function to an n-dimensional input Tensor
rescaling them so that the elements of the n-dimensional output Tensor
lie in the range [0,1] and sum to 1.

Softmax is defined as:

.. math::
    \text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}

Shape:
    - Input: :math:`(*)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(*)`, same shape as the input

Returns:
    a Tensor of the same dimension and shape as the input with
    values in the range [0, 1]

Arguments:
    dim (int): A dimension along which Softmax will be computed (so every slice
        along dim will sum to 1).

.. note::
    This module doesn't work directly with NLLLoss,
    which expects the Log to be computed between the Softmax and itself.
    Use `LogSoftmax` instead (it's faster and has better numerical properties).

Examples::

    >>> m = nn.Softmax(dim=1)
    >>> input = torch.randn(2, 3)
    >>> output = m(input)
",973,1005,959,32
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,Softmax2d,"
Applies SoftMax over features to each spatial location.

When given an image of ``Channels x Height x Width``, it will
apply `Softmax` to each location :math:`(Channels, h_i, w_j)`

Shape:
    - Input: :math:`(N, C, H, W)`
    - Output: :math:`(N, C, H, W)` (same shape as input)

Returns:
    a Tensor of the same dimension and shape as the input with
    values in the range [0, 1]

Examples::

    >>> m = nn.Softmax2d()
    >>> # you softmax over the 2nd dimension
    >>> input = torch.randn(2, 3, 12, 13)
    >>> output = m(input)
",1025,1044,536,19
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\activation.py,LogSoftmax,"
Applies the :math:`\log(\text{Softmax}(x))` function to an n-dimensional
input Tensor. The LogSoftmax formulation can be simplified as:

.. math::
    \text{LogSoftmax}(x_{i}) = \log\left(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} \right)

Shape:
    - Input: :math:`(*)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(*)`, same shape as the input

Arguments:
    dim (int): A dimension along which LogSoftmax will be computed.

Returns:
    a Tensor of the same dimension and shape as the input with
    values in the range [-inf, 0)

Examples::

    >>> m = nn.LogSoftmax()
    >>> input = torch.randn(2, 3)
    >>> output = m(input)
",1052,1075,663,23
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\adaptive.py,AdaptiveLogSoftmaxWithLoss,"
Efficient softmax approximation as described in
`Efficient softmax approximation for GPUs`_ by Edouard Grave, Armand Joulin,
Moustapha Ciss, David Grangier, and Herv Jgou.

Adaptive softmax is an approximate strategy for training models with large
output spaces. It is most effective when the label distribution is highly
imbalanced, for example in natural language modelling, where the word
frequency distribution approximately follows the `Zipf's law`_.

Adaptive softmax partitions the labels into several clusters, according to
their frequency. These clusters may contain different number of targets
each.
Additionally, clusters containing less frequent labels assign lower
dimensional embeddings to those labels, which speeds up the computation.
For each minibatch, only clusters for which at least one target is
present are evaluated.

The idea is that the clusters which are accessed frequently
(like the first one, containing most frequent labels), should also be cheap
to compute -- that is, contain a small number of assigned labels.

We highly recommend taking a look at the original paper for more details.

* :attr:`cutoffs` should be an ordered Sequence of integers sorted
  in the increasing order.
  It controls number of clusters and the partitioning of targets into
  clusters. For example setting ``cutoffs = [10, 100, 1000]``
  means that first `10` targets will be assigned
  to the 'head' of the adaptive softmax, targets `11, 12, ..., 100` will be
  assigned to the first cluster, and targets `101, 102, ..., 1000` will be
  assigned to the second cluster, while targets
  `1001, 1002, ..., n_classes - 1` will be assigned
  to the last, third cluster.

* :attr:`div_value` is used to compute the size of each additional cluster,
  which is given as
  :math:`\left\lfloor\frac{in\_features}{div\_value^{idx}}\right\rfloor`,
  where :math:`idx` is the cluster index (with clusters
  for less frequent words having larger indices,
  and indices starting from :math:`1`).

* :attr:`head_bias` if set to True, adds a bias term to the 'head' of the
  adaptive softmax. See paper for details. Set to False in the official
  implementation.

.. warning::
    Labels passed as inputs to this module should be sorted accoridng to
    their frequency. This means that the most frequent label should be
    represented by the index `0`, and the least frequent
    label should be represented by the index `n_classes - 1`.

.. note::
    This module returns a ``NamedTuple`` with ``output``
    and ``loss`` fields. See further documentation for details.

.. note::
    To compute log-probabilities for all classes, the ``log_prob``
    method can be used.

Args:
    in_features (int): Number of features in the input tensor
    n_classes (int): Number of classes in the dataset
    cutoffs (Sequence): Cutoffs used to assign targets to their buckets
    div_value (float, optional): value used as an exponent to compute sizes
        of the clusters. Default: 4.0
    head_bias (bool, optional): If ``True``, adds a bias term to the 'head' of the
        adaptive softmax. Default: ``False``

Returns:
    ``NamedTuple`` with ``output`` and ``loss`` fields:
        * **output** is a Tensor of size ``N`` containing computed target
          log probabilities for each example
        * **loss** is a Scalar representing the computed negative
          log likelihood loss

Shape:
    - input: :math:`(N, in\_features)`
    - target: :math:`(N)` where each value satisfies :math:`0 <= target[i] <= n\_classes`
    - output1: :math:`(N)`
    - output2: ``Scalar``


.. _Efficient softmax approximation for GPUs:
    https://arxiv.org/abs/1609.04309

.. _Zipf's law:
    https://en.wikipedia.org/wiki/Zipf%27s_law
",16,103,3727,87
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\batchnorm.py,_NormBase,"
Common base of _InstanceNorm and _BatchNorm
",12,13,43,1
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\batchnorm.py,_BatchNorm,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\batchnorm.py,BatchNorm1d,"
Applies Batch Normalization over a 2D or 3D input (a mini-batch of 1D
inputs with optional additional channel dimension) as described in the paper
`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`_ .

.. math::

    y = \frac{x - \mathrm{E}[x]}{\sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta

The mean and standard-deviation are calculated per-dimension over
the mini-batches and :math:`\gamma` and :math:`\beta` are learnable parameter vectors
of size `C` (where `C` is the input size). By default, the elements of :math:`\gamma` are set
to 1 and the elements of :math:`\beta` are set to 0.

Also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default :attr:`momentum`
of 0.1.

If :attr:`track_running_stats` is set to ``False``, this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well.

.. note::
    This :attr:`momentum` argument is different from one used in optimizer
    classes and the conventional notion of momentum. Mathematically, the
    update rule for running statistics here is
    :math:`\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momentum} \times x_t`,
    where :math:`\hat{x}` is the estimated statistic and :math:`x_t` is the
    new observed value.

Because the Batch Normalization is done over the `C` dimension, computing statistics
on `(N, L)` slices, it's common terminology to call this Temporal Batch Normalization.

Args:
    num_features: :math:`C` from an expected input of size
        :math:`(N, C, L)` or :math:`L` from input of size :math:`(N, L)`
    eps: a value added to the denominator for numerical stability.
        Default: 1e-5
    momentum: the value used for the running_mean and running_var
        computation. Can be set to ``None`` for cumulative moving average
        (i.e. simple average). Default: 0.1
    affine: a boolean value that when set to ``True``, this module has
        learnable affine parameters. Default: ``True``
    track_running_stats: a boolean value that when set to ``True``, this
        module tracks the running mean and variance, and when set to ``False``,
        this module does not track such statistics and always uses batch
        statistics in both training and eval modes. Default: ``True``

Shape:
    - Input: :math:`(N, C)` or :math:`(N, C, L)`
    - Output: :math:`(N, C)` or :math:`(N, C, L)` (same shape as input)

Examples::

    >>> # With Learnable Parameters
    >>> m = nn.BatchNorm1d(100)
    >>> # Without Learnable Parameters
    >>> m = nn.BatchNorm1d(100, affine=False)
    >>> input = torch.randn(20, 100)
    >>> output = m(input)

.. _`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`:
    https://arxiv.org/abs/1502.03167
",111,174,2954,63
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\batchnorm.py,BatchNorm2d,"
Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs
with additional channel dimension) as described in the paper
`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`_ .

.. math::

    y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta

The mean and standard-deviation are calculated per-dimension over
the mini-batches and :math:`\gamma` and :math:`\beta` are learnable parameter vectors
of size `C` (where `C` is the input size). By default, the elements of :math:`\gamma` are set
to 1 and the elements of :math:`\beta` are set to 0.

Also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default :attr:`momentum`
of 0.1.

If :attr:`track_running_stats` is set to ``False``, this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well.

.. note::
    This :attr:`momentum` argument is different from one used in optimizer
    classes and the conventional notion of momentum. Mathematically, the
    update rule for running statistics here is
    :math:`\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momentum} \times x_t`,
    where :math:`\hat{x}` is the estimated statistic and :math:`x_t` is the
    new observed value.

Because the Batch Normalization is done over the `C` dimension, computing statistics
on `(N, H, W)` slices, it's common terminology to call this Spatial Batch Normalization.

Args:
    num_features: :math:`C` from an expected input of size
        :math:`(N, C, H, W)`
    eps: a value added to the denominator for numerical stability.
        Default: 1e-5
    momentum: the value used for the running_mean and running_var
        computation. Can be set to ``None`` for cumulative moving average
        (i.e. simple average). Default: 0.1
    affine: a boolean value that when set to ``True``, this module has
        learnable affine parameters. Default: ``True``
    track_running_stats: a boolean value that when set to ``True``, this
        module tracks the running mean and variance, and when set to ``False``,
        this module does not track such statistics and always uses batch
        statistics in both training and eval modes. Default: ``True``

Shape:
    - Input: :math:`(N, C, H, W)`
    - Output: :math:`(N, C, H, W)` (same shape as input)

Examples::

    >>> # With Learnable Parameters
    >>> m = nn.BatchNorm2d(100)
    >>> # Without Learnable Parameters
    >>> m = nn.BatchNorm2d(100, affine=False)
    >>> input = torch.randn(20, 100, 35, 45)
    >>> output = m(input)

.. _`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`:
    https://arxiv.org/abs/1502.03167
",183,246,2876,63
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\batchnorm.py,BatchNorm3d,"
Applies Batch Normalization over a 5D input (a mini-batch of 3D inputs
with additional channel dimension) as described in the paper
`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`_ .

.. math::

    y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta

The mean and standard-deviation are calculated per-dimension over
the mini-batches and :math:`\gamma` and :math:`\beta` are learnable parameter vectors
of size `C` (where `C` is the input size). By default, the elements of :math:`\gamma` are set
to 1 and the elements of :math:`\beta` are set to 0.

Also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default :attr:`momentum`
of 0.1.

If :attr:`track_running_stats` is set to ``False``, this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well.

.. note::
    This :attr:`momentum` argument is different from one used in optimizer
    classes and the conventional notion of momentum. Mathematically, the
    update rule for running statistics here is
    :math:`\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momentum} \times x_t`,
    where :math:`\hat{x}` is the estimated statistic and :math:`x_t` is the
    new observed value.

Because the Batch Normalization is done over the `C` dimension, computing statistics
on `(N, D, H, W)` slices, it's common terminology to call this Volumetric Batch Normalization
or Spatio-temporal Batch Normalization.

Args:
    num_features: :math:`C` from an expected input of size
        :math:`(N, C, D, H, W)`
    eps: a value added to the denominator for numerical stability.
        Default: 1e-5
    momentum: the value used for the running_mean and running_var
        computation. Can be set to ``None`` for cumulative moving average
        (i.e. simple average). Default: 0.1
    affine: a boolean value that when set to ``True``, this module has
        learnable affine parameters. Default: ``True``
    track_running_stats: a boolean value that when set to ``True``, this
        module tracks the running mean and variance, and when set to ``False``,
        this module does not track such statistics and always uses batch
        statistics in both training and eval modes. Default: ``True``

Shape:
    - Input: :math:`(N, C, D, H, W)`
    - Output: :math:`(N, C, D, H, W)` (same shape as input)

Examples::

    >>> # With Learnable Parameters
    >>> m = nn.BatchNorm3d(100)
    >>> # Without Learnable Parameters
    >>> m = nn.BatchNorm3d(100, affine=False)
    >>> input = torch.randn(20, 100, 35, 45, 10)
    >>> output = m(input)

.. _`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`:
    https://arxiv.org/abs/1502.03167
",255,319,2934,64
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\batchnorm.py,SyncBatchNorm,"
Applies Batch Normalization over a N-Dimensional input (a mini-batch of [N-2]D inputs
with additional channel dimension) as described in the paper
`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`_ .

.. math::

    y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta

The mean and standard-deviation are calculated per-dimension over all
mini-batches of the same process groups. :math:`\gamma` and :math:`\beta`
are learnable parameter vectors of size `C` (where `C` is the input size).
By default, the elements of :math:`\gamma` are sampled from
:math:`\mathcal{U}(0, 1)` and the elements of :math:`\beta` are set to 0.

Also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default :attr:`momentum`
of 0.1.

If :attr:`track_running_stats` is set to ``False``, this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well.

.. note::
    This :attr:`momentum` argument is different from one used in optimizer
    classes and the conventional notion of momentum. Mathematically, the
    update rule for running statistics here is
    :math:`\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momemtum} \times x_t`,
    where :math:`\hat{x}` is the estimated statistic and :math:`x_t` is the
    new observed value.

Because the Batch Normalization is done over the `C` dimension, computing statistics
on `(N, +)` slices, it's common terminology to call this Volumetric Batch Normalization
or Spatio-temporal Batch Normalization.

Currently SyncBatchNorm only supports DistributedDataParallel with single GPU per process. Use
torch.nn.SyncBatchNorm.convert_sync_batchnorm() to convert BatchNorm layer to SyncBatchNorm before wrapping
Network with DDP.

Args:
    num_features: :math:`C` from an expected input of size
        :math:`(N, C, +)`
    eps: a value added to the denominator for numerical stability.
        Default: 1e-5
    momentum: the value used for the running_mean and running_var
        computation. Can be set to ``None`` for cumulative moving average
        (i.e. simple average). Default: 0.1
    affine: a boolean value that when set to ``True``, this module has
        learnable affine parameters. Default: ``True``
    track_running_stats: a boolean value that when set to ``True``, this
        module tracks the running mean and variance, and when set to ``False``,
        this module does not track such statistics and always uses batch
        statistics in both training and eval modes. Default: ``True``
    process_group: synchronization of stats happen within each process group
        individually. Default behavior is synchronization across the whole
        world

Shape:
    - Input: :math:`(N, C, +)`
    - Output: :math:`(N, C, +)` (same shape as input)

Examples::

    >>> # With Learnable Parameters
    >>> m = nn.SyncBatchNorm(100)
    >>> # creating process group (optional)
    >>> # process_ids is a list of int identifying rank ids.
    >>> process_group = torch.distributed.new_group(process_ids)
    >>> # Without Learnable Parameters
    >>> m = nn.BatchNorm3d(100, affine=False, process_group=process_group)
    >>> input = torch.randn(20, 100, 35, 45, 10)
    >>> output = m(input)

    >>> # network is nn.BatchNorm layer
    >>> sync_bn_network = nn.SyncBatchNorm.convert_sync_batchnorm(network, process_group)
    >>> # only single gpu per process is currently supported
    >>> ddp_sync_bn_network = torch.nn.parallel.DistributedDataParallel(
    >>>                         sync_bn_network,
    >>>                         device_ids=[args.local_rank],
    >>>                         output_device=args.local_rank)

.. _`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`:
    https://arxiv.org/abs/1502.03167
",328,411,4007,83
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\container.py,Container,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\container.py,Sequential,"
A sequential container.
Modules will be added to it in the order they are passed in the constructor.
Alternatively, an ordered dict of modules can also be passed in.

To make it easier to understand, here is a small example::

    # Example of using Sequential
    model = nn.Sequential(
              nn.Conv2d(1,20,5),
              nn.ReLU(),
              nn.Conv2d(20,64,5),
              nn.ReLU()
            )

    # Example of using Sequential with OrderedDict
    model = nn.Sequential(OrderedDict([
              ('conv1', nn.Conv2d(1,20,5)),
              ('relu1', nn.ReLU()),
              ('conv2', nn.Conv2d(20,64,5)),
              ('relu2', nn.ReLU())
            ]))
",24,45,685,21
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\container.py,ModuleList,"
Holds submodules in a list.

:class:`~torch.nn.ModuleList` can be indexed like a regular Python list, but
modules it contains are properly registered, and will be visible by all
:class:`~torch.nn.Module` methods.

Arguments:
    modules (iterable, optional): an iterable of modules to add

Example::

    class MyModule(nn.Module):
        def __init__(self):
            super(MyModule, self).__init__()
            self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])

        def forward(self, x):
            # ModuleList can act as an iterable, or be indexed using ints
            for i, l in enumerate(self.linears):
                x = self.linears[i // 2](x) + l(x)
            return x
",105,126,711,21
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\container.py,ModuleDict,"
Holds submodules in a dictionary.

:class:`~torch.nn.ModuleDict` can be indexed like a regular Python dictionary,
but modules it contains are properly registered, and will be visible by all
:class:`~torch.nn.Module` methods.

:class:`~torch.nn.ModuleDict` is an **ordered** dictionary that respects

* the order of insertion, and

* in :meth:`~torch.nn.ModuleDict.update`, the order of the merged ``OrderedDict``
  or another :class:`~torch.nn.ModuleDict` (the argument to :meth:`~torch.nn.ModuleDict.update`).

Note that :meth:`~torch.nn.ModuleDict.update` with other unordered mapping
types (e.g., Python's plain ``dict``) does not preserve the order of the
merged mapping.

Arguments:
    modules (iterable, optional): a mapping (dictionary) of (string: module)
        or an iterable of key-value pairs of type (string, module)

Example::

    class MyModule(nn.Module):
        def __init__(self):
            super(MyModule, self).__init__()
            self.choices = nn.ModuleDict({
                    'conv': nn.Conv2d(10, 10, 3),
                    'pool': nn.MaxPool2d(3)
            })
            self.activations = nn.ModuleDict([
                    ['lrelu', nn.LeakyReLU()],
                    ['prelu', nn.PReLU()]
            ])

        def forward(self, x, choice, act):
            x = self.choices[choice](x)
            x = self.activations[act](x)
            return x
",216,255,1396,39
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\container.py,ParameterList,"
Holds parameters in a list.

:class:`~torch.nn.ParameterList` can be indexed like a regular Python
list, but parameters it contains are properly registered, and will be
visible by all :class:`~torch.nn.Module` methods.

Arguments:
    parameters (iterable, optional): an iterable of :class:`~torch.nn.Parameter` to add

Example::

    class MyModule(nn.Module):
        def __init__(self):
            super(MyModule, self).__init__()
            self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)])

        def forward(self, x):
            # ParameterList can act as an iterable, or be indexed using ints
            for i, p in enumerate(self.params):
                x = self.params[i // 2].mm(x) + p.mm(x)
            return x
",358,379,766,21
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\container.py,ParameterDict,"
Holds parameters in a dictionary.

ParameterDict can be indexed like a regular Python dictionary, but parameters it
contains are properly registered, and will be visible by all Module methods.

:class:`~torch.nn.ParameterDict` is an **ordered** dictionary that respects

* the order of insertion, and

* in :meth:`~torch.nn.ParameterDict.update`, the order of the merged ``OrderedDict``
  or another :class:`~torch.nn.ParameterDict` (the argument to
  :meth:`~torch.nn.ParameterDict.update`).

Note that :meth:`~torch.nn.ParameterDict.update` with other unordered mapping
types (e.g., Python's plain ``dict``) does not preserve the order of the
merged mapping.

Arguments:
    parameters (iterable, optional): a mapping (dictionary) of
        (string : :class:`~torch.nn.Parameter`) or an iterable of key-value pairs
        of type (string, :class:`~torch.nn.Parameter`)

Example::

    class MyModule(nn.Module):
        def __init__(self):
            super(MyModule, self).__init__()
            self.params = nn.ParameterDict({
                    'left': nn.Parameter(torch.randn(5, 10)),
                    'right': nn.Parameter(torch.randn(5, 10))
            })

        def forward(self, x, choice):
            x = self.params[choice].mm(x)
            return x
",456,491,1274,35
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\conv.py,_ConvNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\conv.py,Conv1d,"
Applies a 1D convolution over an input signal composed of several input
planes.

In the simplest case, the output value of the layer with input size
:math:`(N, C_{\text{in}}, L)` and output :math:`(N, C_{\text{out}}, L_{\text{out}})` can be
precisely described as:

.. math::
    \text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) +
    \sum_{k = 0}^{C_{in} - 1} \text{weight}(C_{\text{out}_j}, k)
    \star \text{input}(N_i, k)

where :math:`\star` is the valid `cross-correlation`_ operator,
:math:`N` is a batch size, :math:`C` denotes a number of channels,
:math:`L` is a length of signal sequence.

* :attr:`stride` controls the stride for the cross-correlation, a single
  number or a one-element tuple.

* :attr:`padding` controls the amount of implicit zero-paddings on both sides
  for :attr:`padding` number of points.

* :attr:`dilation` controls the spacing between the kernel points; also
  known as the  trous algorithm. It is harder to describe, but this `link`_
  has a nice visualization of what :attr:`dilation` does.

* :attr:`groups` controls the connections between inputs and outputs.
  :attr:`in_channels` and :attr:`out_channels` must both be divisible by
  :attr:`groups`. For example,

    * At groups=1, all inputs are convolved to all outputs.
    * At groups=2, the operation becomes equivalent to having two conv
      layers side by side, each seeing half the input channels,
      and producing half the output channels, and both subsequently
      concatenated.
    * At groups= :attr:`in_channels`, each input channel is convolved with
      its own set of filters,
      of size
      :math:`\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor`.

.. note::

    Depending of the size of your kernel, several (of the last)
    columns of the input might be lost, because it is a valid
    `cross-correlation`_, and not a full `cross-correlation`_.
    It is up to the user to add proper padding.

.. note::

    When `groups == in_channels` and `out_channels == K * in_channels`,
    where `K` is a positive integer, this operation is also termed in
    literature as depthwise convolution.

    In other words, for an input of size :math:`(N, C_{in}, L_{in})`,
    a depthwise convolution with a depthwise multiplier `K`, can be constructed by arguments
    :math:`(C_\text{in}=C_{in}, C_\text{out}=C_{in} \times K, ..., \text{groups}=C_{in})`.

.. include:: cudnn_deterministic.rst

Args:
    in_channels (int): Number of channels in the input image
    out_channels (int): Number of channels produced by the convolution
    kernel_size (int or tuple): Size of the convolving kernel
    stride (int or tuple, optional): Stride of the convolution. Default: 1
    padding (int or tuple, optional): Zero-padding added to both sides of
        the input. Default: 0
    padding_mode (string, optional). Accepted values `zeros` and `circular` Default: `zeros`
    dilation (int or tuple, optional): Spacing between kernel
        elements. Default: 1
    groups (int, optional): Number of blocked connections from input
        channels to output channels. Default: 1
    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``

Shape:
    - Input: :math:`(N, C_{in}, L_{in})`
    - Output: :math:`(N, C_{out}, L_{out})` where

      .. math::
          L_{out} = \left\lfloor\frac{L_{in} + 2 \times \text{padding} - \text{dilation}
                    \times (\text{kernel\_size} - 1) - 1}{\text{stride}} + 1\right\rfloor

Attributes:
    weight (Tensor): the learnable weights of the module of shape
        :math:`(\text{out\_channels}, \frac{\text{in\_channels}}{\text{groups}}, \text{kernel\_size})`.
        The values of these weights are sampled from
        :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
        :math:`k = \frac{1}{C_\text{in} * \text{kernel\_size}}`
    bias (Tensor):   the learnable bias of the module of shape
        (out_channels). If :attr:`bias` is ``True``, then the values of these weights are
        sampled from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
        :math:`k = \frac{1}{C_\text{in} * \text{kernel\_size}}`

Examples::

    >>> m = nn.Conv1d(16, 33, 3, stride=2)
    >>> input = torch.randn(20, 16, 50)
    >>> output = m(input)

.. _cross-correlation:
    https://en.wikipedia.org/wiki/Cross-correlation

.. _link:
    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
",79,182,4432,103
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\conv.py,Conv2d,"
Applies a 2D convolution over an input signal composed of several input
planes.

In the simplest case, the output value of the layer with input size
:math:`(N, C_{\text{in}}, H, W)` and output :math:`(N, C_{\text{out}}, H_{\text{out}}, W_{\text{out}})`
can be precisely described as:

.. math::
    \text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) +
    \sum_{k = 0}^{C_{\text{in}} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)


where :math:`\star` is the valid 2D `cross-correlation`_ operator,
:math:`N` is a batch size, :math:`C` denotes a number of channels,
:math:`H` is a height of input planes in pixels, and :math:`W` is
width in pixels.

* :attr:`stride` controls the stride for the cross-correlation, a single
  number or a tuple.

* :attr:`padding` controls the amount of implicit zero-paddings on both
  sides for :attr:`padding` number of points for each dimension.

* :attr:`dilation` controls the spacing between the kernel points; also
  known as the  trous algorithm. It is harder to describe, but this `link`_
  has a nice visualization of what :attr:`dilation` does.

* :attr:`groups` controls the connections between inputs and outputs.
  :attr:`in_channels` and :attr:`out_channels` must both be divisible by
  :attr:`groups`. For example,

    * At groups=1, all inputs are convolved to all outputs.
    * At groups=2, the operation becomes equivalent to having two conv
      layers side by side, each seeing half the input channels,
      and producing half the output channels, and both subsequently
      concatenated.
    * At groups= :attr:`in_channels`, each input channel is convolved with
      its own set of filters, of size:
      :math:`\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor`.

The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:

    - a single ``int`` -- in which case the same value is used for the height and width dimension
    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,
      and the second `int` for the width dimension

.. note::

     Depending of the size of your kernel, several (of the last)
     columns of the input might be lost, because it is a valid `cross-correlation`_,
     and not a full `cross-correlation`_.
     It is up to the user to add proper padding.

.. note::

    When `groups == in_channels` and `out_channels == K * in_channels`,
    where `K` is a positive integer, this operation is also termed in
    literature as depthwise convolution.

    In other words, for an input of size :math:`(N, C_{in}, H_{in}, W_{in})`,
    a depthwise convolution with a depthwise multiplier `K`, can be constructed by arguments
    :math:`(in\_channels=C_{in}, out\_channels=C_{in} \times K, ..., groups=C_{in})`.

.. include:: cudnn_deterministic.rst

Args:
    in_channels (int): Number of channels in the input image
    out_channels (int): Number of channels produced by the convolution
    kernel_size (int or tuple): Size of the convolving kernel
    stride (int or tuple, optional): Stride of the convolution. Default: 1
    padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0
    padding_mode (string, optional). Accepted values `zeros` and `circular` Default: `zeros`
    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1
    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1
    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``

Shape:
    - Input: :math:`(N, C_{in}, H_{in}, W_{in})`
    - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where

      .. math::
          H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] - \text{dilation}[0]
                    \times (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor

      .. math::
          W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] - \text{dilation}[1]
                    \times (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor

Attributes:
    weight (Tensor): the learnable weights of the module of shape
                     :math:`(\text{out\_channels}, \frac{\text{in\_channels}}{\text{groups}},`
                     :math:`\text{kernel\_size[0]}, \text{kernel\_size[1]})`.
                     The values of these weights are sampled from
                     :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
                     :math:`k = \frac{1}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}`
    bias (Tensor):   the learnable bias of the module of shape (out_channels). If :attr:`bias` is ``True``,
                     then the values of these weights are
                     sampled from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
                     :math:`k = \frac{1}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}`

Examples::

    >>> # With square kernels and equal stride
    >>> m = nn.Conv2d(16, 33, 3, stride=2)
    >>> # non-square kernels and unequal stride and with padding
    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))
    >>> # non-square kernels and unequal stride and with padding and dilation
    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))
    >>> input = torch.randn(20, 16, 50, 100)
    >>> output = m(input)

.. _cross-correlation:
    https://en.wikipedia.org/wiki/Cross-correlation

.. _link:
    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
",206,322,5606,116
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\conv.py,Conv3d,"
Applies a 3D convolution over an input signal composed of several input
planes.

In the simplest case, the output value of the layer with input size :math:`(N, C_{in}, D, H, W)`
and output :math:`(N, C_{out}, D_{out}, H_{out}, W_{out})` can be precisely described as:

.. math::
    out(N_i, C_{out_j}) = bias(C_{out_j}) +
                            \sum_{k = 0}^{C_{in} - 1} weight(C_{out_j}, k) \star input(N_i, k)

where :math:`\star` is the valid 3D `cross-correlation`_ operator

* :attr:`stride` controls the stride for the cross-correlation.

* :attr:`padding` controls the amount of implicit zero-paddings on both
  sides for :attr:`padding` number of points for each dimension.

* :attr:`dilation` controls the spacing between the kernel points; also known as the  trous algorithm.
  It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.

* :attr:`groups` controls the connections between inputs and outputs.
  :attr:`in_channels` and :attr:`out_channels` must both be divisible by
  :attr:`groups`. For example,

    * At groups=1, all inputs are convolved to all outputs.
    * At groups=2, the operation becomes equivalent to having two conv
      layers side by side, each seeing half the input channels,
      and producing half the output channels, and both subsequently
      concatenated.
    * At groups= :attr:`in_channels`, each input channel is convolved with
      its own set of filters, of size
      :math:`\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor`.

The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:

    - a single ``int`` -- in which case the same value is used for the depth, height and width dimension
    - a ``tuple`` of three ints -- in which case, the first `int` is used for the depth dimension,
      the second `int` for the height dimension and the third `int` for the width dimension

.. note::

     Depending of the size of your kernel, several (of the last)
     columns of the input might be lost, because it is a valid `cross-correlation`_,
     and not a full `cross-correlation`_.
     It is up to the user to add proper padding.

.. note::

    When `groups == in_channels` and `out_channels == K * in_channels`,
    where `K` is a positive integer, this operation is also termed in
    literature as depthwise convolution.

    In other words, for an input of size :math:`(N, C_{in}, D_{in}, H_{in}, W_{in})`,
    a depthwise convolution with a depthwise multiplier `K`, can be constructed by arguments
    :math:`(in\_channels=C_{in}, out\_channels=C_{in} \times K, ..., groups=C_{in})`.

.. include:: cudnn_deterministic.rst

Args:
    in_channels (int): Number of channels in the input image
    out_channels (int): Number of channels produced by the convolution
    kernel_size (int or tuple): Size of the convolving kernel
    stride (int or tuple, optional): Stride of the convolution. Default: 1
    padding (int or tuple, optional): Zero-padding added to all three sides of the input. Default: 0
    padding_mode (string, optional). Accepted values `zeros` and `circular` Default: `zeros`
    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1
    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1
    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``

Shape:
    - Input: :math:`(N, C_{in}, D_{in}, H_{in}, W_{in})`
    - Output: :math:`(N, C_{out}, D_{out}, H_{out}, W_{out})` where

      .. math::
          D_{out} = \left\lfloor\frac{D_{in} + 2 \times \text{padding}[0] - \text{dilation}[0]
                \times (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor

      .. math::
          H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[1] - \text{dilation}[1]
                \times (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor

      .. math::
          W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[2] - \text{dilation}[2]
                \times (\text{kernel\_size}[2] - 1) - 1}{\text{stride}[2]} + 1\right\rfloor

Attributes:
    weight (Tensor): the learnable weights of the module of shape
                     :math:`(\text{out\_channels}, \frac{\text{in\_channels}}{\text{groups}},`
                     :math:`\text{kernel\_size[0]}, \text{kernel\_size[1]}, \text{kernel\_size[2]})`.
                     The values of these weights are sampled from
                     :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
                     :math:`k = \frac{1}{C_\text{in} * \prod_{i=0}^{2}\text{kernel\_size}[i]}`
    bias (Tensor):   the learnable bias of the module of shape (out_channels). If :attr:`bias` is ``True``,
                     then the values of these weights are
                     sampled from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
                     :math:`k = \frac{1}{C_\text{in} * \prod_{i=0}^{2}\text{kernel\_size}[i]}`

Examples::

    >>> # With square kernels and equal stride
    >>> m = nn.Conv3d(16, 33, 3, stride=2)
    >>> # non-square kernels and unequal stride and with padding
    >>> m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0))
    >>> input = torch.randn(20, 16, 10, 50, 100)
    >>> output = m(input)

.. _cross-correlation:
    https://en.wikipedia.org/wiki/Cross-correlation

.. _link:
    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
",348,459,5519,111
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\conv.py,_ConvTransposeMixin,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\conv.py,ConvTranspose1d,"
Applies a 1D transposed convolution operator over an input image
composed of several input planes.

This module can be seen as the gradient of Conv1d with respect to its input.
It is also known as a fractionally-strided convolution or
a deconvolution (although it is not an actual deconvolution operation).

* :attr:`stride` controls the stride for the cross-correlation.

* :attr:`padding` controls the amount of implicit zero-paddings on both
  sides for ``dilation * (kernel_size - 1) - padding`` number of points. See note
  below for details.

* :attr:`output_padding` controls the additional size added to one side
  of the output shape. See note below for details.

* :attr:`dilation` controls the spacing between the kernel points; also known as the  trous algorithm.
  It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.

* :attr:`groups` controls the connections between inputs and outputs.
  :attr:`in_channels` and :attr:`out_channels` must both be divisible by
  :attr:`groups`. For example,

    * At groups=1, all inputs are convolved to all outputs.
    * At groups=2, the operation becomes equivalent to having two conv
      layers side by side, each seeing half the input channels,
      and producing half the output channels, and both subsequently
      concatenated.
    * At groups= :attr:`in_channels`, each input channel is convolved with
      its own set of filters (of size
      :math:`\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor`).

.. note::

     Depending of the size of your kernel, several (of the last)
     columns of the input might be lost, because it is a valid `cross-correlation`_,
     and not a full `cross-correlation`_.
     It is up to the user to add proper padding.

.. note::
    The :attr:`padding` argument effectively adds ``dilation * (kernel_size - 1) - padding``
    amount of zero padding to both sizes of the input. This is set so that
    when a :class:`~torch.nn.Conv1d` and a :class:`~torch.nn.ConvTranspose1d`
    are initialized with same parameters, they are inverses of each other in
    regard to the input and output shapes. However, when ``stride > 1``,
    :class:`~torch.nn.Conv1d` maps multiple input shapes to the same output
    shape. :attr:`output_padding` is provided to resolve this ambiguity by
    effectively increasing the calculated output shape on one side. Note
    that :attr:`output_padding` is only used to find output shape, but does
    not actually add zero-padding to output.

.. include:: cudnn_deterministic.rst

Args:
    in_channels (int): Number of channels in the input image
    out_channels (int): Number of channels produced by the convolution
    kernel_size (int or tuple): Size of the convolving kernel
    stride (int or tuple, optional): Stride of the convolution. Default: 1
    padding (int or tuple, optional): ``dilation * (kernel_size - 1) - padding`` zero-padding
        will be added to both sides of the input. Default: 0
    output_padding (int or tuple, optional): Additional size added to one side
        of the output shape. Default: 0
    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1
    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``
    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1

Shape:
    - Input: :math:`(N, C_{in}, L_{in})`
    - Output: :math:`(N, C_{out}, L_{out})` where

      .. math::
          L_{out} = (L_{in} - 1) \times \text{stride} - 2 \times \text{padding} + \text{dilation}
                    \times (\text{kernel\_size} - 1) + \text{output\_padding} + 1

Attributes:
    weight (Tensor): the learnable weights of the module of shape
                     :math:`(\text{in\_channels}, \frac{\text{out\_channels}}{\text{groups}},`
                     :math:`\text{kernel\_size})`.
                     The values of these weights are sampled from
                     :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
                     :math:`k = \frac{1}{C_\text{in} * \text{kernel\_size}}`
    bias (Tensor):   the learnable bias of the module of shape (out_channels).
                     If :attr:`bias` is ``True``, then the values of these weights are
                     sampled from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
                     :math:`k = \frac{1}{C_\text{in} * \text{kernel\_size}}`
",524,609,4461,85
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\conv.py,ConvTranspose2d,"
Applies a 2D transposed convolution operator over an input image
composed of several input planes.

This module can be seen as the gradient of Conv2d with respect to its input.
It is also known as a fractionally-strided convolution or
a deconvolution (although it is not an actual deconvolution operation).

* :attr:`stride` controls the stride for the cross-correlation.

* :attr:`padding` controls the amount of implicit zero-paddings on both
  sides for ``dilation * (kernel_size - 1) - padding`` number of points. See note
  below for details.

* :attr:`output_padding` controls the additional size added to one side
  of the output shape. See note below for details.

* :attr:`dilation` controls the spacing between the kernel points; also known as the  trous algorithm.
  It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.

* :attr:`groups` controls the connections between inputs and outputs.
  :attr:`in_channels` and :attr:`out_channels` must both be divisible by
  :attr:`groups`. For example,

    * At groups=1, all inputs are convolved to all outputs.
    * At groups=2, the operation becomes equivalent to having two conv
      layers side by side, each seeing half the input channels,
      and producing half the output channels, and both subsequently
      concatenated.
    * At groups= :attr:`in_channels`, each input channel is convolved with
      its own set of filters (of size
      :math:`\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor`).

The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`output_padding`
can either be:

    - a single ``int`` -- in which case the same value is used for the height and width dimensions
    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,
      and the second `int` for the width dimension

.. note::

     Depending of the size of your kernel, several (of the last)
     columns of the input might be lost, because it is a valid `cross-correlation`_,
     and not a full `cross-correlation`_.
     It is up to the user to add proper padding.

.. note::
    The :attr:`padding` argument effectively adds ``dilation * (kernel_size - 1) - padding``
    amount of zero padding to both sizes of the input. This is set so that
    when a :class:`~torch.nn.Conv2d` and a :class:`~torch.nn.ConvTranspose2d`
    are initialized with same parameters, they are inverses of each other in
    regard to the input and output shapes. However, when ``stride > 1``,
    :class:`~torch.nn.Conv2d` maps multiple input shapes to the same output
    shape. :attr:`output_padding` is provided to resolve this ambiguity by
    effectively increasing the calculated output shape on one side. Note
    that :attr:`output_padding` is only used to find output shape, but does
    not actually add zero-padding to output.

.. include:: cudnn_deterministic.rst

Args:
    in_channels (int): Number of channels in the input image
    out_channels (int): Number of channels produced by the convolution
    kernel_size (int or tuple): Size of the convolving kernel
    stride (int or tuple, optional): Stride of the convolution. Default: 1
    padding (int or tuple, optional): ``dilation * (kernel_size - 1) - padding`` zero-padding
        will be added to both sides of each dimension in the input. Default: 0
    output_padding (int or tuple, optional): Additional size added to one side
        of each dimension in the output shape. Default: 0
    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1
    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``
    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1

Shape:
    - Input: :math:`(N, C_{in}, H_{in}, W_{in})`
    - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where

    .. math::
          H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0]
                    \times (\text{kernel\_size}[0] - 1) + \text{output\_padding}[0] + 1
    .. math::
          W_{out} = (W_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1] + \text{dilation}[1]
                    \times (\text{kernel\_size}[1] - 1) + \text{output\_padding}[1] + 1

Attributes:
    weight (Tensor): the learnable weights of the module of shape
                     :math:`(\text{in\_channels}, \frac{\text{out\_channels}}{\text{groups}},`
                     :math:`\text{kernel\_size[0]}, \text{kernel\_size[1]})`.
                     The values of these weights are sampled from
                     :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
                     :math:`k = \frac{1}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}`
    bias (Tensor):   the learnable bias of the module of shape (out_channels)
                     If :attr:`bias` is ``True``, then the values of these weights are
                     sampled from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
                     :math:`k = \frac{1}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}`

Examples::

    >>> # With square kernels and equal stride
    >>> m = nn.ConvTranspose2d(16, 33, 3, stride=2)
    >>> # non-square kernels and unequal stride and with padding
    >>> m = nn.ConvTranspose2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))
    >>> input = torch.randn(20, 16, 50, 100)
    >>> output = m(input)
    >>> # exact output size can be also specified as an argument
    >>> input = torch.randn(1, 16, 12, 12)
    >>> downsample = nn.Conv2d(16, 16, 3, stride=2, padding=1)
    >>> upsample = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1)
    >>> h = downsample(input)
    >>> h.size()
    torch.Size([1, 16, 6, 6])
    >>> output = upsample(h, output_size=input.size())
    >>> output.size()
    torch.Size([1, 16, 12, 12])

.. _cross-correlation:
    https://en.wikipedia.org/wiki/Cross-correlation

.. _link:
    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
",635,755,6066,120
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\conv.py,ConvTranspose3d,"
Applies a 3D transposed convolution operator over an input image composed of several input
planes.
The transposed convolution operator multiplies each input value element-wise by a learnable kernel,
and sums over the outputs from all input feature planes.

This module can be seen as the gradient of Conv3d with respect to its input.
It is also known as a fractionally-strided convolution or
a deconvolution (although it is not an actual deconvolution operation).

* :attr:`stride` controls the stride for the cross-correlation.

* :attr:`padding` controls the amount of implicit zero-paddings on both
  sides for ``dilation * (kernel_size - 1) - padding`` number of points. See note
  below for details.

* :attr:`output_padding` controls the additional size added to one side
  of the output shape. See note below for details.

* :attr:`dilation` controls the spacing between the kernel points; also known as the  trous algorithm.
  It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.

* :attr:`groups` controls the connections between inputs and outputs.
  :attr:`in_channels` and :attr:`out_channels` must both be divisible by
  :attr:`groups`. For example,

    * At groups=1, all inputs are convolved to all outputs.
    * At groups=2, the operation becomes equivalent to having two conv
      layers side by side, each seeing half the input channels,
      and producing half the output channels, and both subsequently
      concatenated.
    * At groups= :attr:`in_channels`, each input channel is convolved with
      its own set of filters (of size
      :math:`\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor`).

The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`output_padding`
can either be:

    - a single ``int`` -- in which case the same value is used for the depth, height and width dimensions
    - a ``tuple`` of three ints -- in which case, the first `int` is used for the depth dimension,
      the second `int` for the height dimension and the third `int` for the width dimension

.. note::

     Depending of the size of your kernel, several (of the last)
     columns of the input might be lost, because it is a valid `cross-correlation`_,
     and not a full `cross-correlation`_.
     It is up to the user to add proper padding.

.. note::
    The :attr:`padding` argument effectively adds ``dilation * (kernel_size - 1) - padding``
    amount of zero padding to both sizes of the input. This is set so that
    when a :class:`~torch.nn.Conv3d` and a :class:`~torch.nn.ConvTranspose3d`
    are initialized with same parameters, they are inverses of each other in
    regard to the input and output shapes. However, when ``stride > 1``,
    :class:`~torch.nn.Conv3d` maps multiple input shapes to the same output
    shape. :attr:`output_padding` is provided to resolve this ambiguity by
    effectively increasing the calculated output shape on one side. Note
    that :attr:`output_padding` is only used to find output shape, but does
    not actually add zero-padding to output.

.. include:: cudnn_deterministic.rst

Args:
    in_channels (int): Number of channels in the input image
    out_channels (int): Number of channels produced by the convolution
    kernel_size (int or tuple): Size of the convolving kernel
    stride (int or tuple, optional): Stride of the convolution. Default: 1
    padding (int or tuple, optional): ``dilation * (kernel_size - 1) - padding`` zero-padding
        will be added to both sides of each dimension in the input. Default: 0
    output_padding (int or tuple, optional): Additional size added to one side
        of each dimension in the output shape. Default: 0
    groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1
    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``
    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1

Shape:
    - Input: :math:`(N, C_{in}, D_{in}, H_{in}, W_{in})`
    - Output: :math:`(N, C_{out}, D_{out}, H_{out}, W_{out})` where

    .. math::
          D_{out} = (D_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0]
                    \times (\text{kernel\_size}[0] - 1) + \text{output\_padding}[0] + 1
    .. math::
          H_{out} = (H_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1] + \text{dilation}[1]
                    \times (\text{kernel\_size}[1] - 1) + \text{output\_padding}[1] + 1
    .. math::
          W_{out} = (W_{in} - 1) \times \text{stride}[2] - 2 \times \text{padding}[2] + \text{dilation}[2]
                    \times (\text{kernel\_size}[2] - 1) + \text{output\_padding}[2] + 1


Attributes:
    weight (Tensor): the learnable weights of the module of shape
                     :math:`(\text{in\_channels}, \frac{\text{out\_channels}}{\text{groups}},`
                     :math:`\text{kernel\_size[0]}, \text{kernel\_size[1]}, \text{kernel\_size[2]})`.
                     The values of these weights are sampled from
                     :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
                     :math:`k = \frac{1}{C_\text{in} * \prod_{i=0}^{2}\text{kernel\_size}[i]}`
    bias (Tensor):   the learnable bias of the module of shape (out_channels)
                     If :attr:`bias` is ``True``, then the values of these weights are
                     sampled from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
                     :math:`k = \frac{1}{C_\text{in} * \prod_{i=0}^{2}\text{kernel\_size}[i]}`

Examples::

    >>> # With square kernels and equal stride
    >>> m = nn.ConvTranspose3d(16, 33, 3, stride=2)
    >>> # non-square kernels and unequal stride and with padding
    >>> m = nn.ConvTranspose3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(0, 4, 2))
    >>> input = torch.randn(20, 16, 10, 50, 100)
    >>> output = m(input)

.. _cross-correlation:
    https://en.wikipedia.org/wiki/Cross-correlation

.. _link:
    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
",782,898,6109,116
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\distance.py,PairwiseDistance,"
Computes the batchwise pairwise distance between vectors :math:`v_1`, :math:`v_2` using the p-norm:

.. math ::
    \Vert x \Vert _p = \left( \sum_{i=1}^n  \vert x_i \vert ^ p \right) ^ {1/p}.

Args:
    p (real): the norm degree. Default: 2
    eps (float, optional): Small value to avoid division by zero.
        Default: 1e-6
    keepdim (bool, optional): Determines whether or not to keep the vector dimension.
        Default: False
Shape:
    - Input1: :math:`(N, D)` where `D = vector dimension`
    - Input2: :math:`(N, D)`, same shape as the Input1
    - Output: :math:`(N)`. If :attr:`keepdim` is ``True``, then :math:`(N, 1)`.
Examples::
    >>> pdist = nn.PairwiseDistance(p=2)
    >>> input1 = torch.randn(100, 128)
    >>> input2 = torch.randn(100, 128)
    >>> output = pdist(input1, input2)
",6,26,807,20
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\distance.py,CosineSimilarity,"
Returns cosine similarity between :math:`x_1` and :math:`x_2`, computed along dim.

.. math ::
    \text{similarity} = \dfrac{x_1 \cdot x_2}{\max(\Vert x_1 \Vert _2 \cdot \Vert x_2 \Vert _2, \epsilon)}.

Args:
    dim (int, optional): Dimension where cosine similarity is computed. Default: 1
    eps (float, optional): Small value to avoid division by zero.
        Default: 1e-8
Shape:
    - Input1: :math:`(\ast_1, D, \ast_2)` where D is at position `dim`
    - Input2: :math:`(\ast_1, D, \ast_2)`, same shape as the Input1
    - Output: :math:`(\ast_1, \ast_2)`
Examples::
    >>> input1 = torch.randn(100, 128)
    >>> input2 = torch.randn(100, 128)
    >>> cos = nn.CosineSimilarity(dim=1, eps=1e-6)
    >>> output = cos(input1, input2)
",41,59,742,18
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\dropout.py,_DropoutNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\dropout.py,Dropout,"
During training, randomly zeroes some of the elements of the input
tensor with probability :attr:`p` using samples from a Bernoulli
distribution. Each channel will be zeroed out independently on every forward
call.

This has proven to be an effective technique for regularization and
preventing the co-adaptation of neurons as described in the paper
`Improving neural networks by preventing co-adaptation of feature
detectors`_ .

Furthermore, the outputs are scaled by a factor of :math:`\frac{1}{1-p}` during
training. This means that during evaluation the module simply computes an
identity function.

Args:
    p: probability of an element to be zeroed. Default: 0.5
    inplace: If set to ``True``, will do this operation in-place. Default: ``False``

Shape:
    - Input: :math:`(*)`. Input can be of any shape
    - Output: :math:`(*)`. Output is of the same shape as input

Examples::

    >>> m = nn.Dropout(p=0.2)
    >>> input = torch.randn(20, 16)
    >>> output = m(input)

.. _Improving neural networks by preventing co-adaptation of feature
    detectors: https://arxiv.org/abs/1207.0580
",21,51,1101,30
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\dropout.py,Dropout2d,"
Randomly zero out entire channels (a channel is a 2D feature map,
e.g., the :math:`j`-th channel of the :math:`i`-th sample in the
batched input is a 2D tensor :math:`\text{input}[i, j]`).
Each channel will be zeroed out independently on every forward call with
probability :attr:`p` using samples from a Bernoulli distribution.

Usually the input comes from :class:`nn.Conv2d` modules.

As described in the paper
`Efficient Object Localization Using Convolutional Networks`_ ,
if adjacent pixels within feature maps are strongly correlated
(as is normally the case in early convolution layers) then i.i.d. dropout
will not regularize the activations and will otherwise just result
in an effective learning rate decrease.

In this case, :func:`nn.Dropout2d` will help promote independence between
feature maps and should be used instead.

Args:
    p (float, optional): probability of an element to be zero-ed.
    inplace (bool, optional): If set to ``True``, will do this operation
        in-place

Shape:
    - Input: :math:`(N, C, H, W)`
    - Output: :math:`(N, C, H, W)` (same shape as input)

Examples::

    >>> m = nn.Dropout2d(p=0.2)
    >>> input = torch.randn(20, 16, 32, 32)
    >>> output = m(input)

.. _Efficient Object Localization Using Convolutional Networks:
   http://arxiv.org/abs/1411.4280
",58,93,1313,35
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\dropout.py,Dropout3d,"
Randomly zero out entire channels (a channel is a 3D feature map,
e.g., the :math:`j`-th channel of the :math:`i`-th sample in the
batched input is a 3D tensor :math:`\text{input}[i, j]`).
Each channel will be zeroed out independently on every forward call with
probability :attr:`p` using samples from a Bernoulli distribution.

Usually the input comes from :class:`nn.Conv3d` modules.

As described in the paper
`Efficient Object Localization Using Convolutional Networks`_ ,
if adjacent pixels within feature maps are strongly correlated
(as is normally the case in early convolution layers) then i.i.d. dropout
will not regularize the activations and will otherwise just result
in an effective learning rate decrease.

In this case, :func:`nn.Dropout3d` will help promote independence between
feature maps and should be used instead.

Args:
    p (float, optional): probability of an element to be zeroed.
    inplace (bool, optional): If set to ``True``, will do this operation
        in-place

Shape:
    - Input: :math:`(N, C, D, H, W)`
    - Output: :math:`(N, C, D, H, W)` (same shape as input)

Examples::

    >>> m = nn.Dropout3d(p=0.2)
    >>> input = torch.randn(20, 16, 4, 32, 32)
    >>> output = m(input)

.. _Efficient Object Localization Using Convolutional Networks:
   http://arxiv.org/abs/1411.4280
",100,135,1321,35
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\dropout.py,AlphaDropout,"
Applies Alpha Dropout over the input.

Alpha Dropout is a type of Dropout that maintains the self-normalizing
property.
For an input with zero mean and unit standard deviation, the output of
Alpha Dropout maintains the original mean and standard deviation of the
input.
Alpha Dropout goes hand-in-hand with SELU activation function, which ensures
that the outputs have zero mean and unit standard deviation.

During training, it randomly masks some of the elements of the input
tensor with probability *p* using samples from a bernoulli distribution.
The elements to masked are randomized on every forward call, and scaled
and shifted to maintain zero mean and unit standard deviation.

During evaluation the module simply computes an identity function.

More details can be found in the paper `Self-Normalizing Neural Networks`_ .

Args:
    p (float): probability of an element to be dropped. Default: 0.5
    inplace (bool, optional): If set to ``True``, will do this operation
        in-place

Shape:
    - Input: :math:`(*)`. Input can be of any shape
    - Output: :math:`(*)`. Output is of the same shape as input

Examples::

    >>> m = nn.AlphaDropout(p=0.2)
    >>> input = torch.randn(20, 16)
    >>> output = m(input)

.. _Self-Normalizing Neural Networks: https://arxiv.org/abs/1706.02515
",142,177,1303,35
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\dropout.py,FeatureAlphaDropout,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\flatten.py,Flatten,"
Flattens a contiguous range of dims into a tensor. For use with :class:`~nn.Sequential`.
Args:
    start_dim: first dim to flatten (default = 1).
    end_dim: last dim to flatten (default = -1).

Shape:
    - Input: :math:`(N, *dims)`
    - Output: :math:`(N, \prod *dims)` (for the default case).


Examples::
    >>> m = nn.Sequential(
    >>>     nn.Conv2d(1, 32, 5, 1, 1),
    >>>     nn.Flatten()
    >>> )
",4,19,411,15
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\fold.py,Fold,"
Combines an array of sliding local blocks into a large containing
tensor.

Consider a batched :attr:`input` tensor containing sliding local blocks,
e.g., patches of images, of shape :math:`(N, C \times  \prod(\text{kernel\_size}), L)`,
where :math:`N` is batch dimension, :math:`C \times \prod(\text{kernel\_size})`
is the number of values within a block (a block has :math:`\prod(\text{kernel\_size})`
spatial locations each containing a :math:`C`-channeled vector), and
:math:`L` is the total number of blocks. (This is exactly the
same specification as the output shape of :class:`~torch.nn.Unfold`.) This
operation combines these local blocks into the large :attr:`output` tensor
of shape :math:`(N, C, \text{output\_size}[0], \text{output\_size}[1], \dots)`
by summing the overlapping values. Similar to :class:`~torch.nn.Unfold`, the
arguments must satisfy

.. math::
    L = \prod_d \left\lfloor\frac{\text{output\_size}[d] + 2 \times \text{padding}[d] %
        - \text{dilation}[d] \times (\text{kernel\_size}[d] - 1) - 1}{\text{stride}[d]} + 1\right\rfloor,

where :math:`d` is over all spatial dimensions.

* :attr:`output_size` describes the spatial shape of the large containing
  tensor of the sliding local blocks. It is useful to resolve the ambiguity
  when multiple input shapes map to same number of sliding blocks, e.g.,
  with ``stride > 0``.

The :attr:`padding`, :attr:`stride` and :attr:`dilation` arguments specify
how the sliding blocks are retrieved.

* :attr:`stride` controls the stride for the sliding blocks.

* :attr:`padding` controls the amount of implicit zero-paddings on both
  sides for :attr:`padding` number of points for each dimension before
  reshaping.

* :attr:`dilation` controls the spacing between the kernel points; also known as the  trous algorithm.
  It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.

Args:
    output_size (int or tuple): the shape of the spatial dimensions of the
                                output (i.e., ``output.sizes()[2:]``)
    kernel_size (int or tuple): the size of the sliding blocks
    stride (int or tuple): the stride of the sliding blocks in the input
                           spatial dimensions. Default: 1
    padding (int or tuple, optional): implicit zero padding to be added on
                                      both sides of input. Default: 0
    dilation (int or tuple, optional): a parameter that controls the
                                       stride of elements within the
                                       neighborhood. Default: 1

* If :attr:`output_size`, :attr:`kernel_size`, :attr:`dilation`,
  :attr:`padding` or :attr:`stride` is an int or a tuple of length 1 then
  their values will be replicated across all spatial dimensions.

* For the case of two output spatial dimensions this operation is sometimes
  called ``col2im``.

.. note::
    :class:`~torch.nn.Fold` calculates each combined value in the resulting
    large tensor by summing all values from all containing blocks.
    :class:`~torch.nn.Unfold` extracts the values in the local blocks by
    copying from the large tensor. So, if the blocks overlap, they are not
    inverses of each other.

    In general, folding and unfolding operations are related as
    follows. Consider :class:`~torch.nn.Fold` and
    :class:`~torch.nn.Unfold` instances created with the same
    parameters:

    >>> fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...)
    >>> fold = nn.Fold(output_size=..., **fold_params)
    >>> unfold = nn.Unfold(**fold_params)

    Then for any (supported) ``input`` tensor the following
    equality holds:

    ::

        fold(unfold(input)) == divisor * input

    where ``divisor`` is a tensor that depends only on the shape
    and dtype of the ``input``:

    >>> input_ones = torch.ones(input.shape, dtype=input.dtype)
    >>> divisor = fold(unfold(input_ones))

    When the ``divisor`` tensor contains no zero elements, then
    ``fold`` and ``unfold`` operations are inverses of each
    other (up to constant divisor).

.. warning::
    Currently, only 4-D output tensors (batched image-like tensors) are
    supported.

Shape:
    - Input: :math:`(N, C \times \prod(\text{kernel\_size}), L)`
    - Output: :math:`(N, C, \text{output\_size}[0], \text{output\_size}[1], \dots)` as described above

Examples::

    >>> fold = nn.Fold(output_size=(4, 5), kernel_size=(2, 2))
    >>> input = torch.randn(1, 3 * 2 * 2, 12)
    >>> output = fold(input)
    >>> output.size()
    torch.Size([1, 3, 4, 5])

.. _link:
    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
",7,115,4667,108
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\fold.py,Unfold,"
Extracts sliding local blocks from a batched input tensor.

Consider a batched :attr:`input` tensor of shape :math:`(N, C, *)`,
where :math:`N` is the batch dimension, :math:`C` is the channel dimension,
and :math:`*` represent arbitrary spatial dimensions. This operation flattens
each sliding :attr:`kernel_size`-sized block within the spatial dimensions
of :attr:`input` into a column (i.e., last dimension) of a 3-D :attr:`output`
tensor of shape :math:`(N, C \times \prod(\text{kernel\_size}), L)`, where
:math:`C \times \prod(\text{kernel\_size})` is the total number of values
within each block (a block has :math:`\prod(\text{kernel\_size})` spatial
locations each containing a :math:`C`-channeled vector), and :math:`L` is
the total number of such blocks:

.. math::
    L = \prod_d \left\lfloor\frac{\text{spatial\_size}[d] + 2 \times \text{padding}[d] %
        - \text{dilation}[d] \times (\text{kernel\_size}[d] - 1) - 1}{\text{stride}[d]} + 1\right\rfloor,

where :math:`\text{spatial\_size}` is formed by the spatial dimensions
of :attr:`input` (:math:`*` above), and :math:`d` is over all spatial
dimensions.

Therefore, indexing :attr:`output` at the last dimension (column dimension)
gives all values within a certain block.

The :attr:`padding`, :attr:`stride` and :attr:`dilation` arguments specify
how the sliding blocks are retrieved.

* :attr:`stride` controls the stride for the sliding blocks.

* :attr:`padding` controls the amount of implicit zero-paddings on both
  sides for :attr:`padding` number of points for each dimension before
  reshaping.

* :attr:`dilation` controls the spacing between the kernel points; also known as the  trous algorithm.
  It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.

Args:
    kernel_size (int or tuple): the size of the sliding blocks
    stride (int or tuple, optional): the stride of the sliding blocks in the input
                                     spatial dimensions. Default: 1
    padding (int or tuple, optional): implicit zero padding to be added on
                                      both sides of input. Default: 0
    dilation (int or tuple, optional): a parameter that controls the
                                       stride of elements within the
                                       neighborhood. Default: 1

* If :attr:`kernel_size`, :attr:`dilation`, :attr:`padding` or
  :attr:`stride` is an int or a tuple of length 1, their values will be
  replicated across all spatial dimensions.

* For the case of two input spatial dimensions this operation is sometimes
  called ``im2col``.

.. note::
    :class:`~torch.nn.Fold` calculates each combined value in the resulting
    large tensor by summing all values from all containing blocks.
    :class:`~torch.nn.Unfold` extracts the values in the local blocks by
    copying from the large tensor. So, if the blocks overlap, they are not
    inverses of each other.

    In general, folding and unfolding operations are related as
    follows. Consider :class:`~torch.nn.Fold` and
    :class:`~torch.nn.Unfold` instances created with the same
    parameters:

    >>> fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...)
    >>> fold = nn.Fold(output_size=..., **fold_params)
    >>> unfold = nn.Unfold(**fold_params)

    Then for any (supported) ``input`` tensor the following
    equality holds:

    ::

        fold(unfold(input)) == divisor * input

    where ``divisor`` is a tensor that depends only on the shape
    and dtype of the ``input``:

    >>> input_ones = torch.ones(input.shape, dtype=input.dtype)
    >>> divisor = fold(unfold(input_ones))

    When the ``divisor`` tensor contains no zero elements, then
    ``fold`` and ``unfold`` operations are inverses of each
    other (up to constant divisor).

.. warning::
    Currently, only 4-D input tensors (batched image-like tensors) are
    supported.

Shape:
    - Input: :math:`(N, C, *)`
    - Output: :math:`(N, C \times \prod(\text{kernel\_size}), L)` as described above

Examples::

    >>> unfold = nn.Unfold(kernel_size=(2, 3))
    >>> input = torch.randn(2, 5, 3, 4)
    >>> output = unfold(input)
    >>> # each patch contains 30 values (2x3=6 vectors, each of 5 channels)
    >>> # 4 blocks (2x3 kernels) in total in the 3x4 input
    >>> output.size()
    torch.Size([2, 30, 4])

    >>> # Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)
    >>> inp = torch.randn(1, 3, 10, 12)
    >>> w = torch.randn(2, 3, 4, 5)
    >>> inp_unf = torch.nn.functional.unfold(inp, (4, 5))
    >>> out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)
    >>> out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1))
    >>> # or equivalently (and avoiding a copy),
    >>> # out = out_unf.view(1, 2, 7, 8)
    >>> (torch.nn.functional.conv2d(inp, w) - out).abs().max()
    tensor(1.9073e-06)

.. _link:
    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
",140,257,5027,117
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\instancenorm.py,_InstanceNorm,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\instancenorm.py,InstanceNorm1d,"
Applies Instance Normalization over a 3D input (a mini-batch of 1D
inputs with optional additional channel dimension) as described in the paper
`Instance Normalization: The Missing Ingredient for Fast Stylization`_ .

.. math::

    y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta

The mean and standard-deviation are calculated per-dimension separately
for each object in a mini-batch. :math:`\gamma` and :math:`\beta` are learnable parameter vectors
of size `C` (where `C` is the input size) if :attr:`affine` is ``True``.

By default, this layer uses instance statistics computed from input data in
both training and evaluation modes.

If :attr:`track_running_stats` is set to ``True``, during training this
layer keeps running estimates of its computed mean and variance, which are
then used for normalization during evaluation. The running estimates are
kept with a default :attr:`momentum` of 0.1.

.. note::
    This :attr:`momentum` argument is different from one used in optimizer
    classes and the conventional notion of momentum. Mathematically, the
    update rule for running statistics here is
    :math:`\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momemtum} \times x_t`,
    where :math:`\hat{x}` is the estimated statistic and :math:`x_t` is the
    new observed value.

.. note::
    :class:`InstanceNorm1d` and :class:`LayerNorm` are very similar, but
    have some subtle differences. :class:`InstanceNorm1d` is applied
    on each channel of channeled data like multidimensional time series, but
    :class:`LayerNorm` is usually applied on entire sample and often in NLP
    tasks. Additionaly, :class:`LayerNorm` applies elementwise affine
    transform, while :class:`InstanceNorm1d` usually don't apply affine
    transform.

Args:
    num_features: :math:`C` from an expected input of size
        :math:`(N, C, L)` or :math:`L` from input of size :math:`(N, L)`
    eps: a value added to the denominator for numerical stability. Default: 1e-5
    momentum: the value used for the running_mean and running_var computation. Default: 0.1
    affine: a boolean value that when set to ``True``, this module has
        learnable affine parameters, initialized the same way as done for batch normalization.
        Default: ``False``.
    track_running_stats: a boolean value that when set to ``True``, this
        module tracks the running mean and variance, and when set to ``False``,
        this module does not track such statistics and always uses batch
        statistics in both training and eval modes. Default: ``False``

Shape:
    - Input: :math:`(N, C, L)`
    - Output: :math:`(N, C, L)` (same shape as input)

Examples::

    >>> # Without Learnable Parameters
    >>> m = nn.InstanceNorm1d(100)
    >>> # With Learnable Parameters
    >>> m = nn.InstanceNorm1d(100, affine=True)
    >>> input = torch.randn(20, 100, 40)
    >>> output = m(input)

.. _`Instance Normalization: The Missing Ingredient for Fast Stylization`:
    https://arxiv.org/abs/1607.08022
",53,118,3053,65
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\instancenorm.py,InstanceNorm2d,"
Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs
with additional channel dimension) as described in the paper
`Instance Normalization: The Missing Ingredient for Fast Stylization`_ .

.. math::

    y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta

The mean and standard-deviation are calculated per-dimension separately
for each object in a mini-batch. :math:`\gamma` and :math:`\beta` are learnable parameter vectors
of size `C` (where `C` is the input size) if :attr:`affine` is ``True``.

By default, this layer uses instance statistics computed from input data in
both training and evaluation modes.

If :attr:`track_running_stats` is set to ``True``, during training this
layer keeps running estimates of its computed mean and variance, which are
then used for normalization during evaluation. The running estimates are
kept with a default :attr:`momentum` of 0.1.

.. note::
    This :attr:`momentum` argument is different from one used in optimizer
    classes and the conventional notion of momentum. Mathematically, the
    update rule for running statistics here is
    :math:`\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momemtum} \times x_t`,
    where :math:`\hat{x}` is the estimated statistic and :math:`x_t` is the
    new observed value.

.. note::
    :class:`InstanceNorm2d` and :class:`LayerNorm` are very similar, but
    have some subtle differences. :class:`InstanceNorm2d` is applied
    on each channel of channeled data like RGB images, but
    :class:`LayerNorm` is usually applied on entire sample and often in NLP
    tasks. Additionaly, :class:`LayerNorm` applies elementwise affine
    transform, while :class:`InstanceNorm2d` usually don't apply affine
    transform.

Args:
    num_features: :math:`C` from an expected input of size
        :math:`(N, C, H, W)`
    eps: a value added to the denominator for numerical stability. Default: 1e-5
    momentum: the value used for the running_mean and running_var computation. Default: 0.1
    affine: a boolean value that when set to ``True``, this module has
        learnable affine parameters, initialized the same way as done for batch normalization.
        Default: ``False``.
    track_running_stats: a boolean value that when set to ``True``, this
        module tracks the running mean and variance, and when set to ``False``,
        this module does not track such statistics and always uses batch
        statistics in both training and eval modes. Default: ``False``

Shape:
    - Input: :math:`(N, C, H, W)`
    - Output: :math:`(N, C, H, W)` (same shape as input)

Examples::

    >>> # Without Learnable Parameters
    >>> m = nn.InstanceNorm2d(100)
    >>> # With Learnable Parameters
    >>> m = nn.InstanceNorm2d(100, affine=True)
    >>> input = torch.randn(20, 100, 35, 45)
    >>> output = m(input)

.. _`Instance Normalization: The Missing Ingredient for Fast Stylization`:
    https://arxiv.org/abs/1607.08022
",134,199,2992,65
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\instancenorm.py,InstanceNorm3d,"
Applies Instance Normalization over a 5D input (a mini-batch of 3D inputs
with additional channel dimension) as described in the paper
`Instance Normalization: The Missing Ingredient for Fast Stylization`_ .

.. math::

    y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta

The mean and standard-deviation are calculated per-dimension separately
for each object in a mini-batch. :math:`\gamma` and :math:`\beta` are learnable parameter vectors
of size C (where C is the input size) if :attr:`affine` is ``True``.

By default, this layer uses instance statistics computed from input data in
both training and evaluation modes.

If :attr:`track_running_stats` is set to ``True``, during training this
layer keeps running estimates of its computed mean and variance, which are
then used for normalization during evaluation. The running estimates are
kept with a default :attr:`momentum` of 0.1.

.. note::
    This :attr:`momentum` argument is different from one used in optimizer
    classes and the conventional notion of momentum. Mathematically, the
    update rule for running statistics here is
    :math:`\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momemtum} \times x_t`,
    where :math:`\hat{x}` is the estimated statistic and :math:`x_t` is the
    new observed value.

.. note::
    :class:`InstanceNorm3d` and :class:`LayerNorm` are very similar, but
    have some subtle differences. :class:`InstanceNorm3d` is applied
    on each channel of channeled data like 3D models with RGB color, but
    :class:`LayerNorm` is usually applied on entire sample and often in NLP
    tasks. Additionaly, :class:`LayerNorm` applies elementwise affine
    transform, while :class:`InstanceNorm3d` usually don't apply affine
    transform.

Args:
    num_features: :math:`C` from an expected input of size
        :math:`(N, C, D, H, W)`
    eps: a value added to the denominator for numerical stability. Default: 1e-5
    momentum: the value used for the running_mean and running_var computation. Default: 0.1
    affine: a boolean value that when set to ``True``, this module has
        learnable affine parameters, initialized the same way as done for batch normalization.
        Default: ``False``.
    track_running_stats: a boolean value that when set to ``True``, this
        module tracks the running mean and variance, and when set to ``False``,
        this module does not track such statistics and always uses batch
        statistics in both training and eval modes. Default: ``False``

Shape:
    - Input: :math:`(N, C, D, H, W)`
    - Output: :math:`(N, C, D, H, W)` (same shape as input)

Examples::

    >>> # Without Learnable Parameters
    >>> m = nn.InstanceNorm3d(100)
    >>> # With Learnable Parameters
    >>> m = nn.InstanceNorm3d(100, affine=True)
    >>> input = torch.randn(20, 100, 35, 45, 10)
    >>> output = m(input)

.. _`Instance Normalization: The Missing Ingredient for Fast Stylization`:
    https://arxiv.org/abs/1607.08022
",208,273,3015,65
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\linear.py,Identity,"
A placeholder identity operator that is argument-insensitive.

Args:
    args: any argument (unused)
    kwargs: any keyword argument (unused)

Examples::

    >>> m = nn.Identity(54, unused_argument1=0.1, unused_argument2=False)
    >>> input = torch.randn(128, 20)
    >>> output = m(input)
    >>> print(output.size())
    torch.Size([128, 20])
",11,24,347,13
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\linear.py,Linear,"
Applies a linear transformation to the incoming data: :math:`y = xA^T + b`

Args:
    in_features: size of each input sample
    out_features: size of each output sample
    bias: If set to ``False``, the layer will not learn an additive bias.
        Default: ``True``

Shape:
    - Input: :math:`(N, *, H_{in})` where :math:`*` means any number of
      additional dimensions and :math:`H_{in} = \text{in\_features}`
    - Output: :math:`(N, *, H_{out})` where all but the last dimension
      are the same shape as the input and :math:`H_{out} = \text{out\_features}`.

Attributes:
    weight: the learnable weights of the module of shape
        :math:`(\text{out\_features}, \text{in\_features})`. The values are
        initialized from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`, where
        :math:`k = \frac{1}{\text{in\_features}}`
    bias:   the learnable bias of the module of shape :math:`(\text{out\_features})`.
            If :attr:`bias` is ``True``, the values are initialized from
            :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
            :math:`k = \frac{1}{\text{in\_features}}`

Examples::

    >>> m = nn.Linear(20, 30)
    >>> input = torch.randn(128, 20)
    >>> output = m(input)
    >>> print(output.size())
    torch.Size([128, 30])
",34,65,1273,31
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\linear.py,Bilinear,"
Applies a bilinear transformation to the incoming data:
:math:`y = x_1 A x_2 + b`

Args:
    in1_features: size of each first input sample
    in2_features: size of each second input sample
    out_features: size of each output sample
    bias: If set to False, the layer will not learn an additive bias.
        Default: ``True``

Shape:
    - Input1: :math:`(N, *, H_{in1})` where :math:`H_{in1}=\text{in1\_features}` and
      :math:`*` means any number of additional dimensions. All but the last dimension
      of the inputs should be the same.
    - Input2: :math:`(N, *, H_{in2})` where :math:`H_{in2}=\text{in2\_features}`.
    - Output: :math:`(N, *, H_{out})` where :math:`H_{out}=\text{out\_features}`
      and all but the last dimension are the same shape as the input.

Attributes:
    weight: the learnable weights of the module of shape
        :math:`(\text{out\_features}, \text{in1\_features}, \text{in2\_features})`.
        The values are initialized from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`, where
        :math:`k = \frac{1}{\text{in1\_features}}`
    bias:   the learnable bias of the module of shape :math:`(\text{out\_features})`.
            If :attr:`bias` is ``True``, the values are initialized from
            :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`, where
            :math:`k = \frac{1}{\text{in1\_features}}`

Examples::

    >>> m = nn.Bilinear(20, 30, 40)
    >>> input1 = torch.randn(128, 20)
    >>> input2 = torch.randn(128, 30)
    >>> output = m(input1, input2)
    >>> print(output.size())
    torch.Size([128, 40])
",96,132,1564,36
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,_Loss,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,_WeightedLoss,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,L1Loss,"
Creates a criterion that measures the mean absolute error (MAE) between each element in
the input :math:`x` and target :math:`y`.

The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:

.. math::
    \ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
    l_n = \left| x_n - y_n \right|,

where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``
(default ``'mean'``), then:

.. math::
    \ell(x, y) =
    \begin{cases}
        \operatorname{mean}(L), & \text{if reduction} = \text{'mean';}\\
        \operatorname{sum}(L),  & \text{if reduction} = \text{'sum'.}
    \end{cases}

:math:`x` and :math:`y` are tensors of arbitrary shapes with a total
of :math:`n` elements each.

The sum operation still operates over all the elements, and divides by :math:`n`.

The division by :math:`n` can be avoided if one sets ``reduction = 'sum'``.

Args:
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Shape:
    - Input: :math:`(N, *)` where :math:`*` means, any number of additional
      dimensions
    - Target: :math:`(N, *)`, same shape as the input
    - Output: scalar. If :attr:`reduction` is ``'none'``, then
      :math:`(N, *)`, same shape as the input

Examples::

    >>> loss = nn.L1Loss()
    >>> input = torch.randn(3, 5, requires_grad=True)
    >>> target = torch.randn(3, 5)
    >>> output = loss(input, target)
    >>> output.backward()
",24,81,2605,57
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,NLLLoss,"
The negative log likelihood loss. It is useful to train a classification
problem with `C` classes.

If provided, the optional argument :attr:`weight` should be a 1D Tensor assigning
weight to each of the classes. This is particularly useful when you have an
unbalanced training set.

The `input` given through a forward call is expected to contain
log-probabilities of each class. `input` has to be a Tensor of size either
:math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)`
with :math:`K \geq 1` for the `K`-dimensional case (described later).

Obtaining log-probabilities in a neural network is easily achieved by
adding a  `LogSoftmax`  layer in the last layer of your network.
You may use `CrossEntropyLoss` instead, if you prefer not to add an extra
layer.

The `target` that this loss expects should be a class index in the range :math:`[0, C-1]`
where `C = number of classes`; if `ignore_index` is specified, this loss also accepts
this class index (this index may not necessarily be in the class range).

The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:

.. math::
    \ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
    l_n = - w_{y_n} x_{n,y_n}, \quad
    w_{c} = \text{weight}[c] \cdot \mathbb{1}\{c \not= \text{ignore\_index}\},

where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight, and
:math:`N` is the batch size. If :attr:`reduction` is not ``'none'``
(default ``'mean'``), then

.. math::
    \ell(x, y) = \begin{cases}
        \sum_{n=1}^N \frac{1}{\sum_{n=1}^N w_{y_n}} l_n, &
        \text{if reduction} = \text{'mean';}\\
        \sum_{n=1}^N l_n,  &
        \text{if reduction} = \text{'sum'.}
    \end{cases}

Can also be used for higher dimension inputs, such as 2D images, by providing
an input of size :math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`,
where :math:`K` is the number of dimensions, and a target of appropriate shape
(see below). In the case of images, it computes NLL loss per-pixel.

Args:
    weight (Tensor, optional): a manual rescaling weight given to each
        class. If given, it has to be a Tensor of size `C`. Otherwise, it is
        treated as if having all ones.
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    ignore_index (int, optional): Specifies a target value that is ignored
        and does not contribute to the input gradient. When
        :attr:`size_average` is ``True``, the loss is averaged over
        non-ignored targets.
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Shape:
    - Input: :math:`(N, C)` where `C = number of classes`, or
      :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`
      in the case of `K`-dimensional loss.
    - Target: :math:`(N)` where each value is :math:`0 \leq \text{targets}[i] \leq C-1`, or
      :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \geq 1` in the case of
      K-dimensional loss.
    - Output: scalar.
      If :attr:`reduction` is ``'none'``, then the same size as the target: :math:`(N)`, or
      :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \geq 1` in the case
      of K-dimensional loss.

Examples::

    >>> m = nn.LogSoftmax(dim=1)
    >>> loss = nn.NLLLoss()
    >>> # input is of size N x C = 3 x 5
    >>> input = torch.randn(3, 5, requires_grad=True)
    >>> # each element in target has to have 0 <= value < C
    >>> target = torch.tensor([1, 0, 4])
    >>> output = loss(m(input), target)
    >>> output.backward()
    >>>
    >>>
    >>> # 2D loss example (used, for example, with image inputs)
    >>> N, C = 5, 4
    >>> loss = nn.NLLLoss()
    >>> # input is of size N x C x height x width
    >>> data = torch.randn(N, 16, 10, 10)
    >>> conv = nn.Conv2d(16, C, (3, 3))
    >>> m = nn.LogSoftmax(dim=1)
    >>> # each element in target has to have 0 <= value < C
    >>> target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)
    >>> output = loss(m(conv(data)), target)
    >>> output.backward()
",92,196,5122,104
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,NLLLoss2d,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,PoissonNLLLoss,"
Negative log likelihood loss with Poisson distribution of target.

The loss can be described as:

.. math::
    \text{target} \sim \mathrm{Poisson}(\text{input})

    \text{loss}(\text{input}, \text{target}) = \text{input} - \text{target} * \log(\text{input})
                                + \log(\text{target!})

The last term can be omitted or approximated with Stirling formula. The
approximation is used for target values more than 1. For targets less or
equal to 1 zeros are added to the loss.

Args:
    log_input (bool, optional): if ``True`` the loss is computed as
        :math:`\exp(\text{input}) - \text{target}*\text{input}`, if ``False`` the loss is
        :math:`\text{input} - \text{target}*\log(\text{input}+\text{eps})`.
    full (bool, optional): whether to compute full loss, i. e. to add the
        Stirling approximation term

        .. math::
            \text{target}*\log(\text{target}) - \text{target} + 0.5 * \log(2\pi\text{target}).
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    eps (float, optional): Small value to avoid evaluation of :math:`\log(0)` when
        :attr:`log_input = False`. Default: 1e-8
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Examples::

    >>> loss = nn.PoissonNLLLoss()
    >>> log_input = torch.randn(5, 2, requires_grad=True)
    >>> target = torch.randn(5, 2)
    >>> output = loss(log_input, target)
    >>> output.backward()

Shape:
    - Input: :math:`(N, *)` where :math:`*` means, any number of additional
      dimensions
    - Target: :math:`(N, *)`, same shape as the input
    - Output: scalar by default. If :attr:`reduction` is ``'none'``, then :math:`(N, *)`,
      the same shape as the input
",218,273,2844,55
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,KLDivLoss,"
The `Kullback-Leibler divergence`_ Loss

KL divergence is a useful distance measure for continuous distributions
and is often useful when performing direct regression over the space of
(discretely sampled) continuous output distributions.

As with :class:`~torch.nn.NLLLoss`, the `input` given is expected to contain
*log-probabilities* and is not restricted to a 2D Tensor.
The targets are given as *probabilities* (i.e. without taking the logarithm).

This criterion expects a `target` `Tensor` of the same size as the
`input` `Tensor`.

The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:

.. math::
    l(x,y) = L = \{ l_1,\dots,l_N \}, \quad
    l_n = y_n \cdot \left( \log y_n - x_n \right)

where the index :math:`N` spans all dimensions of ``input`` and :math:`L` has the same
shape as ``input``. If :attr:`reduction` is not ``'none'`` (default ``'mean'``), then:

.. math::
    \ell(x, y) = \begin{cases}
        \operatorname{mean}(L), & \text{if reduction} = \text{'mean';} \\
        \operatorname{sum}(L),  & \text{if reduction} = \text{'sum'.}
    \end{cases}

In default :attr:`reduction` mode ``'mean'``, the losses are averaged for each minibatch over observations
**as well as** over dimensions. ``'batchmean'`` mode gives the correct KL divergence where losses
are averaged over batch dimension only. ``'mean'`` mode's behavior will be changed to the same as
``'batchmean'`` in the next major release.

.. _Kullback-Leibler divergence:
    https://en.wikipedia.org/wiki/Kullback-Leibler_divergence

Args:
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'batchmean'`` | ``'sum'`` | ``'mean'``.
        ``'none'``: no reduction will be applied.
        ``'batchmean'``: the sum of the output will be divided by batchsize.
        ``'sum'``: the output will be summed.
        ``'mean'``: the output will be divided by the number of elements in the output.
        Default: ``'mean'``

.. note::
    :attr:`size_average` and :attr:`reduce` are in the process of being deprecated,
    and in the meantime, specifying either of those two args will override :attr:`reduction`.

.. note::
    :attr:`reduction` = ``'mean'`` doesn't return the true kl divergence value, please use
    :attr:`reduction` = ``'batchmean'`` which aligns with KL math definition.
    In the next major release, ``'mean'`` will be changed to be the same as ``'batchmean'``.

Shape:
    - Input: :math:`(N, *)` where :math:`*` means, any number of additional
      dimensions
    - Target: :math:`(N, *)`, same shape as the input
    - Output: scalar by default. If :attr:``reduction`` is ``'none'``, then :math:`(N, *)`,
      the same shape as the input
",289,358,3470,69
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,MSELoss,"
Creates a criterion that measures the mean squared error (squared L2 norm) between
each element in the input :math:`x` and target :math:`y`.

The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:

.. math::
    \ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
    l_n = \left( x_n - y_n \right)^2,

where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``
(default ``'mean'``), then:

.. math::
    \ell(x, y) =
    \begin{cases}
        \operatorname{mean}(L), &  \text{if reduction} = \text{'mean';}\\
        \operatorname{sum}(L),  &  \text{if reduction} = \text{'sum'.}
    \end{cases}

:math:`x` and :math:`y` are tensors of arbitrary shapes with a total
of :math:`n` elements each.

The sum operation still operates over all the elements, and divides by :math:`n`.

The division by :math:`n` can be avoided if one sets ``reduction = 'sum'``.

Args:
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Shape:
    - Input: :math:`(N, *)` where :math:`*` means, any number of additional
      dimensions
    - Target: :math:`(N, *)`, same shape as the input

Examples::

    >>> loss = nn.MSELoss()
    >>> input = torch.randn(3, 5, requires_grad=True)
    >>> target = torch.randn(3, 5)
    >>> output = loss(input, target)
    >>> output.backward()
",370,425,2512,55
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,BCELoss,"
Creates a criterion that measures the Binary Cross Entropy
between the target and the output:

The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:

.. math::
    \ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
    l_n = - w_n \left[ y_n \cdot \log x_n + (1 - y_n) \cdot \log (1 - x_n) \right],

where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``
(default ``'mean'``), then

.. math::
    \ell(x, y) = \begin{cases}
        \operatorname{mean}(L), & \text{if reduction} = \text{'mean';}\\
        \operatorname{sum}(L),  & \text{if reduction} = \text{'sum'.}
    \end{cases}

This is used for measuring the error of a reconstruction in for example
an auto-encoder. Note that the targets :math:`y` should be numbers
between 0 and 1.

Args:
    weight (Tensor, optional): a manual rescaling weight given to the loss
        of each batch element. If given, has to be a Tensor of size `nbatch`.
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Shape:
    - Input: :math:`(N, *)` where :math:`*` means, any number of additional
      dimensions
    - Target: :math:`(N, *)`, same shape as the input
    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N, *)`, same
      shape as input.

Examples::

    >>> m = nn.Sigmoid()
    >>> loss = nn.BCELoss()
    >>> input = torch.randn(3, requires_grad=True)
    >>> target = torch.empty(3).random_(2)
    >>> output = loss(m(input), target)
    >>> output.backward()
",436,492,2695,56
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,BCEWithLogitsLoss,"
This loss combines a `Sigmoid` layer and the `BCELoss` in one single
class. This version is more numerically stable than using a plain `Sigmoid`
followed by a `BCELoss` as, by combining the operations into one layer,
we take advantage of the log-sum-exp trick for numerical stability.

The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:

.. math::
    \ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
    l_n = - w_n \left[ y_n \cdot \log \sigma(x_n)
    + (1 - y_n) \cdot \log (1 - \sigma(x_n)) \right],

where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``
(default ``'mean'``), then

.. math::
    \ell(x, y) = \begin{cases}
        \operatorname{mean}(L), & \text{if reduction} = \text{'mean';}\\
        \operatorname{sum}(L),  & \text{if reduction} = \text{'sum'.}
    \end{cases}

This is used for measuring the error of a reconstruction in for example
an auto-encoder. Note that the targets `t[i]` should be numbers
between 0 and 1.

It's possible to trade off recall and precision by adding weights to positive examples.
In the case of multi-label classification the loss can be described as:

.. math::
    \ell_c(x, y) = L_c = \{l_{1,c},\dots,l_{N,c}\}^\top, \quad
    l_{n,c} = - w_{n,c} \left[ p_c y_{n,c} \cdot \log \sigma(x_{n,c})
    + (1 - y_{n,c}) \cdot \log (1 - \sigma(x_{n,c})) \right],

where :math:`c` is the class number (:math:`c > 1` for multi-label binary classification,
:math:`c = 1` for single-label binary classification),
:math:`n` is the number of the sample in the batch and
:math:`p_c` is the weight of the positive answer for the class :math:`c`.

:math:`p_c > 1` increases the recall, :math:`p_c < 1` increases the precision.

For example, if a dataset contains 100 positive and 300 negative examples of a single class,
then `pos_weight` for the class should be equal to :math:`\frac{300}{100}=3`.
The loss would act as if the dataset contains :math:`3\times 100=300` positive examples.

Examples::

    >>> target = torch.ones([10, 64], dtype=torch.float32)  # 64 classes, batch size = 10
    >>> output = torch.full([10, 64], 0.999)  # A prediction (logit)
    >>> pos_weight = torch.ones([64])  # All weights are equal to 1
    >>> criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)
    >>> criterion(output, target)  # -log(sigmoid(0.999))
    tensor(0.3135)

Args:
    weight (Tensor, optional): a manual rescaling weight given to the loss
        of each batch element. If given, has to be a Tensor of size `nbatch`.
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
    pos_weight (Tensor, optional): a weight of positive examples.
            Must be a vector with length equal to the number of classes.

Shape:
    - Input: :math:`(N, *)` where :math:`*` means, any number of additional dimensions
    - Target: :math:`(N, *)`, same shape as the input
    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N, *)`, same
      shape as input.

 Examples::

    >>> loss = nn.BCEWithLogitsLoss()
    >>> input = torch.randn(3, requires_grad=True)
    >>> target = torch.empty(3).random_(2)
    >>> output = loss(input, target)
    >>> output.backward()
",503,590,4389,87
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,HingeEmbeddingLoss,"
Measures the loss given an input tensor :math:`x` and a labels tensor :math:`y`
(containing 1 or -1).
This is usually used for measuring whether two inputs are similar or
dissimilar, e.g. using the L1 pairwise distance as :math:`x`, and is typically
used for learning nonlinear embeddings or semi-supervised learning.

The loss function for :math:`n`-th sample in the mini-batch is

.. math::
    l_n = \begin{cases}
        x_n, & \text{if}\; y_n = 1,\\
        \max \{0, \Delta - x_n\}, & \text{if}\; y_n = -1,
    \end{cases}

and the total loss functions is

.. math::
    \ell(x, y) = \begin{cases}
        \operatorname{mean}(L), & \text{if reduction} = \text{'mean';}\\
        \operatorname{sum}(L),  & \text{if reduction} = \text{'sum'.}
    \end{cases}

where :math:`L = \{l_1,\dots,l_N\}^\top`.

Args:
    margin (float, optional): Has a default value of `1`.
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Shape:
    - Input: :math:`(*)` where :math:`*` means, any number of dimensions. The sum operation
      operates over all the elements.
    - Target: :math:`(*)`, same shape as the input
    - Output: scalar. If :attr:`reduction` is ``'none'``, then same shape as the input
",606,653,2406,47
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,MultiLabelMarginLoss,"
Creates a criterion that optimizes a multi-class multi-classification
hinge loss (margin-based loss) between input :math:`x` (a 2D mini-batch `Tensor`)
and output :math:`y` (which is a 2D `Tensor` of target class indices).
For each sample in the mini-batch:

.. math::
    \text{loss}(x, y) = \sum_{ij}\frac{\max(0, 1 - (x[y[j]] - x[i]))}{\text{x.size}(0)}

where :math:`x \in \left\{0, \; \cdots , \; \text{x.size}(0) - 1\right\}`, \
:math:`y \in \left\{0, \; \cdots , \; \text{y.size}(0) - 1\right\}`, \
:math:`0 \leq y[j] \leq \text{x.size}(0)-1`, \
and :math:`i \neq y[j]` for all :math:`i` and :math:`j`.

:math:`y` and :math:`x` must have the same size.

The criterion only considers a contiguous block of non-negative targets that
starts at the front.

This allows for different samples to have variable amounts of target classes.

Args:
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Shape:
    - Input: :math:`(C)` or :math:`(N, C)` where `N` is the batch size and `C`
      is the number of classes.
    - Target: :math:`(C)` or :math:`(N, C)`, label targets padded by -1 ensuring same shape as the input.
    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N)`.

Examples::

    >>> loss = nn.MultiLabelMarginLoss()
    >>> x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8]])
    >>> # for target y, only consider labels 3 and 0, not after label -1
    >>> y = torch.LongTensor([[3, 0, -1, 1]])
    >>> loss(x, y)
    >>> # 0.25 * ((1-(0.1-0.2)) + (1-(0.1-0.4)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))
    tensor(0.8500)
",665,717,2751,52
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,SmoothL1Loss,"
Creates a criterion that uses a squared term if the absolute
element-wise error falls below 1 and an L1 term otherwise.
It is less sensitive to outliers than the `MSELoss` and in some cases
prevents exploding gradients (e.g. see `Fast R-CNN` paper by Ross Girshick).
Also known as the Huber loss:

.. math::
    \text{loss}(x, y) = \frac{1}{n} \sum_{i} z_{i}

where :math:`z_{i}` is given by:

.. math::
    z_{i} =
    \begin{cases}
    0.5 (x_i - y_i)^2, & \text{if } |x_i - y_i| < 1 \\
    |x_i - y_i| - 0.5, & \text{otherwise }
    \end{cases}

:math:`x` and :math:`y` arbitrary shapes with a total of :math:`n` elements each
the sum operation still operates over all the elements, and divides by :math:`n`.

The division by :math:`n` can be avoided if sets ``reduction = 'sum'``.

Args:
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Shape:
    - Input: :math:`(N, *)` where :math:`*` means, any number of additional
      dimensions
    - Target: :math:`(N, *)`, same shape as the input
    - Output: scalar. If :attr:`reduction` is ``'none'``, then
      :math:`(N, *)`, same shape as the input
",729,775,2315,46
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,SoftMarginLoss,"
Creates a criterion that optimizes a two-class classification
logistic loss between input tensor :math:`x` and target tensor :math:`y`
(containing 1 or -1).

.. math::
    \text{loss}(x, y) = \sum_i \frac{\log(1 + \exp(-y[i]*x[i]))}{\text{x.nelement}()}

Args:
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Shape:
    - Input: :math:`(*)` where :math:`*` means, any number of additional
      dimensions
    - Target: :math:`(*)`, same shape as the input
    - Output: scalar. If :attr:`reduction` is ``'none'``, then same shape as the input
",787,816,1756,29
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,CrossEntropyLoss,"
This criterion combines :func:`nn.LogSoftmax` and :func:`nn.NLLLoss` in one single class.

It is useful when training a classification problem with `C` classes.
If provided, the optional argument :attr:`weight` should be a 1D `Tensor`
assigning weight to each of the classes.
This is particularly useful when you have an unbalanced training set.

The `input` is expected to contain raw, unnormalized scores for each class.

`input` has to be a Tensor of size either :math:`(minibatch, C)` or
:math:`(minibatch, C, d_1, d_2, ..., d_K)`
with :math:`K \geq 1` for the `K`-dimensional case (described later).

This criterion expects a class index in the range :math:`[0, C-1]` as the
`target` for each value of a 1D tensor of size `minibatch`; if `ignore_index`
is specified, this criterion also accepts this class index (this index may not
necessarily be in the class range).

The loss can be described as:

.. math::
    \text{loss}(x, class) = -\log\left(\frac{\exp(x[class])}{\sum_j \exp(x[j])}\right)
                   = -x[class] + \log\left(\sum_j \exp(x[j])\right)

or in the case of the :attr:`weight` argument being specified:

.. math::
    \text{loss}(x, class) = weight[class] \left(-x[class] + \log\left(\sum_j \exp(x[j])\right)\right)

The losses are averaged across observations for each minibatch.

Can also be used for higher dimension inputs, such as 2D images, by providing
an input of size :math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`,
where :math:`K` is the number of dimensions, and a target of appropriate shape
(see below).


Args:
    weight (Tensor, optional): a manual rescaling weight given to each class.
        If given, has to be a Tensor of size `C`
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    ignore_index (int, optional): Specifies a target value that is ignored
        and does not contribute to the input gradient. When :attr:`size_average` is
        ``True``, the loss is averaged over non-ignored targets.
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Shape:
    - Input: :math:`(N, C)` where `C = number of classes`, or
      :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`
      in the case of `K`-dimensional loss.
    - Target: :math:`(N)` where each value is :math:`0 \leq \text{targets}[i] \leq C-1`, or
      :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \geq 1` in the case of
      K-dimensional loss.
    - Output: scalar.
      If :attr:`reduction` is ``'none'``, then the same size as the target:
      :math:`(N)`, or
      :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \geq 1` in the case
      of K-dimensional loss.

Examples::

    >>> loss = nn.CrossEntropyLoss()
    >>> input = torch.randn(3, 5, requires_grad=True)
    >>> target = torch.empty(3, dtype=torch.long).random_(5)
    >>> output = loss(input, target)
    >>> output.backward()
",828,907,4002,79
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,MultiLabelSoftMarginLoss,"
Creates a criterion that optimizes a multi-label one-versus-all
loss based on max-entropy, between input :math:`x` and target :math:`y` of size
:math:`(N, C)`.
For each sample in the minibatch:

.. math::
    loss(x, y) = - \frac{1}{C} * \sum_i y[i] * \log((1 + \exp(-x[i]))^{-1})
                     + (1-y[i]) * \log\left(\frac{\exp(-x[i])}{(1 + \exp(-x[i]))}\right)

where :math:`i \in \left\{0, \; \cdots , \; \text{x.nElement}() - 1\right\}`,
:math:`y[i] \in \left\{0, \; 1\right\}`.

Args:
    weight (Tensor, optional): a manual rescaling weight given to each
        class. If given, it has to be a Tensor of size `C`. Otherwise, it is
        treated as if having all ones.
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Shape:
    - Input: :math:`(N, C)` where `N` is the batch size and `C` is the number of classes.
    - Target: :math:`(N, C)`, label targets padded by -1 ensuring same shape as the input.
    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N)`.
",921,957,2208,36
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,CosineEmbeddingLoss,"
Creates a criterion that measures the loss given input tensors
:math:`x_1`, :math:`x_2` and a `Tensor` label :math:`y` with values 1 or -1.
This is used for measuring whether two inputs are similar or dissimilar,
using the cosine distance, and is typically used for learning nonlinear
embeddings or semi-supervised learning.

The loss function for each sample is:

.. math::
    \text{loss}(x, y) =
    \begin{cases}
    1 - \cos(x_1, x_2), & \text{if } y = 1 \\
    \max(0, \cos(x_1, x_2) - \text{margin}), & \text{if } y = -1
    \end{cases}

Args:
    margin (float, optional): Should be a number from :math:`-1` to :math:`1`,
        :math:`0` to :math:`0.5` is suggested. If :attr:`margin` is missing, the
        default value is :math:`0`.
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
",968,1002,2006,34
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,MarginRankingLoss,"
Creates a criterion that measures the loss given
inputs :math:`x1`, :math:`x2`, two 1D mini-batch `Tensors`,
and a label 1D mini-batch tensor :math:`y` (containing 1 or -1).

If :math:`y = 1` then it assumed the first input should be ranked higher
(have a larger value) than the second input, and vice-versa for :math:`y = -1`.

The loss function for each sample in the mini-batch is:

.. math::
    \text{loss}(x, y) = \max(0, -y * (x1 - x2) + \text{margin})

Args:
    margin (float, optional): Has a default value of :math:`0`.
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Shape:
    - Input: :math:`(N, D)` where `N` is the batch size and `D` is the size of a sample.
    - Target: :math:`(N)`
    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N)`.
",1014,1048,1989,34
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,MultiMarginLoss,"
Creates a criterion that optimizes a multi-class classification hinge
loss (margin-based loss) between input :math:`x` (a 2D mini-batch `Tensor`) and
output :math:`y` (which is a 1D tensor of target class indices,
:math:`0 \leq y \leq \text{x.size}(1)-1`):

For each mini-batch sample, the loss in terms of the 1D input :math:`x` and scalar
output :math:`y` is:

.. math::
    \text{loss}(x, y) = \frac{\sum_i \max(0, \text{margin} - x[y] + x[i]))^p}{\text{x.size}(0)}

where :math:`x \in \left\{0, \; \cdots , \; \text{x.size}(0) - 1\right\}`
and :math:`i \neq y`.

Optionally, you can give non-equal weighting on the classes by passing
a 1D :attr:`weight` tensor into the constructor.

The loss function then becomes:

.. math::
    \text{loss}(x, y) = \frac{\sum_i \max(0, w[y] * (\text{margin} - x[y] + x[i]))^p)}{\text{x.size}(0)}

Args:
    p (int, optional): Has a default value of :math:`1`. :math:`1` and :math:`2`
        are the only supported values.
    margin (float, optional): Has a default value of :math:`1`.
    weight (Tensor, optional): a manual rescaling weight given to each
        class. If given, it has to be a Tensor of size `C`. Otherwise, it is
        treated as if having all ones.
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
",1060,1104,2473,44
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,TripletMarginLoss,"
Creates a criterion that measures the triplet loss given an input
tensors :math:`x1`, :math:`x2`, :math:`x3` and a margin with a value greater than :math:`0`.
This is used for measuring a relative similarity between samples. A triplet
is composed by `a`, `p` and `n` (i.e., `anchor`, `positive examples` and `negative
examples` respectively). The shapes of all input tensors should be
:math:`(N, D)`.

The distance swap is described in detail in the paper `Learning shallow
convolutional feature descriptors with triplet losses`_ by
V. Balntas, E. Riba et al.

The loss function for each sample in the mini-batch is:

.. math::
    L(a, p, n) = \max \{d(a_i, p_i) - d(a_i, n_i) + {\rm margin}, 0\}


where

.. math::
    d(x_i, y_i) = \left\lVert {\bf x}_i - {\bf y}_i \right\rVert_p

Args:
    margin (float, optional): Default: :math:`1`.
    p (int, optional): The norm degree for pairwise distance. Default: :math:`2`.
    swap (bool, optional): The distance swap is described in detail in the paper
        `Learning shallow convolutional feature descriptors with triplet losses` by
        V. Balntas, E. Riba et al. Default: ``False``.
    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
        the losses are averaged over each loss element in the batch. Note that for
        some losses, there are multiple elements per sample. If the field :attr:`size_average`
        is set to ``False``, the losses are instead summed for each minibatch. Ignored
        when reduce is ``False``. Default: ``True``
    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
        losses are averaged or summed over observations for each minibatch depending
        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
        batch element instead and ignores :attr:`size_average`. Default: ``True``
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the sum of the output will be divided by the number of
        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
        and :attr:`reduce` are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``

Shape:
    - Input: :math:`(N, D)` where :math:`D` is the vector dimension.
    - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N)`.

>>> triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)
>>> anchor = torch.randn(100, 128, requires_grad=True)
>>> positive = torch.randn(100, 128, requires_grad=True)
>>> negative = torch.randn(100, 128, requires_grad=True)
>>> output = triplet_loss(anchor, positive, negative)
>>> output.backward()

.. _Learning shallow convolutional feature descriptors with triplet losses:
    http://www.bmva.org/bmvc/2016/papers/paper119/index.html
",1122,1179,2996,57
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\loss.py,CTCLoss,"
The Connectionist Temporal Classification loss.

Calculates loss between a continuous (unsegmented) time series and a target sequence. CTCLoss sums over the
probability of possible alignments of input to target, producing a loss value which is differentiable
with respect to each input node. The alignment of input to target is assumed to be ""many-to-one"", which
limits the length of the target sequence such that it must be :math:`\leq` the input length.

Args:
    blank (int, optional): blank label. Default :math:`0`.
    reduction (string, optional): Specifies the reduction to apply to the output:
        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
        ``'mean'``: the output losses will be divided by the target lengths and
        then the mean over the batch is taken. Default: ``'mean'``
    zero_infinity (bool, optional):
        Whether to zero infinite losses and the associated gradients.
        Default: ``False``
        Infinite losses mainly occur when the inputs are too short
        to be aligned to the targets.

Shape:
    - Log_probs: Tensor of size :math:`(T, N, C)`,
      where :math:`T = \text{input length}`,
      :math:`N = \text{batch size}`, and
      :math:`C = \text{number of classes (including blank)}`.
      The logarithmized probabilities of the outputs (e.g. obtained with
      :func:`torch.nn.functional.log_softmax`).
    - Targets: Tensor of size :math:`(N, S)` or
      :math:`(\operatorname{sum}(\text{target\_lengths}))`,
      where :math:`N = \text{batch size}` and
      :math:`S = \text{max target length, if shape is } (N, S)`.
      It represent the target sequences. Each element in the target
      sequence is a class index. And the target index cannot be blank (default=0).
      In the :math:`(N, S)` form, targets are padded to the
      length of the longest sequence, and stacked.
      In the :math:`(\operatorname{sum}(\text{target\_lengths}))` form,
      the targets are assumed to be un-padded and
      concatenated within 1 dimension.
    - Input_lengths: Tuple or tensor of size :math:`(N)`,
      where :math:`N = \text{batch size}`. It represent the lengths of the
      inputs (must each be :math:`\leq T`). And the lengths are specified
      for each sequence to achieve masking under the assumption that sequences
      are padded to equal lengths.
    - Target_lengths: Tuple or tensor of size :math:`(N)`,
      where :math:`N = \text{batch size}`. It represent lengths of the targets.
      Lengths are specified for each sequence to achieve masking under the
      assumption that sequences are padded to equal lengths. If target shape is
      :math:`(N,S)`, target_lengths are effectively the stop index
      :math:`s_n` for each target sequence, such that ``target_n = targets[n,0:s_n]`` for
      each target in a batch. Lengths must each be :math:`\leq S`
      If the targets are given as a 1d tensor that is the concatenation of individual
      targets, the target_lengths must add up to the total length of the tensor.
    - Output: scalar. If :attr:`reduction` is ``'none'``, then
      :math:`(N)`, where :math:`N = \text{batch size}`.

Example::

    >>> T = 50      # Input sequence length
    >>> C = 20      # Number of classes (including blank)
    >>> N = 16      # Batch size
    >>> S = 30      # Target sequence length of longest target in batch
    >>> S_min = 10  # Minimum target length, for demonstration purposes
    >>>
    >>> # Initialize random batch of input vectors, for *size = (T,N,C)
    >>> input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()
    >>>
    >>> # Initialize random batch of targets (0 = blank, 1:C = classes)
    >>> target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)
    >>>
    >>> input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)
    >>> target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)
    >>> ctc_loss = nn.CTCLoss()
    >>> loss = ctc_loss(input, target, input_lengths, target_lengths)
    >>> loss.backward()

Reference:
    A. Graves et al.: Connectionist Temporal Classification:
    Labelling Unsegmented Sequence Data with Recurrent Neural Networks:
    https://www.cs.toronto.edu/~graves/icml_2006.pdf

.. Note::
    In order to use CuDNN, the following must be satisfied: :attr:`targets` must be
    in concatenated format, all :attr:`input_lengths` must be `T`.  :math:`blank=0`,
    :attr:`target_lengths` :math:`\leq 256`, the integer arguments must be of
    dtype :attr:`torch.int32`.

    The regular implementation uses the (more common in PyTorch) `torch.long` dtype.


.. include:: cudnn_deterministic.rst
",1196,1285,4686,89
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\module.py,_IncompatibleKeys,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\module.py,Module,"
Base class for all neural network modules.

Your models should also subclass this class.

Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::

    import torch.nn as nn
    import torch.nn.functional as F

    class Model(nn.Module):
        def __init__(self):
            super(Model, self).__init__()
            self.conv1 = nn.Conv2d(1, 20, 5)
            self.conv2 = nn.Conv2d(20, 20, 5)

        def forward(self, x):
            x = F.relu(self.conv1(x))
            return F.relu(self.conv2(x))

Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:`to`, etc.
",31,53,718,22
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\normalization.py,LocalResponseNorm,"
Applies local response normalization over an input signal composed
of several input planes, where channels occupy the second dimension.
Applies normalization across channels.

.. math::
    b_{c} = a_{c}\left(k + \frac{\alpha}{n}
    \sum_{c'=\max(0, c-n/2)}^{\min(N-1,c+n/2)}a_{c'}^2\right)^{-\beta}

Args:
    size: amount of neighbouring channels used for normalization
    alpha: multiplicative factor. Default: 0.0001
    beta: exponent. Default: 0.75
    k: additive factor. Default: 1

Shape:
    - Input: :math:`(N, C, *)`
    - Output: :math:`(N, C, *)` (same shape as input)

Examples::

    >>> lrn = nn.LocalResponseNorm(2)
    >>> signal_2d = torch.randn(32, 5, 24, 24)
    >>> signal_4d = torch.randn(16, 5, 7, 7, 7, 7)
    >>> output_2d = lrn(signal_2d)
    >>> output_4d = lrn(signal_4d)
",11,36,803,25
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\normalization.py,CrossMapLRN2d,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\normalization.py,LayerNorm,"
Applies Layer Normalization over a mini-batch of inputs as described in
the paper `Layer Normalization`_ .

.. math::
    y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta

The mean and standard-deviation are calculated separately over the last
certain number dimensions which have to be of the shape specified by
:attr:`normalized_shape`.
:math:`\gamma` and :math:`\beta` are learnable affine transform parameters of
:attr:`normalized_shape` if :attr:`elementwise_affine` is ``True``.

.. note::
    Unlike Batch Normalization and Instance Normalization, which applies
    scalar scale and bias for each entire channel/plane with the
    :attr:`affine` option, Layer Normalization applies per-element scale and
    bias with :attr:`elementwise_affine`.

This layer uses statistics computed from input data in both training and
evaluation modes.

Args:
    normalized_shape (int or list or torch.Size): input shape from an expected input
        of size

        .. math::
            [* \times \text{normalized\_shape}[0] \times \text{normalized\_shape}[1]
                \times \ldots \times \text{normalized\_shape}[-1]]

        If a single integer is used, it is treated as a singleton list, and this module will
        normalize over the last dimension which is expected to be of that specific size.
    eps: a value added to the denominator for numerical stability. Default: 1e-5
    elementwise_affine: a boolean value that when set to ``True``, this module
        has learnable per-element affine parameters initialized to ones (for weights)
        and zeros (for biases). Default: ``True``.

Shape:
    - Input: :math:`(N, *)`
    - Output: :math:`(N, *)` (same shape as input)

Examples::

    >>> input = torch.randn(20, 5, 10, 10)
    >>> # With Learnable Parameters
    >>> m = nn.LayerNorm(input.size()[1:])
    >>> # Without Learnable Parameters
    >>> m = nn.LayerNorm(input.size()[1:], elementwise_affine=False)
    >>> # Normalize over last two dimensions
    >>> m = nn.LayerNorm([10, 10])
    >>> # Normalize over last dimension of size 10
    >>> m = nn.LayerNorm(10)
    >>> # Activating the module
    >>> output = m(input)

.. _`Layer Normalization`: https://arxiv.org/abs/1607.06450
",73,128,2245,55
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\normalization.py,GroupNorm,"
Applies Group Normalization over a mini-batch of inputs as described in
the paper `Group Normalization`_ .

.. math::
    y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta

The input channels are separated into :attr:`num_groups` groups, each containing
``num_channels / num_groups`` channels. The mean and standard-deviation are calculated
separately over the each group. :math:`\gamma` and :math:`\beta` are learnable
per-channel affine transform parameter vectors of size :attr:`num_channels` if
:attr:`affine` is ``True``.

This layer uses statistics computed from input data in both training and
evaluation modes.

Args:
    num_groups (int): number of groups to separate the channels into
    num_channels (int): number of channels expected in input
    eps: a value added to the denominator for numerical stability. Default: 1e-5
    affine: a boolean value that when set to ``True``, this module
        has learnable per-channel affine parameters initialized to ones (for weights)
        and zeros (for biases). Default: ``True``.

Shape:
    - Input: :math:`(N, C, *)` where :math:`C=\text{num\_channels}`
    - Output: :math:`(N, C, *)` (same shape as input)

Examples::

    >>> input = torch.randn(20, 6, 10, 10)
    >>> # Separate 6 channels into 3 groups
    >>> m = nn.GroupNorm(3, 6)
    >>> # Separate 6 channels into 6 groups (equivalent with InstanceNorm)
    >>> m = nn.GroupNorm(6, 6)
    >>> # Put all 6 channels into a single group (equivalent with LayerNorm)
    >>> m = nn.GroupNorm(1, 6)
    >>> # Activating the module
    >>> output = m(input)

.. _`Group Normalization`: https://arxiv.org/abs/1803.08494
",161,201,1666,40
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\padding.py,_ConstantPadNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\padding.py,ConstantPad1d,"
Pads the input tensor boundaries with a constant value.

For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.

Args:
    padding (int, tuple): the size of the padding. If is `int`, uses the same
        padding in both boundaries. If a 2-`tuple`, uses
        (:math:`\text{padding\_left}`, :math:`\text{padding\_right}`)

Shape:
    - Input: :math:`(N, C, W_{in})`
    - Output: :math:`(N, C, W_{out})` where

      :math:`W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}`

Examples::

    >>> m = nn.ConstantPad1d(2, 3.5)
    >>> input = torch.randn(1, 2, 4)
    >>> input
    tensor([[[-1.0491, -0.7152, -0.0749,  0.8530],
             [-1.3287,  1.8966,  0.1466, -0.2771]]])
    >>> m(input)
    tensor([[[ 3.5000,  3.5000, -1.0491, -0.7152, -0.0749,  0.8530,  3.5000,
               3.5000],
             [ 3.5000,  3.5000, -1.3287,  1.8966,  0.1466, -0.2771,  3.5000,
               3.5000]]])
    >>> m = nn.ConstantPad1d(2, 3.5)
    >>> input = torch.randn(1, 2, 3)
    >>> input
    tensor([[[ 1.6616,  1.4523, -1.1255],
             [-3.6372,  0.1182, -1.8652]]])
    >>> m(input)
    tensor([[[ 3.5000,  3.5000,  1.6616,  1.4523, -1.1255,  3.5000,  3.5000],
             [ 3.5000,  3.5000, -3.6372,  0.1182, -1.8652,  3.5000,  3.5000]]])
    >>> # using different paddings for different sides
    >>> m = nn.ConstantPad1d((3, 1), 3.5)
    >>> m(input)
    tensor([[[ 3.5000,  3.5000,  3.5000,  1.6616,  1.4523, -1.1255,  3.5000],
             [ 3.5000,  3.5000,  3.5000, -3.6372,  0.1182, -1.8652,  3.5000]]])
",24,64,1550,40
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\padding.py,ConstantPad2d,"
Pads the input tensor boundaries with a constant value.

For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.

Args:
    padding (int, tuple): the size of the padding. If is `int`, uses the same
        padding in all boundaries. If a 4-`tuple`, uses (:math:`\text{padding\_left}`,
        :math:`\text{padding\_right}`, :math:`\text{padding\_top}`, :math:`\text{padding\_bottom}`)

Shape:
    - Input: :math:`(N, C, H_{in}, W_{in})`
    - Output: :math:`(N, C, H_{out}, W_{out})` where

      :math:`H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}`

      :math:`W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}`

Examples::

    >>> m = nn.ConstantPad2d(2, 3.5)
    >>> input = torch.randn(1, 2, 2)
    >>> input
    tensor([[[ 1.6585,  0.4320],
             [-0.8701, -0.4649]]])
    >>> m(input)
    tensor([[[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],
             [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],
             [ 3.5000,  3.5000,  1.6585,  0.4320,  3.5000,  3.5000],
             [ 3.5000,  3.5000, -0.8701, -0.4649,  3.5000,  3.5000],
             [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],
             [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000]]])
    >>> # using different paddings for different sides
    >>> m = nn.ConstantPad2d((3, 0, 2, 1), 3.5)
    >>> m(input)
    tensor([[[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],
             [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],
             [ 3.5000,  3.5000,  3.5000,  1.6585,  0.4320],
             [ 3.5000,  3.5000,  3.5000, -0.8701, -0.4649],
             [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000]]])
",73,112,1683,39
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\padding.py,ConstantPad3d,"
Pads the input tensor boundaries with a constant value.

For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.

Args:
    padding (int, tuple): the size of the padding. If is `int`, uses the same
        padding in all boundaries. If a 6-`tuple`, uses
        (:math:`\text{padding\_left}`, :math:`\text{padding\_right}`,
        :math:`\text{padding\_top}`, :math:`\text{padding\_bottom}`,
        :math:`\text{padding\_front}`, :math:`\text{padding\_back}`)

Shape:
    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})`
    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})` where

      :math:`D_{out} = D_{in} + \text{padding\_front} + \text{padding\_back}`

      :math:`H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}`

      :math:`W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}`

Examples::

    >>> m = nn.ConstantPad3d(3, 3.5)
    >>> input = torch.randn(16, 3, 10, 20, 30)
    >>> output = m(input)
    >>> # using different paddings for different sides
    >>> m = nn.ConstantPad3d((3, 3, 6, 6, 0, 1), 3.5)
    >>> output = m(input)
",122,151,1090,29
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\padding.py,_ReflectionPadNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\padding.py,ReflectionPad1d,"
Pads the input tensor using the reflection of the input boundary.

For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.

Args:
    padding (int, tuple): the size of the padding. If is `int`, uses the same
        padding in all boundaries. If a 2-`tuple`, uses
        (:math:`\text{padding\_left}`, :math:`\text{padding\_right}`)

Shape:
    - Input: :math:`(N, C, W_{in})`
    - Output: :math:`(N, C, W_{out})` where

      :math:`W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}`

Examples::

    >>> m = nn.ReflectionPad1d(2)
    >>> input = torch.arange(8, dtype=torch.float).reshape(1, 2, 4)
    >>> input
    tensor([[[0., 1., 2., 3.],
             [4., 5., 6., 7.]]])
    >>> m(input)
    tensor([[[2., 1., 0., 1., 2., 3., 2., 1.],
             [6., 5., 4., 5., 6., 7., 6., 5.]]])
    >>> # using different paddings for different sides
    >>> m = nn.ReflectionPad1d((3, 1))
    >>> m(input)
    tensor([[[3., 2., 1., 0., 1., 2., 3., 2.],
             [7., 6., 5., 4., 5., 6., 7., 6.]]])
",170,200,1025,30
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\padding.py,ReflectionPad2d,"
Pads the input tensor using the reflection of the input boundary.

For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.

Args:
    padding (int, tuple): the size of the padding. If is `int`, uses the same
        padding in all boundaries. If a 4-`tuple`, uses (:math:`\text{padding\_left}`,
        :math:`\text{padding\_right}`, :math:`\text{padding\_top}`, :math:`\text{padding\_bottom}`)

Shape:
    - Input: :math:`(N, C, H_{in}, W_{in})`
    - Output: :math:`(N, C, H_{out}, W_{out})` where

      :math:`H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}`

      :math:`W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}`

Examples::

    >>> m = nn.ReflectionPad2d(2)
    >>> input = torch.arange(9, dtype=torch.float).reshape(1, 1, 3, 3)
    >>> input
    tensor([[[[0., 1., 2.],
              [3., 4., 5.],
              [6., 7., 8.]]]])
    >>> m(input)
    tensor([[[[8., 7., 6., 7., 8., 7., 6.],
              [5., 4., 3., 4., 5., 4., 3.],
              [2., 1., 0., 1., 2., 1., 0.],
              [5., 4., 3., 4., 5., 4., 3.],
              [8., 7., 6., 7., 8., 7., 6.],
              [5., 4., 3., 4., 5., 4., 3.],
              [2., 1., 0., 1., 2., 1., 0.]]]])
    >>> # using different paddings for different sides
    >>> m = nn.ReflectionPad2d((1, 1, 2, 0))
    >>> m(input)
    tensor([[[[7., 6., 7., 8., 7.],
              [4., 3., 4., 5., 4.],
              [1., 0., 1., 2., 1.],
              [4., 3., 4., 5., 4.],
              [7., 6., 7., 8., 7.]]]])
",209,250,1516,41
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\padding.py,_ReplicationPadNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\padding.py,ReplicationPad1d,"
Pads the input tensor using replication of the input boundary.

For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.

Args:
    padding (int, tuple): the size of the padding. If is `int`, uses the same
        padding in all boundaries. If a 2-`tuple`, uses
        (:math:`\text{padding\_left}`, :math:`\text{padding\_right}`)

Shape:
    - Input: :math:`(N, C, W_{in})`
    - Output: :math:`(N, C, W_{out})` where

      :math:`W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}`

Examples::

    >>> m = nn.ReplicationPad1d(2)
    >>> input = torch.arange(8, dtype=torch.float).reshape(1, 2, 4)
    >>> input
    tensor([[[0., 1., 2., 3.],
             [4., 5., 6., 7.]]])
    >>> m(input)
    tensor([[[0., 0., 0., 1., 2., 3., 3., 3.],
             [4., 4., 4., 5., 6., 7., 7., 7.]]])
    >>> # using different paddings for different sides
    >>> m = nn.ReplicationPad1d((3, 1))
    >>> m(input)
    tensor([[[0., 0., 0., 0., 1., 2., 3., 3.],
             [4., 4., 4., 4., 5., 6., 7., 7.]]])
",269,299,1024,30
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\padding.py,ReplicationPad2d,"
Pads the input tensor using replication of the input boundary.

For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.

Args:
    padding (int, tuple): the size of the padding. If is `int`, uses the same
        padding in all boundaries. If a 4-`tuple`, uses (:math:`\text{padding\_left}`,
        :math:`\text{padding\_right}`, :math:`\text{padding\_top}`, :math:`\text{padding\_bottom}`)

Shape:
    - Input: :math:`(N, C, H_{in}, W_{in})`
    - Output: :math:`(N, C, H_{out}, W_{out})` where

      :math:`H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}`

      :math:`W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}`

Examples::

    >>> m = nn.ReplicationPad2d(2)
    >>> input = torch.arange(9, dtype=torch.float).reshape(1, 1, 3, 3)
    >>> input
    tensor([[[[0., 1., 2.],
              [3., 4., 5.],
              [6., 7., 8.]]]])
    >>> m(input)
    tensor([[[[0., 0., 0., 1., 2., 2., 2.],
              [0., 0., 0., 1., 2., 2., 2.],
              [0., 0., 0., 1., 2., 2., 2.],
              [3., 3., 3., 4., 5., 5., 5.],
              [6., 6., 6., 7., 8., 8., 8.],
              [6., 6., 6., 7., 8., 8., 8.],
              [6., 6., 6., 7., 8., 8., 8.]]]])
    >>> # using different paddings for different sides
    >>> m = nn.ReplicationPad2d((1, 1, 2, 0))
    >>> m(input)
    tensor([[[[0., 0., 1., 2., 2.],
              [0., 0., 1., 2., 2.],
              [0., 0., 1., 2., 2.],
              [3., 3., 4., 5., 5.],
              [6., 6., 7., 8., 8.]]]])
",308,349,1515,41
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\padding.py,ReplicationPad3d,"
Pads the input tensor using replication of the input boundary.

For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.

Args:
    padding (int, tuple): the size of the padding. If is `int`, uses the same
        padding in all boundaries. If a 6-`tuple`, uses
        (:math:`\text{padding\_left}`, :math:`\text{padding\_right}`,
        :math:`\text{padding\_top}`, :math:`\text{padding\_bottom}`,
        :math:`\text{padding\_front}`, :math:`\text{padding\_back}`)

Shape:
    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})`
    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})` where

      :math:`D_{out} = D_{in} + \text{padding\_front} + \text{padding\_back}`

      :math:`H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}`

      :math:`W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}`

Examples::

    >>> m = nn.ReplicationPad3d(3)
    >>> input = torch.randn(16, 3, 8, 320, 480)
    >>> output = m(input)
    >>> # using different paddings for different sides
    >>> m = nn.ReplicationPad3d((3, 3, 6, 6, 1, 1))
    >>> output = m(input)
",358,387,1094,29
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\padding.py,ZeroPad2d,"
Pads the input tensor boundaries with zero.

For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.

Args:
    padding (int, tuple): the size of the padding. If is `int`, uses the same
        padding in all boundaries. If a 4-`tuple`, uses (:math:`\text{padding\_left}`,
        :math:`\text{padding\_right}`, :math:`\text{padding\_top}`, :math:`\text{padding\_bottom}`)

Shape:
    - Input: :math:`(N, C, H_{in}, W_{in})`
    - Output: :math:`(N, C, H_{out}, W_{out})` where

      :math:`H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}`

      :math:`W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}`

Examples::

    >>> m = nn.ZeroPad2d(2)
    >>> input = torch.randn(1, 1, 3, 3)
    >>> input
    tensor([[[[-0.1678, -0.4418,  1.9466],
              [ 0.9604, -0.4219, -0.5241],
              [-0.9162, -0.5436, -0.6446]]]])
    >>> m(input)
    tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
              [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
              [ 0.0000,  0.0000, -0.1678, -0.4418,  1.9466,  0.0000,  0.0000],
              [ 0.0000,  0.0000,  0.9604, -0.4219, -0.5241,  0.0000,  0.0000],
              [ 0.0000,  0.0000, -0.9162, -0.5436, -0.6446,  0.0000,  0.0000],
              [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
              [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])
    >>> # using different paddings for different sides
    >>> m = nn.ZeroPad2d((1, 1, 2, 0))
    >>> m(input)
    tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
              [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
              [ 0.0000, -0.1678, -0.4418,  1.9466,  0.0000],
              [ 0.0000,  0.9604, -0.4219, -0.5241,  0.0000],
              [ 0.0000, -0.9162, -0.5436, -0.6446,  0.0000]]]])
",396,437,1866,41
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pixelshuffle.py,PixelShuffle,"
Rearranges elements in a tensor of shape :math:`(*, C \times r^2, H, W)`
to a tensor of shape :math:`(*, C, H \times r, W \times r)`.

This is useful for implementing efficient sub-pixel convolution
with a stride of :math:`1/r`.

Look at the paper:
`Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network`_
by Shi et. al (2016) for more details.

Args:
    upscale_factor (int): factor to increase spatial resolution by

Shape:
    - Input: :math:`(N, L, H_{in}, W_{in})` where :math:`L=C \times \text{upscale\_factor}^2`
    - Output: :math:`(N, C, H_{out}, W_{out})` where
      :math:`H_{out} = H_{in} \times \text{upscale\_factor}`
      and :math:`W_{out} = W_{in} \times \text{upscale\_factor}`

Examples::

    >>> pixel_shuffle = nn.PixelShuffle(3)
    >>> input = torch.randn(1, 9, 4, 4)
    >>> output = pixel_shuffle(input)
    >>> print(output.size())
    torch.Size([1, 1, 12, 12])

.. _Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network:
    https://arxiv.org/abs/1609.05158
",6,35,1098,29
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,_MaxPoolNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,MaxPool1d,"
Applies a 1D max pooling over an input signal composed of several input
planes.

In the simplest case, the output value of the layer with input size :math:`(N, C, L)`
and output :math:`(N, C, L_{out})` can be precisely described as:

.. math::
    out(N_i, C_j, k) = \max_{m=0, \ldots, \text{kernel\_size} - 1}
            input(N_i, C_j, stride \times k + m)

If :attr:`padding` is non-zero, then the input is implicitly zero-padded on both sides
for :attr:`padding` number of points. :attr:`dilation` controls the spacing between the kernel points.
It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.

Args:
    kernel_size: the size of the window to take a max over
    stride: the stride of the window. Default value is :attr:`kernel_size`
    padding: implicit zero padding to be added on both sides
    dilation: a parameter that controls the stride of elements in the window
    return_indices: if ``True``, will return the max indices along with the outputs.
                    Useful for :class:`torch.nn.MaxUnpool1d` later
    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape

Shape:
    - Input: :math:`(N, C, L_{in})`
    - Output: :math:`(N, C, L_{out})`, where

      .. math::
          L_{out} = \left\lfloor \frac{L_{in} + 2 \times \text{padding} - \text{dilation}
                \times (\text{kernel\_size} - 1) - 1}{\text{stride}} + 1\right\rfloor

Examples::

    >>> # pool of size=3, stride=2
    >>> m = nn.MaxPool1d(3, stride=2)
    >>> input = torch.randn(20, 16, 50)
    >>> output = m(input)

.. _link:
    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
",31,71,1685,40
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,MaxPool2d,"
Applies a 2D max pooling over an input signal composed of several input
planes.

In the simplest case, the output value of the layer with input size :math:`(N, C, H, W)`,
output :math:`(N, C, H_{out}, W_{out})` and :attr:`kernel_size` :math:`(kH, kW)`
can be precisely described as:

.. math::
    \begin{aligned}
        out(N_i, C_j, h, w) ={} & \max_{m=0, \ldots, kH-1} \max_{n=0, \ldots, kW-1} \\
                                & \text{input}(N_i, C_j, \text{stride[0]} \times h + m,
                                               \text{stride[1]} \times w + n)
    \end{aligned}

If :attr:`padding` is non-zero, then the input is implicitly zero-padded on both sides
for :attr:`padding` number of points. :attr:`dilation` controls the spacing between the kernel points.
It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.

The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:

    - a single ``int`` -- in which case the same value is used for the height and width dimension
    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,
      and the second `int` for the width dimension

Args:
    kernel_size: the size of the window to take a max over
    stride: the stride of the window. Default value is :attr:`kernel_size`
    padding: implicit zero padding to be added on both sides
    dilation: a parameter that controls the stride of elements in the window
    return_indices: if ``True``, will return the max indices along with the outputs.
                    Useful for :class:`torch.nn.MaxUnpool2d` later
    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape

Shape:
    - Input: :math:`(N, C, H_{in}, W_{in})`
    - Output: :math:`(N, C, H_{out}, W_{out})`, where

      .. math::
          H_{out} = \left\lfloor\frac{H_{in} + 2 * \text{padding[0]} - \text{dilation[0]}
                \times (\text{kernel\_size[0]} - 1) - 1}{\text{stride[0]}} + 1\right\rfloor

      .. math::
          W_{out} = \left\lfloor\frac{W_{in} + 2 * \text{padding[1]} - \text{dilation[1]}
                \times (\text{kernel\_size[1]} - 1) - 1}{\text{stride[1]}} + 1\right\rfloor

Examples::

    >>> # pool of square window of size=3, stride=2
    >>> m = nn.MaxPool2d(3, stride=2)
    >>> # pool of non-square window
    >>> m = nn.MaxPool2d((3, 2), stride=(2, 1))
    >>> input = torch.randn(20, 16, 50, 32)
    >>> output = m(input)

.. _link:
    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
",80,136,2587,56
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,MaxPool3d,"
Applies a 3D max pooling over an input signal composed of several input
planes.

In the simplest case, the output value of the layer with input size :math:`(N, C, D, H, W)`,
output :math:`(N, C, D_{out}, H_{out}, W_{out})` and :attr:`kernel_size` :math:`(kD, kH, kW)`
can be precisely described as:

.. math::
    \begin{aligned}
        \text{out}(N_i, C_j, d, h, w) ={} & \max_{k=0, \ldots, kD-1} \max_{m=0, \ldots, kH-1} \max_{n=0, \ldots, kW-1} \\
                                          & \text{input}(N_i, C_j, \text{stride[0]} \times d + k,
                                                         \text{stride[1]} \times h + m, \text{stride[2]} \times w + n)
    \end{aligned}

If :attr:`padding` is non-zero, then the input is implicitly zero-padded on both sides
for :attr:`padding` number of points. :attr:`dilation` controls the spacing between the kernel points.
It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.

The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:

    - a single ``int`` -- in which case the same value is used for the depth, height and width dimension
    - a ``tuple`` of three ints -- in which case, the first `int` is used for the depth dimension,
      the second `int` for the height dimension and the third `int` for the width dimension

Args:
    kernel_size: the size of the window to take a max over
    stride: the stride of the window. Default value is :attr:`kernel_size`
    padding: implicit zero padding to be added on all three sides
    dilation: a parameter that controls the stride of elements in the window
    return_indices: if ``True``, will return the max indices along with the outputs.
                    Useful for :class:`torch.nn.MaxUnpool3d` later
    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape

Shape:
    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})`
    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})`, where

      .. math::
          D_{out} = \left\lfloor\frac{D_{in} + 2 \times \text{padding}[0] - \text{dilation}[0] \times
            (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor

      .. math::
          H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[1] - \text{dilation}[1] \times
            (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor

      .. math::
          W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[2] - \text{dilation}[2] \times
            (\text{kernel\_size}[2] - 1) - 1}{\text{stride}[2]} + 1\right\rfloor

Examples::

    >>> # pool of square window of size=3, stride=2
    >>> m = nn.MaxPool3d(3, stride=2)
    >>> # pool of non-square window
    >>> m = nn.MaxPool3d((3, 2, 2), stride=(2, 1, 2))
    >>> input = torch.randn(20, 16, 50,44, 31)
    >>> output = m(input)

.. _link:
    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
",145,205,2971,60
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,_MaxUnpoolNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,MaxUnpool1d,"
Computes a partial inverse of :class:`MaxPool1d`.

:class:`MaxPool1d` is not fully invertible, since the non-maximal values are lost.

:class:`MaxUnpool1d` takes in as input the output of :class:`MaxPool1d`
including the indices of the maximal values and computes a partial inverse
in which all non-maximal values are set to zero.

.. note:: :class:`MaxPool1d` can map several input sizes to the same output
          sizes. Hence, the inversion process can get ambiguous.
          To accommodate this, you can provide the needed output size
          as an additional argument :attr:`output_size` in the forward call.
          See the Inputs and Example below.

Args:
    kernel_size (int or tuple): Size of the max pooling window.
    stride (int or tuple): Stride of the max pooling window.
        It is set to :attr:`kernel_size` by default.
    padding (int or tuple): Padding that was added to the input

Inputs:
    - `input`: the input Tensor to invert
    - `indices`: the indices given out by :class:`~torch.nn.MaxPool1d`
    - `output_size` (optional): the targeted output size

Shape:
    - Input: :math:`(N, C, H_{in})`
    - Output: :math:`(N, C, H_{out})`, where

      .. math::
          H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{kernel\_size}[0]

      or as given by :attr:`output_size` in the call operator

Example::

    >>> pool = nn.MaxPool1d(2, stride=2, return_indices=True)
    >>> unpool = nn.MaxUnpool1d(2, stride=2)
    >>> input = torch.tensor([[[1., 2, 3, 4, 5, 6, 7, 8]]])
    >>> output, indices = pool(input)
    >>> unpool(output, indices)
    tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])

    >>> # Example showcasing the use of output_size
    >>> input = torch.tensor([[[1., 2, 3, 4, 5, 6, 7, 8, 9]]])
    >>> output, indices = pool(input)
    >>> unpool(output, indices, output_size=input.size())
    tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.,  0.]]])

    >>> unpool(output, indices)
    tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])
",222,273,2038,51
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,MaxUnpool2d,"
Computes a partial inverse of :class:`MaxPool2d`.

:class:`MaxPool2d` is not fully invertible, since the non-maximal values are lost.

:class:`MaxUnpool2d` takes in as input the output of :class:`MaxPool2d`
including the indices of the maximal values and computes a partial inverse
in which all non-maximal values are set to zero.

.. note:: :class:`MaxPool2d` can map several input sizes to the same output
          sizes. Hence, the inversion process can get ambiguous.
          To accommodate this, you can provide the needed output size
          as an additional argument :attr:`output_size` in the forward call.
          See the Inputs and Example below.

Args:
    kernel_size (int or tuple): Size of the max pooling window.
    stride (int or tuple): Stride of the max pooling window.
        It is set to :attr:`kernel_size` by default.
    padding (int or tuple): Padding that was added to the input

Inputs:
    - `input`: the input Tensor to invert
    - `indices`: the indices given out by :class:`~torch.nn.MaxPool2d`
    - `output_size` (optional): the targeted output size

Shape:
    - Input: :math:`(N, C, H_{in}, W_{in})`
    - Output: :math:`(N, C, H_{out}, W_{out})`, where

      .. math::
        H_{out} = (H_{in} - 1) \times \text{stride[0]} - 2 \times \text{padding[0]} + \text{kernel\_size[0]}

      .. math::
        W_{out} = (W_{in} - 1) \times \text{stride[1]} - 2 \times \text{padding[1]} + \text{kernel\_size[1]}

      or as given by :attr:`output_size` in the call operator

Example::

    >>> pool = nn.MaxPool2d(2, stride=2, return_indices=True)
    >>> unpool = nn.MaxUnpool2d(2, stride=2)
    >>> input = torch.tensor([[[[ 1.,  2,  3,  4],
                                [ 5,  6,  7,  8],
                                [ 9, 10, 11, 12],
                                [13, 14, 15, 16]]]])
    >>> output, indices = pool(input)
    >>> unpool(output, indices)
    tensor([[[[  0.,   0.,   0.,   0.],
              [  0.,   6.,   0.,   8.],
              [  0.,   0.,   0.,   0.],
              [  0.,  14.,   0.,  16.]]]])

    >>> # specify a different output size than input size
    >>> unpool(output, indices, output_size=torch.Size([1, 1, 5, 5]))
    tensor([[[[  0.,   0.,   0.,   0.,   0.],
              [  6.,   0.,   8.,   0.,   0.],
              [  0.,   0.,   0.,  14.,   0.],
              [ 16.,   0.,   0.,   0.,   0.],
              [  0.,   0.,   0.,   0.,   0.]]]])
",288,347,2430,59
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,MaxUnpool3d,"
Computes a partial inverse of :class:`MaxPool3d`.

:class:`MaxPool3d` is not fully invertible, since the non-maximal values are lost.
:class:`MaxUnpool3d` takes in as input the output of :class:`MaxPool3d`
including the indices of the maximal values and computes a partial inverse
in which all non-maximal values are set to zero.

.. note:: :class:`MaxPool3d` can map several input sizes to the same output
          sizes. Hence, the inversion process can get ambiguous.
          To accommodate this, you can provide the needed output size
          as an additional argument :attr:`output_size` in the forward call.
          See the Inputs section below.

Args:
    kernel_size (int or tuple): Size of the max pooling window.
    stride (int or tuple): Stride of the max pooling window.
        It is set to :attr:`kernel_size` by default.
    padding (int or tuple): Padding that was added to the input

Inputs:
    - `input`: the input Tensor to invert
    - `indices`: the indices given out by :class:`~torch.nn.MaxPool3d`
    - `output_size` (optional): the targeted output size

Shape:
    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})`
    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})`, where

      .. math::
          D_{out} = (D_{in} - 1) \times \text{stride[0]} - 2 \times \text{padding[0]} + \text{kernel\_size[0]}

      .. math::
          H_{out} = (H_{in} - 1) \times \text{stride[1]} - 2 \times \text{padding[1]} + \text{kernel\_size[1]}

      .. math::
          W_{out} = (W_{in} - 1) \times \text{stride[2]} - 2 \times \text{padding[2]} + \text{kernel\_size[2]}

      or as given by :attr:`output_size` in the call operator

Example::

    >>> # pool of square window of size=3, stride=2
    >>> pool = nn.MaxPool3d(3, stride=2, return_indices=True)
    >>> unpool = nn.MaxUnpool3d(3, stride=2)
    >>> output, indices = pool(torch.randn(20, 16, 51, 33, 15))
    >>> unpooled_output = unpool(output, indices)
    >>> unpooled_output.size()
    torch.Size([20, 16, 51, 33, 15])
",362,410,2009,48
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,_AvgPoolNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,AvgPool1d,"
Applies a 1D average pooling over an input signal composed of several
input planes.

In the simplest case, the output value of the layer with input size :math:`(N, C, L)`,
output :math:`(N, C, L_{out})` and :attr:`kernel_size` :math:`k`
can be precisely described as:

.. math::

    \text{out}(N_i, C_j, l) = \frac{1}{k} \sum_{m=0}^{k-1}
                           \text{input}(N_i, C_j, \text{stride} \times l + m)

If :attr:`padding` is non-zero, then the input is implicitly zero-padded on both sides
for :attr:`padding` number of points.

The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding` can each be
an ``int`` or a one-element tuple.

Args:
    kernel_size: the size of the window
    stride: the stride of the window. Default value is :attr:`kernel_size`
    padding: implicit zero padding to be added on both sides
    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape
    count_include_pad: when True, will include the zero-padding in the averaging calculation

Shape:
    - Input: :math:`(N, C, L_{in})`
    - Output: :math:`(N, C, L_{out})`, where

      .. math::
          L_{out} = \left\lfloor \frac{L_{in} +
          2 \times \text{padding} - \text{kernel\_size}}{\text{stride}} + 1\right\rfloor

Examples::

    >>> # pool with window of size=3, stride=2
    >>> m = nn.AvgPool1d(3, stride=2)
    >>> m(torch.tensor([[[1.,2,3,4,5,6,7]]]))
    tensor([[[ 2.,  4.,  6.]]])
",434,473,1442,39
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,AvgPool2d,"
Applies a 2D average pooling over an input signal composed of several input
planes.

In the simplest case, the output value of the layer with input size :math:`(N, C, H, W)`,
output :math:`(N, C, H_{out}, W_{out})` and :attr:`kernel_size` :math:`(kH, kW)`
can be precisely described as:

.. math::

    out(N_i, C_j, h, w)  = \frac{1}{kH * kW} \sum_{m=0}^{kH-1} \sum_{n=0}^{kW-1}
                           input(N_i, C_j, stride[0] \times h + m, stride[1] \times w + n)

If :attr:`padding` is non-zero, then the input is implicitly zero-padded on both sides
for :attr:`padding` number of points.

The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding` can either be:

    - a single ``int`` -- in which case the same value is used for the height and width dimension
    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,
      and the second `int` for the width dimension

Args:
    kernel_size: the size of the window
    stride: the stride of the window. Default value is :attr:`kernel_size`
    padding: implicit zero padding to be added on both sides
    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape
    count_include_pad: when True, will include the zero-padding in the averaging calculation
    divisor_override: if specified, it will be used as divisor, otherwise attr:`kernel_size` will be used

Shape:
    - Input: :math:`(N, C, H_{in}, W_{in})`
    - Output: :math:`(N, C, H_{out}, W_{out})`, where

      .. math::
          H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] -
            \text{kernel\_size}[0]}{\text{stride}[0]} + 1\right\rfloor

      .. math::
          W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] -
            \text{kernel\_size}[1]}{\text{stride}[1]} + 1\right\rfloor

Examples::

    >>> # pool of square window of size=3, stride=2
    >>> m = nn.AvgPool2d(3, stride=2)
    >>> # pool of non-square window
    >>> m = nn.AvgPool2d((3, 2), stride=(2, 1))
    >>> input = torch.randn(20, 16, 50, 32)
    >>> output = m(input)
",490,539,2092,49
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,AvgPool3d,"
Applies a 3D average pooling over an input signal composed of several input
planes.

In the simplest case, the output value of the layer with input size :math:`(N, C, D, H, W)`,
output :math:`(N, C, D_{out}, H_{out}, W_{out})` and :attr:`kernel_size` :math:`(kD, kH, kW)`
can be precisely described as:

.. math::
    \begin{aligned}
        \text{out}(N_i, C_j, d, h, w) ={} & \sum_{k=0}^{kD-1} \sum_{m=0}^{kH-1} \sum_{n=0}^{kW-1} \\
                                          & \frac{\text{input}(N_i, C_j, \text{stride}[0] \times d + k,
                                                  \text{stride}[1] \times h + m, \text{stride}[2] \times w + n)}
                                                 {kD \times kH \times kW}
    \end{aligned}

If :attr:`padding` is non-zero, then the input is implicitly zero-padded on all three sides
for :attr:`padding` number of points.

The parameters :attr:`kernel_size`, :attr:`stride` can either be:

    - a single ``int`` -- in which case the same value is used for the depth, height and width dimension
    - a ``tuple`` of three ints -- in which case, the first `int` is used for the depth dimension,
      the second `int` for the height dimension and the third `int` for the width dimension

Args:
    kernel_size: the size of the window
    stride: the stride of the window. Default value is :attr:`kernel_size`
    padding: implicit zero padding to be added on all three sides
    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape
    count_include_pad: when True, will include the zero-padding in the averaging calculation
    divisor_override: if specified, it will be used as divisor, otherwise attr:`kernel_size` will be used

Shape:
    - Input: :math:`(N, C, D_{in}, H_{in}, W_{in})`
    - Output: :math:`(N, C, D_{out}, H_{out}, W_{out})`, where

      .. math::
          D_{out} = \left\lfloor\frac{D_{in} + 2 \times \text{padding}[0] -
                \text{kernel\_size}[0]}{\text{stride}[0]} + 1\right\rfloor

      .. math::
          H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[1] -
                \text{kernel\_size}[1]}{\text{stride}[1]} + 1\right\rfloor

      .. math::
          W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[2] -
                \text{kernel\_size}[2]}{\text{stride}[2]} + 1\right\rfloor

Examples::

    >>> # pool of square window of size=3, stride=2
    >>> m = nn.AvgPool3d(3, stride=2)
    >>> # pool of non-square window
    >>> m = nn.AvgPool3d((3, 2, 2), stride=(2, 1, 2))
    >>> input = torch.randn(20, 16, 50,44, 31)
    >>> output = m(input)
",558,614,2607,56
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,FractionalMaxPool2d,"
Applies a 2D fractional max pooling over an input signal composed of several input planes.

Fractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham

The max-pooling operation is applied in :math:`kH \times kW` regions by a stochastic
step size determined by the target output size.
The number of output features is equal to the number of input planes.

Args:
    kernel_size: the size of the window to take a max over.
                 Can be a single number k (for a square kernel of k x k) or a tuple `(kh, kw)`
    output_size: the target output size of the image of the form `oH x oW`.
                 Can be a tuple `(oH, oW)` or a single number oH for a square image `oH x oH`
    output_ratio: If one wants to have an output size as a ratio of the input size, this option can be given.
                  This has to be a number or tuple in the range (0, 1)
    return_indices: if ``True``, will return the indices along with the outputs.
                    Useful to pass to :meth:`nn.MaxUnpool2d`. Default: ``False``

Examples:
    >>> # pool of square window of size=3, and target output size 13x12
    >>> m = nn.FractionalMaxPool2d(3, output_size=(13, 12))
    >>> # pool of square window and target output size being half of input image size
    >>> m = nn.FractionalMaxPool2d(3, output_ratio=(0.5, 0.5))
    >>> input = torch.randn(20, 16, 50, 32)
    >>> output = m(input)

.. _Fractional MaxPooling:
    http://arxiv.org/abs/1412.6071
",639,667,1492,28
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,FractionalMaxPool3d,"
Applies a 3D fractional max pooling over an input signal composed of several input planes.

Fractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham

The max-pooling operation is applied in :math:`kTxkHxkW` regions by a stochastic
step size determined by the target output size.
The number of output features is equal to the number of input planes.

Args:
    kernel_size: the size of the window to take a max over.
                 Can be a single number k (for a square kernel of k x k x k) or a tuple `(kt x kh x kw)`
    output_size: the target output size of the image of the form `oT x oH x oW`.
                 Can be a tuple `(oT, oH, oW)` or a single number oH for a square image `oH x oH x oH`
    output_ratio: If one wants to have an output size as a ratio of the input size, this option can be given.
                  This has to be a number or tuple in the range (0, 1)
    return_indices: if ``True``, will return the indices along with the outputs.
                    Useful to pass to :meth:`nn.MaxUnpool3d`. Default: ``False``

Examples:
    >>> # pool of cubic window of size=3, and target output size 13x12x11
    >>> m = nn.FractionalMaxPool3d(3, output_size=(13, 12, 11))
    >>> # pool of cubic window and target output size being half of input size
    >>> m = nn.FractionalMaxPool3d(3, output_ratio=(0.5, 0.5, 0.5))
    >>> input = torch.randn(20, 16, 50, 32, 16)
    >>> output = m(input)

.. _Fractional MaxPooling:
    http://arxiv.org/abs/1412.6071
",697,725,1520,28
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,_LPPoolNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,LPPool1d,"
Applies a 1D power-average pooling over an input signal composed of several input
planes.

On each window, the function computed is:

.. math::
    f(X) = \sqrt[p]{\sum_{x \in X} x^{p}}

- At p = :math:`\infty`, one gets Max Pooling
- At p = 1, one gets Sum Pooling (which is proportional to Average Pooling)

.. note:: If the sum to the power of `p` is zero, the gradient of this function is
          not defined. This implementation will set the gradient to zero in this case.

Args:
    kernel_size: a single int, the size of the window
    stride: a single int, the stride of the window. Default value is :attr:`kernel_size`
    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape

Shape:
    - Input: :math:`(N, C, L_{in})`
    - Output: :math:`(N, C, L_{out})`, where

      .. math::
          L_{out} = \left\lfloor\frac{L_{in} +
          2 \times \text{padding} - \text{kernel\_size}}{\text{stride}} + 1\right\rfloor

Examples::
    >>> # power-2 pool of window of length 3, with stride 2.
    >>> m = nn.LPPool1d(2, 3, stride=2)
    >>> input = torch.randn(20, 16, 50)
    >>> output = m(input)
",770,802,1139,32
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,LPPool2d,"
Applies a 2D power-average pooling over an input signal composed of several input
planes.

On each window, the function computed is:

.. math::
    f(X) = \sqrt[p]{\sum_{x \in X} x^{p}}

- At p = :math:`\infty`, one gets Max Pooling
- At p = 1, one gets Sum Pooling (which is proportional to average pooling)

The parameters :attr:`kernel_size`, :attr:`stride` can either be:

    - a single ``int`` -- in which case the same value is used for the height and width dimension
    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,
      and the second `int` for the width dimension

.. note:: If the sum to the power of `p` is zero, the gradient of this function is
          not defined. This implementation will set the gradient to zero in this case.

Args:
    kernel_size: the size of the window
    stride: the stride of the window. Default value is :attr:`kernel_size`
    ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape

Shape:
    - Input: :math:`(N, C, H_{in}, W_{in})`
    - Output: :math:`(N, C, H_{out}, W_{out})`, where

      .. math::
          H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] - \text{dilation}[0] \times
                (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor

      .. math::
          W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] - \text{dilation}[1] \times
                (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor

Examples::

    >>> # power-2 pool of square window of size=3, stride=2
    >>> m = nn.LPPool2d(2, 3, stride=2)
    >>> # pool of non-square window of power 1.2
    >>> m = nn.LPPool2d(1.2, (3, 2), stride=(2, 1))
    >>> input = torch.randn(20, 16, 50, 32)
    >>> output = m(input)
",810,855,1805,45
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,_AdaptiveMaxPoolNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,AdaptiveMaxPool1d,"
Applies a 1D adaptive max pooling over an input signal composed of several input planes.

The output size is H, for any input size.
The number of output features is equal to the number of input planes.

Args:
    output_size: the target output size H
    return_indices: if ``True``, will return the indices along with the outputs.
                    Useful to pass to nn.MaxUnpool1d. Default: ``False``

Examples:
    >>> # target output size of 5
    >>> m = nn.AdaptiveMaxPool1d(5)
    >>> input = torch.randn(1, 64, 8)
    >>> output = m(input)
",879,894,549,15
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,AdaptiveMaxPool2d,"
Applies a 2D adaptive max pooling over an input signal composed of several input planes.

The output is of size H x W, for any input size.
The number of output features is equal to the number of input planes.

Args:
    output_size: the target output size of the image of the form H x W.
                 Can be a tuple (H, W) or a single H for a square image H x H.
                 H and W can be either a ``int``, or ``None`` which means the size will
                 be the same as that of the input.
    return_indices: if ``True``, will return the indices along with the outputs.
                    Useful to pass to nn.MaxUnpool2d. Default: ``False``

Examples:
    >>> # target output size of 5x7
    >>> m = nn.AdaptiveMaxPool2d((5,7))
    >>> input = torch.randn(1, 64, 8, 9)
    >>> output = m(input)
    >>> # target output size of 7x7 (square)
    >>> m = nn.AdaptiveMaxPool2d(7)
    >>> input = torch.randn(1, 64, 10, 9)
    >>> output = m(input)
    >>> # target output size of 10x7
    >>> m = nn.AdaptiveMaxPool2d((None, 7))
    >>> input = torch.randn(1, 64, 10, 9)
    >>> output = m(input)
",902,928,1111,26
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,AdaptiveMaxPool3d,"
Applies a 3D adaptive max pooling over an input signal composed of several input planes.

The output is of size D x H x W, for any input size.
The number of output features is equal to the number of input planes.

Args:
    output_size: the target output size of the image of the form D x H x W.
                 Can be a tuple (D, H, W) or a single D for a cube D x D x D.
                 D, H and W can be either a ``int``, or ``None`` which means the size will
                 be the same as that of the input.

    return_indices: if ``True``, will return the indices along with the outputs.
                    Useful to pass to nn.MaxUnpool3d. Default: ``False``

Examples:
    >>> # target output size of 5x7x9
    >>> m = nn.AdaptiveMaxPool3d((5,7,9))
    >>> input = torch.randn(1, 64, 8, 9, 10)
    >>> output = m(input)
    >>> # target output size of 7x7x7 (cube)
    >>> m = nn.AdaptiveMaxPool3d(7)
    >>> input = torch.randn(1, 64, 10, 9, 8)
    >>> output = m(input)
    >>> # target output size of 7x9x8
    >>> m = nn.AdaptiveMaxPool3d((7, None, None))
    >>> input = torch.randn(1, 64, 10, 9, 8)
    >>> output = m(input)
",936,963,1143,27
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,_AdaptiveAvgPoolNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,AdaptiveAvgPool1d,"
Applies a 1D adaptive average pooling over an input signal composed of several input planes.

The output size is H, for any input size.
The number of output features is equal to the number of input planes.

Args:
    output_size: the target output size H

Examples:
    >>> # target output size of 5
    >>> m = nn.AdaptiveAvgPool1d(5)
    >>> input = torch.randn(1, 64, 8)
    >>> output = m(input)
",982,995,399,13
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,AdaptiveAvgPool2d,"
Applies a 2D adaptive average pooling over an input signal composed of several input planes.

The output is of size H x W, for any input size.
The number of output features is equal to the number of input planes.

Args:
    output_size: the target output size of the image of the form H x W.
                 Can be a tuple (H, W) or a single H for a square image H x H.
                 H and W can be either a ``int``, or ``None`` which means the size will
                 be the same as that of the input.

Examples:
    >>> # target output size of 5x7
    >>> m = nn.AdaptiveAvgPool2d((5,7))
    >>> input = torch.randn(1, 64, 8, 9)
    >>> output = m(input)
    >>> # target output size of 7x7 (square)
    >>> m = nn.AdaptiveAvgPool2d(7)
    >>> input = torch.randn(1, 64, 10, 9)
    >>> output = m(input)
    >>> # target output size of 10x7
    >>> m = nn.AdaptiveMaxPool2d((None, 7))
    >>> input = torch.randn(1, 64, 10, 9)
    >>> output = m(input)
",1003,1027,961,24
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\pooling.py,AdaptiveAvgPool3d,"
Applies a 3D adaptive average pooling over an input signal composed of several input planes.

The output is of size D x H x W, for any input size.
The number of output features is equal to the number of input planes.

Args:
    output_size: the target output size of the form D x H x W.
                 Can be a tuple (D, H, W) or a single number D for a cube D x D x D.
                 D, H and W can be either a ``int``, or ``None`` which means the size will
                 be the same as that of the input.

Examples:
    >>> # target output size of 5x7x9
    >>> m = nn.AdaptiveAvgPool3d((5,7,9))
    >>> input = torch.randn(1, 64, 8, 9, 10)
    >>> output = m(input)
    >>> # target output size of 7x7x7 (cube)
    >>> m = nn.AdaptiveAvgPool3d(7)
    >>> input = torch.randn(1, 64, 10, 9, 8)
    >>> output = m(input)
    >>> # target output size of 7x9x8
    >>> m = nn.AdaptiveMaxPool3d((7, None, None))
    >>> input = torch.randn(1, 64, 10, 9, 8)
    >>> output = m(input)
",1035,1059,986,24
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\rnn.py,RNNBase,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\rnn.py,RNN,"
Applies a multi-layer Elman RNN with :math:`tanh` or :math:`ReLU` non-linearity to an
input sequence.


For each element in the input sequence, each layer computes the following
function:

.. math::
    h_t = \text{tanh}(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})

where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is
the input at time `t`, and :math:`h_{(t-1)}` is the hidden state of the
previous layer at time `t-1` or the initial hidden state at time `0`.
If :attr:`nonlinearity` is ``'relu'``, then `ReLU` is used instead of `tanh`.

Args:
    input_size: The number of expected features in the input `x`
    hidden_size: The number of features in the hidden state `h`
    num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``
        would mean stacking two RNNs together to form a `stacked RNN`,
        with the second RNN taking in outputs of the first RNN and
        computing the final results. Default: 1
    nonlinearity: The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``
    bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.
        Default: ``True``
    batch_first: If ``True``, then the input and output tensors are provided
        as `(batch, seq, feature)`. Default: ``False``
    dropout: If non-zero, introduces a `Dropout` layer on the outputs of each
        RNN layer except the last layer, with dropout probability equal to
        :attr:`dropout`. Default: 0
    bidirectional: If ``True``, becomes a bidirectional RNN. Default: ``False``

Inputs: input, h_0
    - **input** of shape `(seq_len, batch, input_size)`: tensor containing the features
      of the input sequence. The input can also be a packed variable length
      sequence. See :func:`torch.nn.utils.rnn.pack_padded_sequence`
      or :func:`torch.nn.utils.rnn.pack_sequence`
      for details.
    - **h_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor
      containing the initial hidden state for each element in the batch.
      Defaults to zero if not provided. If the RNN is bidirectional,
      num_directions should be 2, else it should be 1.

Outputs: output, h_n
    - **output** of shape `(seq_len, batch, num_directions * hidden_size)`: tensor
      containing the output features (`h_t`) from the last layer of the RNN,
      for each `t`.  If a :class:`torch.nn.utils.rnn.PackedSequence` has
      been given as the input, the output will also be a packed sequence.

      For the unpacked case, the directions can be separated
      using ``output.view(seq_len, batch, num_directions, hidden_size)``,
      with forward and backward being direction `0` and `1` respectively.
      Similarly, the directions can be separated in the packed case.
    - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor
      containing the hidden state for `t = seq_len`.

      Like *output*, the layers can be separated using
      ``h_n.view(num_layers, num_directions, batch, hidden_size)``.

Shape:
    - Input1: :math:`(L, N, H_{in})` tensor containing input features where
      :math:`H_{in}=\text{input\_size}` and `L` represents a sequence length.
    - Input2: :math:`(S, N, H_{out})` tensor
      containing the initial hidden state for each element in the batch.
      :math:`H_{out}=\text{hidden\_size}`
      Defaults to zero if not provided. where :math:`S=\text{num\_layers} * \text{num\_directions}`
      If the RNN is bidirectional, num_directions should be 2, else it should be 1.
    - Output1: :math:`(L, N, H_{all})` where :math:`H_{all}=\text{num\_directions} * \text{hidden\_size}`
    - Output2: :math:`(S, N, H_{out})` tensor containing the next hidden state
      for each element in the batch

Attributes:
    weight_ih_l[k]: the learnable input-hidden weights of the k-th layer,
        of shape `(hidden_size, input_size)` for `k = 0`. Otherwise, the shape is
        `(hidden_size, num_directions * hidden_size)`
    weight_hh_l[k]: the learnable hidden-hidden weights of the k-th layer,
        of shape `(hidden_size, hidden_size)`
    bias_ih_l[k]: the learnable input-hidden bias of the k-th layer,
        of shape `(hidden_size)`
    bias_hh_l[k]: the learnable hidden-hidden bias of the k-th layer,
        of shape `(hidden_size)`

.. note::
    All the weights and biases are initialized from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`
    where :math:`k = \frac{1}{\text{hidden\_size}}`

.. include:: cudnn_persistent_rnn.rst

Examples::

    >>> rnn = nn.RNN(10, 20, 2)
    >>> input = torch.randn(5, 3, 10)
    >>> h0 = torch.randn(2, 3, 20)
    >>> output, hn = rnn(input, h0)
",280,374,4662,94
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\rnn.py,LSTM,"
Applies a multi-layer long short-term memory (LSTM) RNN to an input
sequence.


For each element in the input sequence, each layer computes the following
function:

.. math::
    \begin{array}{ll} \\
        i_t = \sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\
        f_t = \sigma(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\
        g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\
        o_t = \sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\
        c_t = f_t * c_{(t-1)} + i_t * g_t \\
        h_t = o_t * \tanh(c_t) \\
    \end{array}

where :math:`h_t` is the hidden state at time `t`, :math:`c_t` is the cell
state at time `t`, :math:`x_t` is the input at time `t`, :math:`h_{(t-1)}`
is the hidden state of the layer at time `t-1` or the initial hidden
state at time `0`, and :math:`i_t`, :math:`f_t`, :math:`g_t`,
:math:`o_t` are the input, forget, cell, and output gates, respectively.
:math:`\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.

In a multilayer LSTM, the input :math:`x^{(l)}_t` of the :math:`l` -th layer
(:math:`l >= 2`) is the hidden state :math:`h^{(l-1)}_t` of the previous layer multiplied by
dropout :math:`\delta^{(l-1)}_t` where each :math:`\delta^{(l-1)}_t` is a Bernoulli random
variable which is :math:`0` with probability :attr:`dropout`.

Args:
    input_size: The number of expected features in the input `x`
    hidden_size: The number of features in the hidden state `h`
    num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``
        would mean stacking two LSTMs together to form a `stacked LSTM`,
        with the second LSTM taking in outputs of the first LSTM and
        computing the final results. Default: 1
    bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.
        Default: ``True``
    batch_first: If ``True``, then the input and output tensors are provided
        as (batch, seq, feature). Default: ``False``
    dropout: If non-zero, introduces a `Dropout` layer on the outputs of each
        LSTM layer except the last layer, with dropout probability equal to
        :attr:`dropout`. Default: 0
    bidirectional: If ``True``, becomes a bidirectional LSTM. Default: ``False``

Inputs: input, (h_0, c_0)
    - **input** of shape `(seq_len, batch, input_size)`: tensor containing the features
      of the input sequence.
      The input can also be a packed variable length sequence.
      See :func:`torch.nn.utils.rnn.pack_padded_sequence` or
      :func:`torch.nn.utils.rnn.pack_sequence` for details.
    - **h_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor
      containing the initial hidden state for each element in the batch.
      If the LSTM is bidirectional, num_directions should be 2, else it should be 1.
    - **c_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor
      containing the initial cell state for each element in the batch.

      If `(h_0, c_0)` is not provided, both **h_0** and **c_0** default to zero.


Outputs: output, (h_n, c_n)
    - **output** of shape `(seq_len, batch, num_directions * hidden_size)`: tensor
      containing the output features `(h_t)` from the last layer of the LSTM,
      for each `t`. If a :class:`torch.nn.utils.rnn.PackedSequence` has been
      given as the input, the output will also be a packed sequence.

      For the unpacked case, the directions can be separated
      using ``output.view(seq_len, batch, num_directions, hidden_size)``,
      with forward and backward being direction `0` and `1` respectively.
      Similarly, the directions can be separated in the packed case.
    - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor
      containing the hidden state for `t = seq_len`.

      Like *output*, the layers can be separated using
      ``h_n.view(num_layers, num_directions, batch, hidden_size)`` and similarly for *c_n*.
    - **c_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor
      containing the cell state for `t = seq_len`.

Attributes:
    weight_ih_l[k] : the learnable input-hidden weights of the :math:`\text{k}^{th}` layer
        `(W_ii|W_if|W_ig|W_io)`, of shape `(4*hidden_size, input_size)` for `k = 0`.
        Otherwise, the shape is `(4*hidden_size, num_directions * hidden_size)`
    weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\text{k}^{th}` layer
        `(W_hi|W_hf|W_hg|W_ho)`, of shape `(4*hidden_size, hidden_size)`
    bias_ih_l[k] : the learnable input-hidden bias of the :math:`\text{k}^{th}` layer
        `(b_ii|b_if|b_ig|b_io)`, of shape `(4*hidden_size)`
    bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\text{k}^{th}` layer
        `(b_hi|b_hf|b_hg|b_ho)`, of shape `(4*hidden_size)`

.. note::
    All the weights and biases are initialized from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`
    where :math:`k = \frac{1}{\text{hidden\_size}}`

.. include:: cudnn_persistent_rnn.rst

Examples::

    >>> rnn = nn.LSTM(10, 20, 2)
    >>> input = torch.randn(5, 3, 10)
    >>> h0 = torch.randn(2, 3, 20)
    >>> c0 = torch.randn(2, 3, 20)
    >>> output, (hn, cn) = rnn(input, (h0, c0))
",400,502,5218,102
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\rnn.py,GRU,"
Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.


For each element in the input sequence, each layer computes the following
function:

.. math::
    \begin{array}{ll}
        r_t = \sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\
        z_t = \sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\
        n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\
        h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}
    \end{array}

where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is the input
at time `t`, :math:`h_{(t-1)}` is the hidden state of the layer
at time `t-1` or the initial hidden state at time `0`, and :math:`r_t`,
:math:`z_t`, :math:`n_t` are the reset, update, and new gates, respectively.
:math:`\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.

In a multilayer GRU, the input :math:`x^{(l)}_t` of the :math:`l` -th layer
(:math:`l >= 2`) is the hidden state :math:`h^{(l-1)}_t` of the previous layer multiplied by
dropout :math:`\delta^{(l-1)}_t` where each :math:`\delta^{(l-1)}_t` is a Bernoulli random
variable which is :math:`0` with probability :attr:`dropout`.

Args:
    input_size: The number of expected features in the input `x`
    hidden_size: The number of features in the hidden state `h`
    num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``
        would mean stacking two GRUs together to form a `stacked GRU`,
        with the second GRU taking in outputs of the first GRU and
        computing the final results. Default: 1
    bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.
        Default: ``True``
    batch_first: If ``True``, then the input and output tensors are provided
        as (batch, seq, feature). Default: ``False``
    dropout: If non-zero, introduces a `Dropout` layer on the outputs of each
        GRU layer except the last layer, with dropout probability equal to
        :attr:`dropout`. Default: 0
    bidirectional: If ``True``, becomes a bidirectional GRU. Default: ``False``

Inputs: input, h_0
    - **input** of shape `(seq_len, batch, input_size)`: tensor containing the features
      of the input sequence. The input can also be a packed variable length
      sequence. See :func:`torch.nn.utils.rnn.pack_padded_sequence`
      for details.
    - **h_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor
      containing the initial hidden state for each element in the batch.
      Defaults to zero if not provided. If the RNN is bidirectional,
      num_directions should be 2, else it should be 1.

Outputs: output, h_n
    - **output** of shape `(seq_len, batch, num_directions * hidden_size)`: tensor
      containing the output features h_t from the last layer of the GRU,
      for each `t`. If a :class:`torch.nn.utils.rnn.PackedSequence` has been
      given as the input, the output will also be a packed sequence.
      For the unpacked case, the directions can be separated
      using ``output.view(seq_len, batch, num_directions, hidden_size)``,
      with forward and backward being direction `0` and `1` respectively.

      Similarly, the directions can be separated in the packed case.
    - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor
      containing the hidden state for `t = seq_len`

      Like *output*, the layers can be separated using
      ``h_n.view(num_layers, num_directions, batch, hidden_size)``.

Shape:
    - Input1: :math:`(L, N, H_{in})` tensor containing input features where
      :math:`H_{in}=\text{input\_size}` and `L` represents a sequence length.
    - Input2: :math:`(S, N, H_{out})` tensor
      containing the initial hidden state for each element in the batch.
      :math:`H_{out}=\text{hidden\_size}`
      Defaults to zero if not provided. where :math:`S=\text{num\_layers} * \text{num\_directions}`
      If the RNN is bidirectional, num_directions should be 2, else it should be 1.
    - Output1: :math:`(L, N, H_{all})` where :math:`H_{all}=\text{num\_directions} * \text{hidden\_size}`
    - Output2: :math:`(S, N, H_{out})` tensor containing the next hidden state
      for each element in the batch

Attributes:
    weight_ih_l[k] : the learnable input-hidden weights of the :math:`\text{k}^{th}` layer
        (W_ir|W_iz|W_in), of shape `(3*hidden_size, input_size)` for `k = 0`.
        Otherwise, the shape is `(3*hidden_size, num_directions * hidden_size)`
    weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\text{k}^{th}` layer
        (W_hr|W_hz|W_hn), of shape `(3*hidden_size, hidden_size)`
    bias_ih_l[k] : the learnable input-hidden bias of the :math:`\text{k}^{th}` layer
        (b_ir|b_iz|b_in), of shape `(3*hidden_size)`
    bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\text{k}^{th}` layer
        (b_hr|b_hz|b_hn), of shape `(3*hidden_size)`

.. note::
    All the weights and biases are initialized from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`
    where :math:`k = \frac{1}{\text{hidden\_size}}`

.. include:: cudnn_persistent_rnn.rst

Examples::

    >>> rnn = nn.GRU(10, 20, 2)
    >>> input = torch.randn(5, 3, 10)
    >>> h0 = torch.randn(2, 3, 20)
    >>> output, hn = rnn(input, h0)
",574,676,5268,102
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\rnn.py,RNNCellBase,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\rnn.py,RNNCell,"
An Elman RNN cell with tanh or ReLU non-linearity.

.. math::

    h' = \tanh(W_{ih} x + b_{ih}  +  W_{hh} h + b_{hh})

If :attr:`nonlinearity` is `'relu'`, then ReLU is used in place of tanh.

Args:
    input_size: The number of expected features in the input `x`
    hidden_size: The number of features in the hidden state `h`
    bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.
        Default: ``True``
    nonlinearity: The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``

Inputs: input, hidden
    - **input** of shape `(batch, input_size)`: tensor containing input features
    - **hidden** of shape `(batch, hidden_size)`: tensor containing the initial hidden
      state for each element in the batch.
      Defaults to zero if not provided.

Outputs: h'
    - **h'** of shape `(batch, hidden_size)`: tensor containing the next hidden state
      for each element in the batch

Shape:
    - Input1: :math:`(N, H_{in})` tensor containing input features where
      :math:`H_{in}` = `input_size`
    - Input2: :math:`(N, H_{out})` tensor containing the initial hidden
      state for each element in the batch where :math:`H_{out}` = `hidden_size`
      Defaults to zero if not provided.
    - Output: :math:`(N, H_{out})` tensor containing the next hidden state
      for each element in the batch

Attributes:
    weight_ih: the learnable input-hidden weights, of shape
        `(hidden_size, input_size)`
    weight_hh: the learnable hidden-hidden weights, of shape
        `(hidden_size, hidden_size)`
    bias_ih: the learnable input-hidden bias, of shape `(hidden_size)`
    bias_hh: the learnable hidden-hidden bias, of shape `(hidden_size)`

.. note::
    All the weights and biases are initialized from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`
    where :math:`k = \frac{1}{\text{hidden\_size}}`

Examples::

    >>> rnn = nn.RNNCell(10, 20)
    >>> input = torch.randn(6, 3, 10)
    >>> hx = torch.randn(3, 20)
    >>> output = []
    >>> for i in range(6):
            hx = rnn(input[i], hx)
            output.append(hx)
",782,837,2105,55
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\rnn.py,LSTMCell,"
A long short-term memory (LSTM) cell.

.. math::

    \begin{array}{ll}
    i = \sigma(W_{ii} x + b_{ii} + W_{hi} h + b_{hi}) \\
    f = \sigma(W_{if} x + b_{if} + W_{hf} h + b_{hf}) \\
    g = \tanh(W_{ig} x + b_{ig} + W_{hg} h + b_{hg}) \\
    o = \sigma(W_{io} x + b_{io} + W_{ho} h + b_{ho}) \\
    c' = f * c + i * g \\
    h' = o * \tanh(c') \\
    \end{array}

where :math:`\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.

Args:
    input_size: The number of expected features in the input `x`
    hidden_size: The number of features in the hidden state `h`
    bias: If ``False``, then the layer does not use bias weights `b_ih` and
        `b_hh`. Default: ``True``

Inputs: input, (h_0, c_0)
    - **input** of shape `(batch, input_size)`: tensor containing input features
    - **h_0** of shape `(batch, hidden_size)`: tensor containing the initial hidden
      state for each element in the batch.
    - **c_0** of shape `(batch, hidden_size)`: tensor containing the initial cell state
      for each element in the batch.

      If `(h_0, c_0)` is not provided, both **h_0** and **c_0** default to zero.

Outputs: (h_1, c_1)
    - **h_1** of shape `(batch, hidden_size)`: tensor containing the next hidden state
      for each element in the batch
    - **c_1** of shape `(batch, hidden_size)`: tensor containing the next cell state
      for each element in the batch

Attributes:
    weight_ih: the learnable input-hidden weights, of shape
        `(4*hidden_size, input_size)`
    weight_hh: the learnable hidden-hidden weights, of shape
        `(4*hidden_size, hidden_size)`
    bias_ih: the learnable input-hidden bias, of shape `(4*hidden_size)`
    bias_hh: the learnable hidden-hidden bias, of shape `(4*hidden_size)`

.. note::
    All the weights and biases are initialized from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`
    where :math:`k = \frac{1}{\text{hidden\_size}}`

Examples::

    >>> rnn = nn.LSTMCell(10, 20)
    >>> input = torch.randn(6, 3, 10)
    >>> hx = torch.randn(3, 20)
    >>> cx = torch.randn(3, 20)
    >>> output = []
    >>> for i in range(6):
            hx, cx = rnn(input[i], (hx, cx))
            output.append(hx)
",870,928,2190,58
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\rnn.py,GRUCell,"
A gated recurrent unit (GRU) cell

.. math::

    \begin{array}{ll}
    r = \sigma(W_{ir} x + b_{ir} + W_{hr} h + b_{hr}) \\
    z = \sigma(W_{iz} x + b_{iz} + W_{hz} h + b_{hz}) \\
    n = \tanh(W_{in} x + b_{in} + r * (W_{hn} h + b_{hn})) \\
    h' = (1 - z) * n + z * h
    \end{array}

where :math:`\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.

Args:
    input_size: The number of expected features in the input `x`
    hidden_size: The number of features in the hidden state `h`
    bias: If ``False``, then the layer does not use bias weights `b_ih` and
        `b_hh`. Default: ``True``

Inputs: input, hidden
    - **input** of shape `(batch, input_size)`: tensor containing input features
    - **hidden** of shape `(batch, hidden_size)`: tensor containing the initial hidden
      state for each element in the batch.
      Defaults to zero if not provided.

Outputs: h'
    - **h'** of shape `(batch, hidden_size)`: tensor containing the next hidden state
      for each element in the batch

Shape:
    - Input1: :math:`(N, H_{in})` tensor containing input features where
      :math:`H_{in}` = `input_size`
    - Input2: :math:`(N, H_{out})` tensor containing the initial hidden
      state for each element in the batch where :math:`H_{out}` = `hidden_size`
      Defaults to zero if not provided.
    - Output: :math:`(N, H_{out})` tensor containing the next hidden state
      for each element in the batch

Attributes:
    weight_ih: the learnable input-hidden weights, of shape
        `(3*hidden_size, input_size)`
    weight_hh: the learnable hidden-hidden weights, of shape
        `(3*hidden_size, hidden_size)`
    bias_ih: the learnable input-hidden bias, of shape `(3*hidden_size)`
    bias_hh: the learnable hidden-hidden bias, of shape `(3*hidden_size)`

.. note::
    All the weights and biases are initialized from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})`
    where :math:`k = \frac{1}{\text{hidden\_size}}`

Examples::

    >>> rnn = nn.GRUCell(10, 20)
    >>> input = torch.randn(6, 3, 10)
    >>> hx = torch.randn(3, 20)
    >>> output = []
    >>> for i in range(6):
            hx = rnn(input[i], hx)
            output.append(hx)
",949,1008,2191,59
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\sparse.py,Embedding,"
A simple lookup table that stores embeddings of a fixed dictionary and size.

This module is often used to store word embeddings and retrieve them using indices.
The input to the module is a list of indices, and the output is the corresponding
word embeddings.

Args:
    num_embeddings (int): size of the dictionary of embeddings
    embedding_dim (int): the size of each embedding vector
    padding_idx (int, optional): If given, pads the output with the embedding vector at :attr:`padding_idx`
                                     (initialized to zeros) whenever it encounters the index.
    max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`
                                is renormalized to have norm :attr:`max_norm`.
    norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.
    scale_grad_by_freq (boolean, optional): If given, this will scale gradients by the inverse of frequency of
                                            the words in the mini-batch. Default ``False``.
    sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor.
                             See Notes for more details regarding sparse gradients.

Attributes:
    weight (Tensor): the learnable weights of the module of shape (num_embeddings, embedding_dim)
                     initialized from :math:`\mathcal{N}(0, 1)`

Shape:
    - Input: :math:`(*)`, LongTensor of arbitrary shape containing the indices to extract
    - Output: :math:`(*, H)`, where `*` is the input shape and :math:`H=\text{embedding\_dim}`

.. note::
    Keep in mind that only a limited number of optimizers support
    sparse gradients: currently it's :class:`optim.SGD` (`CUDA` and `CPU`),
    :class:`optim.SparseAdam` (`CUDA` and `CPU`) and :class:`optim.Adagrad` (`CPU`)

.. note::
    With :attr:`padding_idx` set, the embedding vector at
    :attr:`padding_idx` is initialized to all zeros. However, note that this
    vector can be modified afterwards, e.g., using a customized
    initialization method, and thus changing the vector used to pad the
    output. The gradient for this vector from :class:`~torch.nn.Embedding`
    is always zero.

Examples::

    >>> # an Embedding module containing 10 tensors of size 3
    >>> embedding = nn.Embedding(10, 3)
    >>> # a batch of 2 samples of 4 indices each
    >>> input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])
    >>> embedding(input)
    tensor([[[-0.0251, -1.6902,  0.7172],
             [-0.6431,  0.0748,  0.6969],
             [ 1.4970,  1.3448, -0.9685],
             [-0.3677, -2.7265, -0.1685]],

            [[ 1.4970,  1.3448, -0.9685],
             [ 0.4362, -0.4004,  0.9400],
             [-0.6431,  0.0748,  0.6969],
             [ 0.9124, -2.3616,  1.1151]]])


    >>> # example with padding_idx
    >>> embedding = nn.Embedding(10, 3, padding_idx=0)
    >>> input = torch.LongTensor([[0,2,0,5]])
    >>> embedding(input)
    tensor([[[ 0.0000,  0.0000,  0.0000],
             [ 0.1535, -2.0309,  0.9315],
             [ 0.0000,  0.0000,  0.0000],
             [-0.1655,  0.9897,  0.0635]]])
",10,76,3177,66
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\sparse.py,EmbeddingBag,"
Computes sums or means of 'bags' of embeddings, without instantiating the
intermediate embeddings.

For bags of constant length and no :attr:`per_sample_weights`, this class

    * with ``mode=""sum""`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.sum(dim=0)``,
    * with ``mode=""mean""`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.mean(dim=0)``,
    * with ``mode=""max""`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.max(dim=0)``.

However, :class:`~torch.nn.EmbeddingBag` is much more time and memory efficient than using a chain of these
operations.

EmbeddingBag also supports per-sample weights as an argument to the forward
pass. This scales the output of the Embedding before performing a weighted
reduction as specified by ``mode``. If :attr:`per_sample_weights`` is passed, the
only supported ``mode`` is ``""sum""``, which computes a weighted sum according to
:attr:`per_sample_weights`.

Args:
    num_embeddings (int): size of the dictionary of embeddings
    embedding_dim (int): the size of each embedding vector
    max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`
                                is renormalized to have norm :attr:`max_norm`.
    norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.
    scale_grad_by_freq (boolean, optional): if given, this will scale gradients by the inverse of frequency of
                                            the words in the mini-batch. Default ``False``.
                                            Note: this option is not supported when ``mode=""max""``.
    mode (string, optional): ``""sum""``, ``""mean""`` or ``""max""``. Specifies the way to reduce the bag.
                             ``""sum""`` computes the weighted sum, taking :attr:`per_sample_weights`
                             into consideration. ``""mean""`` computes the average of the values
                             in the bag, ``""max""`` computes the max value over each bag.
                             Default: ``""mean""``
    sparse (bool, optional): if ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor. See
                             Notes for more details regarding sparse gradients. Note: this option is not
                             supported when ``mode=""max""``.

Attributes:
    weight (Tensor): the learnable weights of the module of shape `(num_embeddings, embedding_dim)`
                     initialized from :math:`\mathcal{N}(0, 1)`.

Inputs: :attr:`input` (LongTensor), :attr:`offsets` (LongTensor, optional), and
    :attr:`per_index_weights` (Tensor, optional)

    - If :attr:`input` is 2D of shape `(B, N)`,

      it will be treated as ``B`` bags (sequences) each of fixed length ``N``, and
      this will return ``B`` values aggregated in a way depending on the :attr:`mode`.
      :attr:`offsets` is ignored and required to be ``None`` in this case.

    - If :attr:`input` is 1D of shape `(N)`,

      it will be treated as a concatenation of multiple bags (sequences).
      :attr:`offsets` is required to be a 1D tensor containing the
      starting index positions of each bag in :attr:`input`. Therefore,
      for :attr:`offsets` of shape `(B)`, :attr:`input` will be viewed as
      having ``B`` bags. Empty bags (i.e., having 0-length) will have
      returned vectors filled by zeros.

    per_sample_weights (Tensor, optional): a tensor of float / double weights, or None
        to indicate all weights should be taken to be ``1``. If specified, :attr:`per_sample_weights`
        must have exactly the same shape as input and is treated as having the same
        :attr:`offsets`, if those are not ``None``. Only supported for ``mode='sum'``.


Output shape: `(B, embedding_dim)`

Examples::

    >>> # an Embedding module containing 10 tensors of size 3
    >>> embedding_sum = nn.EmbeddingBag(10, 3, mode='sum')
    >>> # a batch of 2 samples of 4 indices each
    >>> input = torch.LongTensor([1,2,4,5,4,3,2,9])
    >>> offsets = torch.LongTensor([0,4])
    >>> embedding_sum(input, offsets)
    tensor([[-0.8861, -5.4350, -0.0523],
            [ 1.1306, -2.5798, -1.0044]])
",174,250,4236,76
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\transformer.py,Transformer,"
A transformer model. User is able to modify the attributes as needed. The architecture
is based on the paper ""Attention Is All You Need"". Ashish Vaswani, Noam Shazeer,
Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and
Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information
Processing Systems, pages 6000-6010. Users can build the BERT(https://arxiv.org/abs/1810.04805)
model with corresponding parameters.

Args:
    d_model: the number of expected features in the encoder/decoder inputs (default=512).
    nhead: the number of heads in the multiheadattention models (default=8).
    num_encoder_layers: the number of sub-encoder-layers in the encoder (default=6).
    num_decoder_layers: the number of sub-decoder-layers in the decoder (default=6).
    dim_feedforward: the dimension of the feedforward network model (default=2048).
    dropout: the dropout value (default=0.1).
    activation: the activation function of encoder/decoder intermediate layer, relu or gelu (default=relu).
    custom_encoder: custom encoder (default=None).
    custom_decoder: custom decoder (default=None).

Examples::
    >>> transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)
    >>> src = torch.rand((10, 32, 512))
    >>> tgt = torch.rand((20, 32, 512))
    >>> out = transformer_model(src, tgt)

Note: A full example to apply nn.Transformer module for the word language model is available in
https://github.com/pytorch/examples/tree/master/word_language_model
",14,40,1521,26
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\transformer.py,TransformerEncoder,"
TransformerEncoder is a stack of N encoder layers

Args:
    encoder_layer: an instance of the TransformerEncoderLayer() class (required).
    num_layers: the number of sub-encoder-layers in the encoder (required).
    norm: the layer normalization component (optional).

Examples::
    >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)
    >>> transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)
    >>> src = torch.rand(10, 32, 512)
    >>> out = transformer_encoder(src)
",143,155,513,12
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\transformer.py,TransformerDecoder,"
TransformerDecoder is a stack of N decoder layers

Args:
    decoder_layer: an instance of the TransformerDecoderLayer() class (required).
    num_layers: the number of sub-decoder-layers in the decoder (required).
    norm: the layer normalization component (optional).

Examples::
    >>> decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)
    >>> transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)
    >>> memory = torch.rand(10, 32, 512)
    >>> tgt = torch.rand(20, 32, 512)
    >>> out = transformer_decoder(tgt, memory)
",188,201,562,13
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\transformer.py,TransformerEncoderLayer,"
TransformerEncoderLayer is made up of self-attn and feedforward network.
This standard encoder layer is based on the paper ""Attention Is All You Need"".
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in
Neural Information Processing Systems, pages 6000-6010. Users may modify or implement
in a different way during application.

Args:
    d_model: the number of expected features in the input (required).
    nhead: the number of heads in the multiheadattention models (required).
    dim_feedforward: the dimension of the feedforward network model (default=2048).
    dropout: the dropout value (default=0.1).
    activation: the activation function of intermediate layer, relu or gelu (default=relu).

Examples::
    >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)
    >>> src = torch.rand(10, 32, 512)
    >>> out = encoder_layer(src)
",241,259,980,18
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\transformer.py,TransformerDecoderLayer,"
TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.
This standard decoder layer is based on the paper ""Attention Is All You Need"".
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in
Neural Information Processing Systems, pages 6000-6010. Users may modify or implement
in a different way during application.

Args:
    d_model: the number of expected features in the input (required).
    nhead: the number of heads in the multiheadattention models (required).
    dim_feedforward: the dimension of the feedforward network model (default=2048).
    dropout: the dropout value (default=0.1).
    activation: the activation function of intermediate layer, relu or gelu (default=relu).

Examples::
    >>> decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)
    >>> memory = torch.rand(10, 32, 512)
    >>> tgt = torch.rand(20, 32, 512)
    >>> out = decoder_layer(tgt, memory)
",304,323,1046,19
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\upsampling.py,Upsample,"
Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.

The input data is assumed to be of the form
`minibatch x channels x [optional depth] x [optional height] x width`.
Hence, for spatial inputs, we expect a 4D Tensor and for volumetric inputs, we expect a 5D Tensor.

The algorithms available for upsampling are nearest neighbor and linear,
bilinear, bicubic and trilinear for 3D, 4D and 5D input Tensor,
respectively.

One can either give a :attr:`scale_factor` or the target output :attr:`size` to
calculate the output size. (You cannot give both, as it is ambiguous)

Args:
    size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int], optional):
        output spatial sizes
    scale_factor (float or Tuple[float] or Tuple[float, float] or Tuple[float, float, float], optional):
        multiplier for spatial size. Has to match input size if it is a tuple.
    mode (str, optional): the upsampling algorithm: one of ``'nearest'``,
        ``'linear'``, ``'bilinear'``, ``'bicubic'`` and ``'trilinear'``.
        Default: ``'nearest'``
    align_corners (bool, optional): if ``True``, the corner pixels of the input
        and output tensors are aligned, and thus preserving the values at
        those pixels. This only has effect when :attr:`mode` is
        ``'linear'``, ``'bilinear'``, or ``'trilinear'``. Default: ``False``

Shape:
    - Input: :math:`(N, C, W_{in})`, :math:`(N, C, H_{in}, W_{in})` or :math:`(N, C, D_{in}, H_{in}, W_{in})`
    - Output: :math:`(N, C, W_{out})`, :math:`(N, C, H_{out}, W_{out})`
      or :math:`(N, C, D_{out}, H_{out}, W_{out})`, where

.. math::
    D_{out} = \left\lfloor D_{in} \times \text{scale\_factor} \right\rfloor

.. math::
    H_{out} = \left\lfloor H_{in} \times \text{scale\_factor} \right\rfloor

.. math::
    W_{out} = \left\lfloor W_{in} \times \text{scale\_factor} \right\rfloor

.. warning::
    With ``align_corners = True``, the linearly interpolating modes
    (`linear`, `bilinear`, `bicubic`, and `trilinear`) don't proportionally
    align the output and input pixels, and thus the output values can depend
    on the input size. This was the default behavior for these modes up to
    version 0.3.1. Since then, the default behavior is
    ``align_corners = False``. See below for concrete examples on how this
    affects the outputs.

.. note::
    If you want downsampling/general resizing, you should use :func:`~nn.functional.interpolate`.

Examples::

    >>> input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2)
    >>> input
    tensor([[[[ 1.,  2.],
              [ 3.,  4.]]]])

    >>> m = nn.Upsample(scale_factor=2, mode='nearest')
    >>> m(input)
    tensor([[[[ 1.,  1.,  2.,  2.],
              [ 1.,  1.,  2.,  2.],
              [ 3.,  3.,  4.,  4.],
              [ 3.,  3.,  4.,  4.]]]])

    >>> m = nn.Upsample(scale_factor=2, mode='bilinear')  # align_corners=False
    >>> m(input)
    tensor([[[[ 1.0000,  1.2500,  1.7500,  2.0000],
              [ 1.5000,  1.7500,  2.2500,  2.5000],
              [ 2.5000,  2.7500,  3.2500,  3.5000],
              [ 3.0000,  3.2500,  3.7500,  4.0000]]]])

    >>> m = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
    >>> m(input)
    tensor([[[[ 1.0000,  1.3333,  1.6667,  2.0000],
              [ 1.6667,  2.0000,  2.3333,  2.6667],
              [ 2.3333,  2.6667,  3.0000,  3.3333],
              [ 3.0000,  3.3333,  3.6667,  4.0000]]]])

    >>> # Try scaling the same data in a larger tensor
    >>>
    >>> input_3x3 = torch.zeros(3, 3).view(1, 1, 3, 3)
    >>> input_3x3[:, :, :2, :2].copy_(input)
    tensor([[[[ 1.,  2.],
              [ 3.,  4.]]]])
    >>> input_3x3
    tensor([[[[ 1.,  2.,  0.],
              [ 3.,  4.,  0.],
              [ 0.,  0.,  0.]]]])

    >>> m = nn.Upsample(scale_factor=2, mode='bilinear')  # align_corners=False
    >>> # Notice that values in top left corner are the same with the small input (except at boundary)
    >>> m(input_3x3)
    tensor([[[[ 1.0000,  1.2500,  1.7500,  1.5000,  0.5000,  0.0000],
              [ 1.5000,  1.7500,  2.2500,  1.8750,  0.6250,  0.0000],
              [ 2.5000,  2.7500,  3.2500,  2.6250,  0.8750,  0.0000],
              [ 2.2500,  2.4375,  2.8125,  2.2500,  0.7500,  0.0000],
              [ 0.7500,  0.8125,  0.9375,  0.7500,  0.2500,  0.0000],
              [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])

    >>> m = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
    >>> # Notice that values in top left corner are now changed
    >>> m(input_3x3)
    tensor([[[[ 1.0000,  1.4000,  1.8000,  1.6000,  0.8000,  0.0000],
              [ 1.8000,  2.2000,  2.6000,  2.2400,  1.1200,  0.0000],
              [ 2.6000,  3.0000,  3.4000,  2.8800,  1.4400,  0.0000],
              [ 2.4000,  2.7200,  3.0400,  2.5600,  1.2800,  0.0000],
              [ 1.2000,  1.3600,  1.5200,  1.2800,  0.6400,  0.0000],
              [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])
",6,116,4999,110
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\upsampling.py,UpsamplingNearest2d,"
Applies a 2D nearest neighbor upsampling to an input signal composed of several input
channels.

To specify the scale, it takes either the :attr:`size` or the :attr:`scale_factor`
as it's constructor argument.

When :attr:`size` is given, it is the output size of the image `(h, w)`.

Args:
    size (int or Tuple[int, int], optional): output spatial sizes
    scale_factor (float or Tuple[float, float], optional): multiplier for
        spatial size.

.. warning::
    This class is deprecated in favor of :func:`~nn.functional.interpolate`.

Shape:
    - Input: :math:`(N, C, H_{in}, W_{in})`
    - Output: :math:`(N, C, H_{out}, W_{out})` where

.. math::
      H_{out} = \left\lfloor H_{in} \times \text{scale\_factor} \right\rfloor

.. math::
      W_{out} = \left\lfloor W_{in} \times \text{scale\_factor} \right\rfloor

Examples::

    >>> input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2)
    >>> input
    tensor([[[[ 1.,  2.],
              [ 3.,  4.]]]])

    >>> m = nn.UpsamplingNearest2d(scale_factor=2)
    >>> m(input)
    tensor([[[[ 1.,  1.,  2.,  2.],
              [ 1.,  1.,  2.,  2.],
              [ 3.,  3.,  4.,  4.],
              [ 3.,  3.,  4.,  4.]]]])
",143,182,1197,39
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\upsampling.py,UpsamplingBilinear2d,"
Applies a 2D bilinear upsampling to an input signal composed of several input
channels.

To specify the scale, it takes either the :attr:`size` or the :attr:`scale_factor`
as it's constructor argument.

When :attr:`size` is given, it is the output size of the image `(h, w)`.

Args:
    size (int or Tuple[int, int], optional): output spatial sizes
    scale_factor (float or Tuple[float, float], optional): multiplier for
        spatial size.

.. warning::
    This class is deprecated in favor of :func:`~nn.functional.interpolate`. It is
    equivalent to ``nn.functional.interpolate(..., mode='bilinear', align_corners=True)``.

Shape:
    - Input: :math:`(N, C, H_{in}, W_{in})`
    - Output: :math:`(N, C, H_{out}, W_{out})` where

.. math::
    H_{out} = \left\lfloor H_{in} \times \text{scale\_factor} \right\rfloor

.. math::
    W_{out} = \left\lfloor W_{in} \times \text{scale\_factor} \right\rfloor

Examples::

    >>> input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2)
    >>> input
    tensor([[[[ 1.,  2.],
              [ 3.,  4.]]]])

    >>> m = nn.UpsamplingBilinear2d(scale_factor=2)
    >>> m(input)
    tensor([[[[ 1.0000,  1.3333,  1.6667,  2.0000],
              [ 1.6667,  2.0000,  2.3333,  2.6667],
              [ 2.3333,  2.6667,  3.0000,  3.3333],
              [ 3.0000,  3.3333,  3.6667,  4.0000]]]])
",188,228,1347,40
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\_functions.py,SyncBatchNorm,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\modules\_functions.py,CrossMapLRN2d,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\parallel\data_parallel.py,DataParallel,"
Implements data parallelism at the module level.

This container parallelizes the application of the given :attr:`module` by
splitting the input across the specified devices by chunking in the batch
dimension (other objects will be copied once per device). In the forward
pass, the module is replicated on each device, and each replica handles a
portion of the input. During the backwards pass, gradients from each replica
are summed into the original module.

The batch size should be larger than the number of GPUs used.

See also: :ref:`cuda-nn-dataparallel-instead`

Arbitrary positional and keyword inputs are allowed to be passed into
DataParallel but some types are specially handled. tensors will be
**scattered** on dim specified (default 0). tuple, list and dict types will
be shallow copied. The other types will be shared among different threads
and can be corrupted if written to in the model's forward pass.

The parallelized :attr:`module` must have its parameters and buffers on
``device_ids[0]`` before running this :class:`~torch.nn.DataParallel`
module.

.. warning::
    In each forward, :attr:`module` is **replicated** on each device, so any
    updates to the running module in ``forward`` will be lost. For example,
    if :attr:`module` has a counter attribute that is incremented in each
    ``forward``, it will always stay at the initial value because the update
    is done on the replicas which are destroyed after ``forward``. However,
    :class:`~torch.nn.DataParallel` guarantees that the replica on
    ``device[0]`` will have its parameters and buffers sharing storage with
    the base parallelized :attr:`module`. So **in-place** updates to the
    parameters or buffers on ``device[0]`` will be recorded. E.g.,
    :class:`~torch.nn.BatchNorm2d` and :func:`~torch.nn.utils.spectral_norm`
    rely on this behavior to update the buffers.

.. warning::
    Forward and backward hooks defined on :attr:`module` and its submodules
    will be invoked ``len(device_ids)`` times, each with inputs located on
    a particular device. Particularly, the hooks are only guaranteed to be
    executed in correct order with respect to operations on corresponding
    devices. For example, it is not guaranteed that hooks set via
    :meth:`~torch.nn.Module.register_forward_pre_hook` be executed before
    `all` ``len(device_ids)`` :meth:`~torch.nn.Module.forward` calls, but
    that each such hook be executed before the corresponding
    :meth:`~torch.nn.Module.forward` call of that device.

.. warning::
    When :attr:`module` returns a scalar (i.e., 0-dimensional tensor) in
    :func:`forward`, this wrapper will return a vector of length equal to
    number of devices used in data parallelism, containing the result from
    each device.

.. note::
    There is a subtlety in using the
    ``pack sequence -> recurrent network -> unpack sequence`` pattern in a
    :class:`~torch.nn.Module` wrapped in :class:`~torch.nn.DataParallel`.
    See :ref:`pack-rnn-unpack-with-data-parallelism` section in FAQ for
    details.


Args:
    module (Module): module to be parallelized
    device_ids (list of int or torch.device): CUDA devices (default: all devices)
    output_device (int or torch.device): device location of output (default: device_ids[0])

Attributes:
    module (Module): the module to be parallelized

Example::

    >>> net = torch.nn.DataParallel(model, device_ids=[0, 1, 2])
    >>> output = net(input_var)  # input_var can be on any device, including CPU
TODO: update notes/cuda.rst when this class handles 8+ GPUs well",37,110,3508,73
C:\Users\vaano\python_projects\pytorch\torch\nn\parallel\distributed.py,DistributedDataParallel,"
Implements distributed data parallelism that is based on
``torch.distributed`` package at the module level.

This container parallelizes the application of the given module by
splitting the input across the specified devices by chunking in the batch
dimension. The module is replicated on each machine and each device, and
each such replica handles a portion of the input. During the backwards
pass, gradients from each node are averaged.

The batch size should be larger than the number of GPUs used locally.

See also: :ref:`distributed-basics` and :ref:`cuda-nn-dataparallel-instead`.
The same constraints on input as in :class:`torch.nn.DataParallel` apply.

Creation of this class requires that ``torch.distributed`` to be already
initialized, by calling :func:`torch.distributed.init_process_group`.

``DistributedDataParallel`` can be used in the following two ways:

(1) Single-Process Multi-GPU

In this case, a single process will be
spawned on each host/node and each process will operate on all the GPUs
of the node where it's running. To use ``DistributedDataParallel`` in
this way, you can simply construct the model as the following:

    >>> torch.distributed.init_process_group(backend=""nccl"")
    >>> model = DistributedDataParallel(model) # device_ids will include all GPU devices by default

(2) Multi-Process Single-GPU

This is the highly recommended way to use ``DistributedDataParallel``, with
multiple processes, each of which operates on a single GPU. This is
currently the fastest approach to do data parallel training using PyTorch
and applies to both single-node(multi-GPU) and multi-node data
parallel training. It is proven to be significantly faster than
:class:`torch.nn.DataParallel` for single-node multi-GPU data
parallel training.

Here is how to use it: on each host with N GPUs, you should spawn up N
processes, while ensuring that each process individually works on a single GPU
from 0 to N-1. Therefore, it is your job to ensure that your training script
operates on a single given GPU by calling:

    >>> torch.cuda.set_device(i)

where i is from 0 to N-1. In each process, you should refer the following
to construct this module:

    >>> torch.distributed.init_process_group(backend='nccl', world_size=4, init_method='...')
    >>> model = DistributedDataParallel(model, device_ids=[i], output_device=i)

In order to spawn up multiple processes per node, you can use either
``torch.distributed.launch`` or ``torch.multiprocessing.spawn``

.. note:: ``nccl`` backend is currently the fastest and
    highly recommended backend to be used with Multi-Process Single-GPU
    distributed training and this applies to both single-node and multi-node
    distributed training

.. note:: This module also supports mixed-precision distributed training.
    This means that your model can have different types of parameters such
    as mixed types of fp16 and fp32, the gradient reduction on these
    mixed types of parameters will just work fine.
    Also note that ``nccl`` backend is currently the fastest and highly
    recommended backend for fp16/fp32 mixed-precision training.

.. note:: If you use ``torch.save`` on one process to checkpoint the module,
    and ``torch.load`` on some other processes to recover it, make sure that
    ``map_location`` is configured properly for every process. Without
    ``map_location``, ``torch.load`` would recover the module to devices
    where the module was saved from.

.. warning::
    This module works only with the ``gloo`` and ``nccl`` backends.

.. warning::
    Constructor, forward method, and differentiation of the output (or a
    function of the output of this module) is a distributed synchronization
    point. Take that into account in case different processes might be
    executing different code.

.. warning::
    This module assumes all parameters are registered in the model by the
    time it is created. No parameters should be added nor removed later.
    Same applies to buffers.

.. warning::
    This module assumes all parameters are registered in the model of each
    distributed processes are in the same order. The module itself will
    conduct gradient all-reduction following the reverse order of the
    registered parameters of the model. In other words, it is users'
    responsibility to ensure that each distributed process has the exact
    same model and thus the exact same parameter registration order.

.. warning::
    This module assumes all buffers and gradients are dense.

.. warning::
    This module doesn't work with :func:`torch.autograd.grad` (i.e. it will
    only work if gradients are to be accumulated in ``.grad`` attributes of
    parameters).

.. warning::

    If you plan on using this module with a ``nccl`` backend or a ``gloo``
    backend (that uses Infiniband), together with a DataLoader that uses
    multiple workers, please change the multiprocessing start method to
    ``forkserver`` (Python 3 only) or ``spawn``. Unfortunately
    Gloo (that uses Infiniband) and NCCL2 are not fork safe, and you will
    likely experience deadlocks if you don't change this setting.

.. warning::
    Forward and backward hooks defined on :attr:`module` and its submodules
    won't be invoked anymore, unless the hooks are initialized in the
    :meth:`forward` method.

.. warning::
    You should never try to change your model's parameters after wrapping
    up your model with DistributedDataParallel. In other words, when
    wrapping up your model with DistributedDataParallel, the constructor of
    DistributedDataParallel will register the additional gradient
    reduction functions on all the parameters of the model itself at the
    time of construction. If you change the model's parameters after
    the DistributedDataParallel construction, this is not supported and
    unexpected behaviors can happen, since some parameters' gradient
    reduction functions might not get called.

.. note::
    Parameters are never broadcast between processes. The module performs
    an all-reduce step on gradients and assumes that they will be modified
    by the optimizer in all processes in the same way. Buffers
    (e.g. BatchNorm stats) are broadcast from the module in process of rank
    0, to all other replicas in the system in every iteration.

Args:
    module (Module): module to be parallelized
    device_ids (list of int or torch.device): CUDA devices. This should
               only be provided when the input module resides on a single
               CUDA device. For single-device modules, the ``i``th
               :attr:`module` replica is placed on ``device_ids[i]``. For
               multi-device modules and CPU modules, device_ids must be None
               or an empty list, and input data for the forward pass must be
               placed on the correct device. (default: all devices for
               single-device modules)
    output_device (int or torch.device): device location of output for
                  single-device CUDA modules. For multi-device modules and
                  CPU modules, it must be None, and the module itself
                  dictates the output location. (default: device_ids[0] for
                  single-device modules)
    broadcast_buffers (bool): flag that enables syncing (broadcasting) buffers of
                      the module at beginning of the forward function.
                      (default: ``True``)
    process_group: the process group to be used for distributed data
                   all-reduction. If ``None``, the default process group, which
                   is created by ```torch.distributed.init_process_group```,
                   will be used. (default: ``None``)
    bucket_cap_mb: DistributedDataParallel will bucket parameters into
                   multiple buckets so that gradient reduction of each
                   bucket can potentially overlap with backward computation.
                   :attr:`bucket_cap_mb` controls the bucket size in MegaBytes (MB)
                   (default: 25)
    find_unused_parameters (bool): Traverse the autograd graph of all tensors
                                   contained in the return value of the wrapped
                                   module's ``forward`` function.
                                   Parameters that don't receive gradients as
                                   part of this graph are preemptively marked
                                   as being ready to be reduced. Note that all
                                   ``forward`` outputs that are derived from
                                   module parameters must participate in
                                   calculating loss and later the gradient
                                   computation. If they don't, this wrapper will
                                   hang waiting for autograd to produce gradients
                                   for those parameters. Any outputs derived from
                                   module parameters that are otherwise unused can
                                   be detached from the autograd graph using
                                   ``torch.Tensor.detach``. (default: ``False``)
    check_reduction: when setting to ``True``, it enables DistributedDataParallel
                     to automatically check if the previous iteration's
                     backward reductions were successfully issued at the
                     beginning of every iteration's forward function.
                     You normally don't need this option enabled unless you
                     are observing weird behaviors such as different ranks
                     are getting different gradients, which should not
                     happen if DistributedDataParallel is correctly used.
                     (default: ``False``)

Attributes:
    module (Module): the module to be parallelized

Example::

    >>> torch.distributed.init_process_group(backend='nccl', world_size=4, init_method='...')
    >>> net = torch.nn.DistributedDataParallel(model, pg)
",34,228,10087,194
C:\Users\vaano\python_projects\pytorch\torch\nn\parallel\_functions.py,Broadcast,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\parallel\_functions.py,ReduceAddCoalesced,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\parallel\_functions.py,Gather,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\parallel\_functions.py,Scatter,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\qat\modules\conv.py,Conv2d,"
A Conv2d module attached with FakeQuantize modules for both output
activation and weight, used for quantization aware training.

We adopt the same interface as `torch.nn.Conv2d`, please see
https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d
for documentation.

Similar to `torch.nn.Conv2d`, with FakeQuantize modules initialized to
default.

Attributes:
    activation_post_process: fake quant module for output activation
    weight_fake_quant: fake quant module for weight
",6,19,496,13
C:\Users\vaano\python_projects\pytorch\torch\nn\qat\modules\linear.py,Linear,"
A linear module attached with FakeQuantize modules for both output
activation and weight, used for quantization aware training.

We adopt the same interface as `torch.nn.Linear`, please see
https://pytorch.org/docs/stable/nn.html#torch.nn.Linear
for documentation.

Similar to `torch.nn.Linear`, with FakeQuantize modules initialized to
default.

Attributes:
    activation_post_process: fake quant module for output activation
    weight: fake quant module for weight
",7,20,468,13
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\dynamic\modules\linear.py,Linear,"
A dynamic quantized linear module with quantized tensor as inputs and outputs.
We adopt the same interface as `torch.nn.Linear`, please see
https://pytorch.org/docs/stable/nn.html#torch.nn.Linear for documentation.

Similar to :class:`torch.nn.Linear`, attributes will be randomly
initialized at module creation time and will be overwritten later

Attributes:
    weight (Tensor): the non-learnable quantized weights of the module which are of
                     shape :math:`(\text{out\_features}, \text{in\_features})`.
    bias (Tensor): the non-learnable bias of the module of shape :math:`(\text{out\_features})`.
            If :attr:`bias` is ``True``, the values are initialized to zero.

Examples::

    >>> m = nn.quantized.dynamic.Linear(20, 30)
    >>> input = torch.randn(128, 20)
    >>> output = m(input)
    >>> print(output.size())
    torch.Size([128, 30])
",8,28,876,20
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\dynamic\modules\rnn.py,PackedParameter,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\dynamic\modules\rnn.py,RNNBase,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\dynamic\modules\rnn.py,LSTM,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\modules\activation.py,ReLU,"
Applies quantized rectified linear unit function element-wise:

:math:`\text{ReLU}(x)= \max(x_0, x)`, where :math:`x_0` is the zero point.

Please see https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU
for more documentation on ReLU.

Args:
    inplace: (Currently not supported) can optionally do the operation in-place.

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

Examples::

    >>> m = nn.quantized.ReLU()
    >>> input = torch.randn(2)
    >>> input = torch.quantize_per_tensor(input, 1.0, 0, dtype=torch.qint32)
    >>> output = m(input)
",10,31,652,21
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\modules\activation.py,ReLU6,"
Applies the element-wise function:

:math:`\text{ReLU6}(x) = \min(\max(x_0, x), q(6))`, where :math:`x_0` is the
zero_point, and :math:`q(6)` is the quantized representation of number 6.

Args:
    inplace: can optionally do the operation in-place. Default: ``False``

Shape:
    - Input: :math:`(N, *)` where `*` means, any number of additional
      dimensions
    - Output: :math:`(N, *)`, same shape as the input

.. image:: scripts/activation_images/ReLU6.png

Examples::

    >>> m = nn.quantized.ReLU6()
    >>> input = torch.randn(2)
    >>> input = torch.quantize_per_tensor(input, 1.0, 0, dtype=torch.qint32)
    >>> output = m(input)
",48,69,644,21
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\modules\conv.py,_ConvNd,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\modules\conv.py,Conv2d,"
Applies a 2D convolution over a quantized input signal composed of
several quantized input planes.

For details on input arguments, parameters, and implementation see
:class:`~torch.nn.Conv2d`.

.. note::
    Only `zeros` is supported for the :attr:`padding_mode` argument.

.. note::
    Only `torch.quint8` is supported for the input data type.


Attributes:
    weight (Tensor):     packed tensor derived from the learnable weight
                         parameter.
    scale (Tensor):      scalar for the output scale
    zero_point (Tensor): scalar for the output zero point

See :class:`~torch.nn.Conv2d` for other attributes.

Examples::

    >>> # With square kernels and equal stride
    >>> m = nn.quantized.Conv2d(16, 33, 3, stride=2)
    >>> # non-square kernels and unequal stride and with padding
    >>> m = nn.quantized.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))
    >>> # non-square kernels and unequal stride and with padding and dilation
    >>> m = nn.quantized.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))
    >>> input = torch.randn(20, 16, 50, 100)
    >>> # quantize input to qint8
    >>> q_input = torch.quantize_per_tensor(input, scale=1.0, zero_point=0, dtype=torch.qint32)
    >>> output = m(input)
",140,173,1265,33
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\modules\conv.py,Conv3d,"
Applies a 3D convolution over a quantized input signal composed of
several quantized input planes.

For details on input arguments, parameters, and implementation see
:class:`~torch.nn.Conv3d`.

.. note::
    Only `zeros` is supported for the :attr:`padding_mode` argument.

.. note::
    Only `torch.quint8` is supported for the input data type.


Attributes:
    weight (Tensor):     packed tensor derived from the learnable weight
                         parameter.
    scale (Tensor):      scalar for the output scale
    zero_point (Tensor): scalar for the output zero point

See :class:`~torch.nn.Conv3d` for other attributes.

Examples::

    >>> # With square kernels and equal stride
    >>> m = nn.quantized.Conv3d(16, 33, 3, stride=2)
    >>> # non-square kernels and unequal stride and with padding
    >>> m = nn.quantized.Conv3d(16, 33, (3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2))
    >>> # non-square kernels and unequal stride and with padding and dilation
    >>> m = nn.quantized.Conv3d(16, 33, (3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2), dilation=(1, 2, 2))
    >>> input = torch.randn(20, 16, 56, 56, 56)
    >>> # quantize input to qint8
    >>> q_input = torch.quantize_per_tensor(input, scale=1.0, zero_point=0, dtype=torch.qint32)
    >>> output = m(input)
",266,299,1289,33
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\modules\functional_modules.py,FloatFunctional,"
State collector class for float operatitons.

The instance of this class can be used instead of the ``torch.`` prefix for
some operations. See example usage below.

.. note::

    This class does not provide a ``forward`` hook. Instead, you must use
    one of the underlying functions (e.g. ``add``).

Examples::

    >>> f_add = FloatFunctional()
    >>> a = torch.tensor(3.0)
    >>> b = torch.tensor(4.0)
    >>> f_add.add(a, b)  # Equivalent to ``torch.add(3, 4)

Valid operation names:
    - add
    - cat
    - mul
    - add_relu
    - add_scalar
    - mul_scalar
",6,30,570,24
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\modules\functional_modules.py,QFunctional,"
Wrapper class for quantized operatitons.

The instance of this class can be used instead of the
``torch.ops.quantized`` prefix. See example usage below.

.. note::

    This class does not provide a ``forward`` hook. Instead, you must use
    one of the underlying functions (e.g. ``add``).

Examples::

    >>> q_add = QFunctional('add')
    >>> a = torch.quantize_per_tensor(torch.tensor(3.0), 1.0, 0, torch.qint32)
    >>> b = torch.quantize_per_tensor(torch.tensor(4.0), 1.0, 0, torch.qint32)
    >>> q_add.add(a, b)  # Equivalent to ``torch.ops.quantized.add(3, 4)

Valid operation names:
    - add
    - cat
    - mul
    - add_relu
    - add_scalar
    - mul_scalar
",84,108,672,24
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\modules\linear.py,LinearPackedParams,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\modules\linear.py,Linear,"
A quantized linear module with quantized tensor as inputs and outputs.
We adopt the same interface as `torch.nn.Linear`, please see
https://pytorch.org/docs/stable/nn.html#torch.nn.Linear for documentation.

Similar to :class:`~torch.nn.Linear`, attributes will be randomly
initialized at module creation time and will be overwritten later

Attributes:
    weight (Tensor): the non-learnable quantized weights of the module of
                     shape :math:`(\text{out\_features}, \text{in\_features})`.
    bias (Tensor): the non-learnable bias of the module of shape :math:`(\text{out\_features})`.
            If :attr:`bias` is ``True``, the values are initialized to zero.
    scale: `scale` parameter of output Quantized Tensor, type: double
    zero_point: `zero_point` parameter for output Quantized Tensor, type: long

Examples::

    >>> m = nn.quantized.Linear(20, 30)
    >>> input = torch.randn(128, 20)
    >>> input = torch.quantize_per_tensor(input, 1.0, 0, torch.quint8)
    >>> output = m(input)
    >>> print(output.size())
    torch.Size([128, 30])
",59,82,1071,23
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\modules\__init__.py,Quantize,"
Quantizes an incoming tensor

Args:
 `scale`: scale of the output Quantized Tensor
 `zero_point`: zero_point of output Quantized Tensor
 `dtype`: data type of output Quantized Tensor

Attributes:
  `scale`, `zero_point`, `dtype`

Examples::
    >>> t = torch.tensor([[1., -1.], [1., -1.]])
    >>> scale, zero_point, dtype = 1.0, 2, torch.qint8
    >>> qm = Quantize(scale, zero_point, dtype)
    >>> qt = qm(t)
    >>> print(qt)
    tensor([[ 1., -1.],
            [ 1., -1.]], size=(2, 2), dtype=torch.qint8, scale=1.0, zero_point=2)
",14,32,535,18
C:\Users\vaano\python_projects\pytorch\torch\nn\quantized\modules\__init__.py,DeQuantize,"
Dequantizes an incoming tensor

Examples::
    >>> input = torch.tensor([[1., -1.], [1., -1.]])
    >>> scale, zero_point, dtype = 1.0, 2, torch.qint8
    >>> qm = Quantize(scale, zero_point, dtype)
    >>> quantized_input = qm(input)
    >>> dqm = DeQuantize()
    >>> dequantized = dqm(quantized_input)
    >>> print(dequantized)
    tensor([[ 1., -1.],
            [ 1., -1.]], dtype=torch.float32)
",55,67,401,12
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\prune.py,BasePruningMethod,"
Abstract base class for creation of new pruning techniques.

Provides a skeleton for customization requiring the overriding of methods
such as :meth:`compute_mask` and :meth:`apply`.
",17,21,182,4
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\prune.py,PruningContainer,"
Container holding a sequence of pruning methods for iterative pruning.
Keeps track of the order in which pruning methods are applied and handles
combining successive pruning calls.

Accepts as argument an instance of a BasePruningMethod or an iterable of 
them. 
",248,254,261,6
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\prune.py,Identity,"
Utility pruning method that does not prune any units but generates the
pruning parametrization with a mask of ones.
",399,401,115,2
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\prune.py,RandomUnstructured,"
Prune (currently unpruned) units in a tensor at random.

Args:
    name (str): parameter name within ``module`` on which pruning
        will act.
    amount (int or float): quantity of parameters to prune.
        If ``float``, should be between 0.0 and 1.0 and represent the
        fraction of parameters to prune. If ``int``, it represents the 
        absolute number of parameters to prune.
",424,433,396,9
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\prune.py,L1Unstructured,"
Prune (currently unpruned) units in a tensor by zeroing out the ones 
with the lowest L1-norm.

Args:
    amount (int or float): quantity of parameters to prune.
        If ``float``, should be between 0.0 and 1.0 and represent the
        fraction of parameters to prune. If ``int``, it represents the 
        absolute number of parameters to prune.
",483,491,351,8
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\prune.py,RandomStructured,"
Prune entire (currently unpruned) channels in a tensor at random.

Args:
    amount (int or float): quantity of parameters to prune.
        If ``float``, should be between 0.0 and 1.0 and represent the
        fraction of parameters to prune. If ``int``, it represents the 
        absolute number of parameters to prune.
    dim (int, optional): index of the dim along which we define
        channels to prune. Default: -1.
",543,552,426,9
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\prune.py,LnStructured,"
Prune entire (currently unpruned) channels in a tensor based on their
Ln-norm.

Args:
    amount (int or float): quantity of channels to prune.
        If ``float``, should be between 0.0 and 1.0 and represent the
        fraction of parameters to prune. If ``int``, it represents the 
        absolute number of parameters to prune.
    n (int, float, inf, -inf, 'fro', 'nuc'): See documentation of valid
        entries for argument ``p`` in :func:`torch.norm`.
    dim (int, optional): index of the dim along which we define
        channels to prune. Default: -1.
",648,660,567,12
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\prune.py,CustomFromMask,,,,,
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\rnn.py,PackedSequence,"
Holds the data and list of :attr:`batch_sizes` of a packed sequence.

All RNN modules accept packed sequences as inputs.

Note:
    Instances of this class should never be created manually. They are meant
    to be instantiated by functions like :func:`pack_padded_sequence`.

    Batch sizes represent the number elements at each sequence step in
    the batch, not the varying sequence lengths passed to
    :func:`pack_padded_sequence`.  For instance, given data ``abc`` and ``x``
    the :class:`PackedSequence` would contain data ``axbc`` with
    ``batch_sizes=[2,1,1]``.

Attributes:
    data (Tensor): Tensor containing packed sequence
    batch_sizes (Tensor): Tensor of integers holding
        information about the batch size at each sequence step
    sorted_indices (Tensor, optional): Tensor of integers holding how this
        :class:`PackedSequence` is constructed from sequences.
    unsorted_indices (Tensor, optional): Tensor of integers holding how this
        to recover the original sequences with correct order.

.. note::
    :attr:`data` can be on arbitrary device and of arbitrary dtype.
    :attr:`sorted_indices` and :attr:`unsorted_indices` must be ``torch.int64``
    tensors on the same device as :attr:`data`.

    However, :attr:`batch_sizes` should always be a CPU ``torch.int64`` tensor.

    This invariant is maintained throughout :class:`PackedSequence` class,
    and all functions that construct a `:class:PackedSequence` in PyTorch
    (i.e., they only pass in tensors conforming to this constraint).
NOTE [ device and dtype of a PackedSequence ]
    
    See the note above in doc string (starting with "":attr:`data` can be on
    arbitrary device..."").",24,57,1543,33
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\spectral_norm.py,SpectralNorm,"Invariant before and after each forward call:
      u = normalize(W @ v)
    NB: At initialization, this invariant is not enforced
 ",9,11,1,1
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\spectral_norm.py,SpectralNormLoadStateDictPreHook,"See docstring of SpectralNorm._version on the changes to spectral_norm.
 ",146,146,23,1
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\spectral_norm.py,SpectralNormStateDictHook,"See docstring of SpectralNorm._version on the changes to spectral_norm.
 ",192,192,23,1
C:\Users\vaano\python_projects\pytorch\torch\nn\utils\weight_norm.py,WeightNorm,,,,,
C:\Users\vaano\python_projects\pytorch\torch\onnx\__init__.py,ExportTypes,,,,,
C:\Users\vaano\python_projects\pytorch\torch\optim\adadelta.py,Adadelta,"
Implements Adadelta algorithm.

It has been proposed in `ADADELTA: An Adaptive Learning Rate Method`__.

Arguments:
    params (iterable): iterable of parameters to optimize or dicts defining
        parameter groups
    rho (float, optional): coefficient used for computing a running average
        of squared gradients (default: 0.9)
    eps (float, optional): term added to the denominator to improve
        numerical stability (default: 1e-6)
    lr (float, optional): coefficient that scale delta before it is applied
        to the parameters (default: 1.0)
    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)

__ https://arxiv.org/abs/1212.5701
",7,23,676,16
C:\Users\vaano\python_projects\pytorch\torch\optim\adagrad.py,Adagrad,"
Implements Adagrad algorithm.

It has been proposed in `Adaptive Subgradient Methods for Online Learning
and Stochastic Optimization`_.

Arguments:
    params (iterable): iterable of parameters to optimize or dicts defining
        parameter groups
    lr (float, optional): learning rate (default: 1e-2)
    lr_decay (float, optional): learning rate decay (default: 0)
    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)
    eps (float, optional): term added to the denominator to improve
        numerical stability (default: 1e-10)

.. _Adaptive Subgradient Methods for Online Learning and Stochastic
    Optimization: http://jmlr.org/papers/v12/duchi11a.html
",6,22,685,16
C:\Users\vaano\python_projects\pytorch\torch\optim\adam.py,Adam,"
Implements Adam algorithm.

It has been proposed in `Adam: A Method for Stochastic Optimization`_.

Arguments:
    params (iterable): iterable of parameters to optimize or dicts defining
        parameter groups
    lr (float, optional): learning rate (default: 1e-3)
    betas (Tuple[float, float], optional): coefficients used for computing
        running averages of gradient and its square (default: (0.9, 0.999))
    eps (float, optional): term added to the denominator to improve
        numerical stability (default: 1e-8)
    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)
    amsgrad (boolean, optional): whether to use the AMSGrad variant of this
        algorithm from the paper `On the Convergence of Adam and Beyond`_
        (default: False)

.. _Adam\: A Method for Stochastic Optimization:
    https://arxiv.org/abs/1412.6980
.. _On the Convergence of Adam and Beyond:
    https://openreview.net/forum?id=ryQu7f-RZ
",7,28,955,21
C:\Users\vaano\python_projects\pytorch\torch\optim\adamax.py,Adamax,"
Implements Adamax algorithm (a variant of Adam based on infinity norm).

It has been proposed in `Adam: A Method for Stochastic Optimization`__.

Arguments:
    params (iterable): iterable of parameters to optimize or dicts defining
        parameter groups
    lr (float, optional): learning rate (default: 2e-3)
    betas (Tuple[float, float], optional): coefficients used for computing
        running averages of gradient and its square
    eps (float, optional): term added to the denominator to improve
        numerical stability (default: 1e-8)
    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)

__ https://arxiv.org/abs/1412.6980
",6,21,663,15
C:\Users\vaano\python_projects\pytorch\torch\optim\adamw.py,AdamW,"
Implements AdamW algorithm.

The original Adam algorithm was proposed in `Adam: A Method for Stochastic Optimization`_.
The AdamW variant was proposed in `Decoupled Weight Decay Regularization`_.

Arguments:
    params (iterable): iterable of parameters to optimize or dicts defining
        parameter groups
    lr (float, optional): learning rate (default: 1e-3)
    betas (Tuple[float, float], optional): coefficients used for computing
        running averages of gradient and its square (default: (0.9, 0.999))
    eps (float, optional): term added to the denominator to improve
        numerical stability (default: 1e-8)
    weight_decay (float, optional): weight decay coefficient (default: 1e-2)
    amsgrad (boolean, optional): whether to use the AMSGrad variant of this
        algorithm from the paper `On the Convergence of Adam and Beyond`_
        (default: False)

.. _Adam\: A Method for Stochastic Optimization:
    https://arxiv.org/abs/1412.6980
.. _Decoupled Weight Decay Regularization:
    https://arxiv.org/abs/1711.05101
.. _On the Convergence of Adam and Beyond:
    https://openreview.net/forum?id=ryQu7f-RZ
",7,31,1134,24
C:\Users\vaano\python_projects\pytorch\torch\optim\asgd.py,ASGD,"
Implements Averaged Stochastic Gradient Descent.

It has been proposed in `Acceleration of stochastic approximation by
averaging`_.

Arguments:
    params (iterable): iterable of parameters to optimize or dicts defining
        parameter groups
    lr (float, optional): learning rate (default: 1e-2)
    lambd (float, optional): decay term (default: 1e-4)
    alpha (float, optional): power for eta update (default: 0.75)
    t0 (float, optional): point at which to start averaging (default: 1e6)
    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)

.. _Acceleration of stochastic approximation by averaging:
    http://dl.acm.org/citation.cfm?id=131098
",7,23,677,16
C:\Users\vaano\python_projects\pytorch\torch\optim\lbfgs.py,LBFGS,"
Implements L-BFGS algorithm, heavily inspired by `minFunc
<https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html>`.

.. warning::
    This optimizer doesn't support per-parameter options and parameter
    groups (there can be only one).

.. warning::
    Right now all parameters have to be on a single device. This will be
    improved in the future.

.. note::
    This is a very memory intensive optimizer (it requires additional
    ``param_bytes * (history_size + 1)`` bytes). If it doesn't fit in memory
    try reducing the history size, or use a different algorithm.

Arguments:
    lr (float): learning rate (default: 1)
    max_iter (int): maximal number of iterations per optimization step
        (default: 20)
    max_eval (int): maximal number of function evaluations per optimization
        step (default: max_iter * 1.25).
    tolerance_grad (float): termination tolerance on first order optimality
        (default: 1e-5).
    tolerance_change (float): termination tolerance on function
        value/parameter changes (default: 1e-9).
    history_size (int): update history size (default: 100).
    line_search_fn (str): either 'strong_wolfe' or None (default: None).
",184,212,1186,28
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,_LRScheduler,,,,,
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,LambdaLR,"
Sets the learning rate of each parameter group to the initial lr
times a given function. When last_epoch=-1, sets initial lr as lr.

Args:
    optimizer (Optimizer): Wrapped optimizer.
    lr_lambda (function or list): A function which computes a multiplicative
        factor given an integer parameter epoch, or a list of such
        functions, one for each group in optimizer.param_groups.
    last_epoch (int): The index of last epoch. Default: -1.

Example:
    >>> # Assuming optimizer has two groups.
    >>> lambda1 = lambda epoch: epoch // 30
    >>> lambda2 = lambda epoch: 0.95 ** epoch
    >>> scheduler = LambdaLR(optimizer, lr_lambda=[lambda1, lambda2])
    >>> for epoch in range(100):
    >>>     train(...)
    >>>     validate(...)
    >>>     scheduler.step()
",158,177,779,19
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,MultiplicativeLR,"
Multiply the learning rate of each parameter group by the factor given
in the specified function. When last_epoch=-1, sets initial lr as lr.

Args:
    optimizer (Optimizer): Wrapped optimizer.
    lr_lambda (function or list): A function which computes a multiplicative
        factor given an integer parameter epoch, or a list of such
        functions, one for each group in optimizer.param_groups.
    last_epoch (int): The index of last epoch. Default: -1.

Example:
    >>> # Assuming optimizer has two groups.
    >>> lmbda = lambda epoch: 0.95
    >>> scheduler = LambdaLR(optimizer, lr_lambda=lmbda)
    >>> for epoch in range(100):
    >>>     train(...)
    >>>     validate(...)
    >>>     scheduler.step()
",237,255,720,18
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,StepLR,"
Decays the learning rate of each parameter group by gamma every
step_size epochs. Notice that such decay can happen simultaneously with
other changes to the learning rate from outside this scheduler. When
last_epoch=-1, sets initial lr as lr.

Args:
    optimizer (Optimizer): Wrapped optimizer.
    step_size (int): Period of learning rate decay.
    gamma (float): Multiplicative factor of learning rate decay.
        Default: 0.1.
    last_epoch (int): The index of last epoch. Default: -1.

Example:
    >>> # Assuming optimizer uses lr = 0.05 for all groups
    >>> # lr = 0.05     if epoch < 30
    >>> # lr = 0.005    if 30 <= epoch < 60
    >>> # lr = 0.0005   if 60 <= epoch < 90
    >>> # ...
    >>> scheduler = StepLR(optimizer, step_size=30, gamma=0.1)
    >>> for epoch in range(100):
    >>>     train(...)
    >>>     validate(...)
    >>>     scheduler.step()
",314,337,877,23
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,MultiStepLR,"
Decays the learning rate of each parameter group by gamma once the
number of epoch reaches one of the milestones. Notice that such decay can
happen simultaneously with other changes to the learning rate from outside
this scheduler. When last_epoch=-1, sets initial lr as lr.

Args:
    optimizer (Optimizer): Wrapped optimizer.
    milestones (list): List of epoch indices. Must be increasing.
    gamma (float): Multiplicative factor of learning rate decay.
        Default: 0.1.
    last_epoch (int): The index of last epoch. Default: -1.

Example:
    >>> # Assuming optimizer uses lr = 0.05 for all groups
    >>> # lr = 0.05     if epoch < 30
    >>> # lr = 0.005    if 30 <= epoch < 80
    >>> # lr = 0.0005   if epoch >= 80
    >>> scheduler = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)
    >>> for epoch in range(100):
    >>>     train(...)
    >>>     validate(...)
    >>>     scheduler.step()
",360,382,915,22
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,ExponentialLR,"
Decays the learning rate of each parameter group by gamma every epoch.
When last_epoch=-1, sets initial lr as lr.

Args:
    optimizer (Optimizer): Wrapped optimizer.
    gamma (float): Multiplicative factor of learning rate decay.
    last_epoch (int): The index of last epoch. Default: -1.
",405,412,291,7
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,CosineAnnealingLR,"
Set the learning rate of each parameter group using a cosine annealing
schedule, where :math:`\eta_{max}` is set to the initial lr and
:math:`T_{cur}` is the number of epochs since the last restart in SGDR:

.. math::
    \eta_t = \eta_{min} + \frac{1}{2}(\eta_{max} - \eta_{min})\left(1 +
    \cos\left(\frac{T_{cur}}{T_{max}}\pi\right)\right)
    T_{cur} \neq (2k+1)T_{max};\\
    \eta_{t+1} = \eta_{t} + (\eta_{max} - \eta_{min})\frac{1 -
    \cos(\frac{1}{T_{max}}\pi)}{2},
    T_{cur} = (2k+1)T_{max}.\\

When last_epoch=-1, sets initial lr as lr. Notice that because the schedule
is defined recursively, the learning rate can be simultaneously modified
outside this scheduler by other operators. If the learning rate is set
solely by this scheduler, the learning rate at each step becomes:

.. math::
    \eta_t = \eta_{min} + \frac{1}{2}(\eta_{max} - \eta_{min})\left(1 +
    \cos\left(\frac{T_{cur}}{T_{max}}\pi\right)\right)

It has been proposed in
`SGDR: Stochastic Gradient Descent with Warm Restarts`_. Note that this only
implements the cosine annealing part of SGDR, and not the restarts.

Args:
    optimizer (Optimizer): Wrapped optimizer.
    T_max (int): Maximum number of iterations.
    eta_min (float): Minimum learning rate. Default: 0.
    last_epoch (int): The index of last epoch. Default: -1.

.. _SGDR\: Stochastic Gradient Descent with Warm Restarts:
    https://arxiv.org/abs/1608.03983
",434,467,1416,33
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,ReduceLROnPlateau,"
Reduce learning rate when a metric has stopped improving.
Models often benefit from reducing the learning rate by a factor
of 2-10 once learning stagnates. This scheduler reads a metrics
quantity and if no improvement is seen for a 'patience' number
of epochs, the learning rate is reduced.

Args:
    optimizer (Optimizer): Wrapped optimizer.
    mode (str): One of `min`, `max`. In `min` mode, lr will
        be reduced when the quantity monitored has stopped
        decreasing; in `max` mode it will be reduced when the
        quantity monitored has stopped increasing. Default: 'min'.
    factor (float): Factor by which the learning rate will be
        reduced. new_lr = lr * factor. Default: 0.1.
    patience (int): Number of epochs with no improvement after
        which learning rate will be reduced. For example, if
        `patience = 2`, then we will ignore the first 2 epochs
        with no improvement, and will only decrease the LR after the
        3rd epoch if the loss still hasn't improved then.
        Default: 10.
    verbose (bool): If ``True``, prints a message to stdout for
        each update. Default: ``False``.
    threshold (float): Threshold for measuring the new optimum,
        to only focus on significant changes. Default: 1e-4.
    threshold_mode (str): One of `rel`, `abs`. In `rel` mode,
        dynamic_threshold = best * ( 1 + threshold ) in 'max'
        mode or best * ( 1 - threshold ) in `min` mode.
        In `abs` mode, dynamic_threshold = best + threshold in
        `max` mode or best - threshold in `min` mode. Default: 'rel'.
    cooldown (int): Number of epochs to wait before resuming
        normal operation after lr has been reduced. Default: 0.
    min_lr (float or list): A scalar or a list of scalars. A
        lower bound on the learning rate of all param groups
        or each group respectively. Default: 0.
    eps (float): Minimal decay applied to lr. If the difference
        between new and old lr is smaller than eps, the update is
        ignored. Default: 1e-8.

Example:
    >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)
    >>> scheduler = ReduceLROnPlateau(optimizer, 'min')
    >>> for epoch in range(10):
    >>>     train(...)
    >>>     val_loss = validate(...)
    >>>     # Note that step should be called after validate()
    >>>     scheduler.step(val_loss)
",498,544,2377,46
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,CyclicLR,"
Sets the learning rate of each parameter group according to
cyclical learning rate policy (CLR). The policy cycles the learning
rate between two boundaries with a constant frequency, as detailed in
the paper `Cyclical Learning Rates for Training Neural Networks`_.
The distance between the two boundaries can be scaled on a per-iteration
or per-cycle basis.

Cyclical learning rate policy changes the learning rate after every batch.
`step` should be called after a batch has been used for training.

This class has three built-in policies, as put forth in the paper:

* ""triangular"": A basic triangular cycle without amplitude scaling.
* ""triangular2"": A basic triangular cycle that scales initial amplitude by half each cycle.
* ""exp_range"": A cycle that scales initial amplitude by :math:`\text{gamma}^{\text{cycle iterations}}`
  at each cycle iteration.

This implementation was adapted from the github repo: `bckenstler/CLR`_

Args:
    optimizer (Optimizer): Wrapped optimizer.
    base_lr (float or list): Initial learning rate which is the
        lower boundary in the cycle for each parameter group.
    max_lr (float or list): Upper learning rate boundaries in the cycle
        for each parameter group. Functionally,
        it defines the cycle amplitude (max_lr - base_lr).
        The lr at any cycle is the sum of base_lr
        and some scaling of the amplitude; therefore
        max_lr may not actually be reached depending on
        scaling function.
    step_size_up (int): Number of training iterations in the
        increasing half of a cycle. Default: 2000
    step_size_down (int): Number of training iterations in the
        decreasing half of a cycle. If step_size_down is None,
        it is set to step_size_up. Default: None
    mode (str): One of {triangular, triangular2, exp_range}.
        Values correspond to policies detailed above.
        If scale_fn is not None, this argument is ignored.
        Default: 'triangular'
    gamma (float): Constant in 'exp_range' scaling function:
        gamma**(cycle iterations)
        Default: 1.0
    scale_fn (function): Custom scaling policy defined by a single
        argument lambda function, where
        0 <= scale_fn(x) <= 1 for all x >= 0.
        If specified, then 'mode' is ignored.
        Default: None
    scale_mode (str): {'cycle', 'iterations'}.
        Defines whether scale_fn is evaluated on
        cycle number or cycle iterations (training
        iterations since start of cycle).
        Default: 'cycle'
    cycle_momentum (bool): If ``True``, momentum is cycled inversely
        to learning rate between 'base_momentum' and 'max_momentum'.
        Default: True
    base_momentum (float or list): Lower momentum boundaries in the cycle
        for each parameter group. Note that momentum is cycled inversely
        to learning rate; at the peak of a cycle, momentum is
        'base_momentum' and learning rate is 'max_lr'.
        Default: 0.8
    max_momentum (float or list): Upper momentum boundaries in the cycle
        for each parameter group. Functionally,
        it defines the cycle amplitude (max_momentum - base_momentum).
        The momentum at any cycle is the difference of max_momentum
        and some scaling of the amplitude; therefore
        base_momentum may not actually be reached depending on
        scaling function. Note that momentum is cycled inversely
        to learning rate; at the start of a cycle, momentum is 'max_momentum'
        and learning rate is 'base_lr'
        Default: 0.9
    last_epoch (int): The index of the last batch. This parameter is used when
        resuming a training job. Since `step()` should be invoked after each
        batch instead of after each epoch, this number represents the total
        number of *batches* computed, not the total number of epochs computed.
        When last_epoch=-1, the schedule is started from the beginning.
        Default: -1

Example:
    >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)
    >>> scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1)
    >>> data_loader = torch.utils.data.DataLoader(...)
    >>> for epoch in range(10):
    >>>     for batch in data_loader:
    >>>         train_batch(...)
    >>>         scheduler.step()


.. _Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186
.. _bckenstler/CLR: https://github.com/bckenstler/CLR
",669,758,4459,89
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,CosineAnnealingWarmRestarts,"
Set the learning rate of each parameter group using a cosine annealing
schedule, where :math:`\eta_{max}` is set to the initial lr, :math:`T_{cur}`
is the number of epochs since the last restart and :math:`T_{i}` is the number
of epochs between two warm restarts in SGDR:

.. math::
    \eta_t = \eta_{min} + \frac{1}{2}(\eta_{max} - \eta_{min})\left(1 +
    \cos\left(\frac{T_{cur}}{T_{i}}\pi\right)\right)

When :math:`T_{cur}=T_{i}`, set :math:`\eta_t = \eta_{min}`.
When :math:`T_{cur}=0` after restart, set :math:`\eta_t=\eta_{max}`.

It has been proposed in
`SGDR: Stochastic Gradient Descent with Warm Restarts`_.

Args:
    optimizer (Optimizer): Wrapped optimizer.
    T_0 (int): Number of iterations for the first restart.
    T_mult (int, optional): A factor increases :math:`T_{i}` after a restart. Default: 1.
    eta_min (float, optional): Minimum learning rate. Default: 0.
    last_epoch (int, optional): The index of last epoch. Default: -1.

.. _SGDR\: Stochastic Gradient Descent with Warm Restarts:
    https://arxiv.org/abs/1608.03983
",892,916,1055,24
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,OneCycleLR,"
Sets the learning rate of each parameter group according to the
1cycle learning rate policy. The 1cycle policy anneals the learning
rate from an initial learning rate to some maximum learning rate and then
from that maximum learning rate to some minimum learning rate much lower
than the initial learning rate.
This policy was initially described in the paper `Super-Convergence:
Very Fast Training of Neural Networks Using Large Learning Rates`_.

The 1cycle learning rate policy changes the learning rate after every batch.
`step` should be called after a batch has been used for training.

This scheduler is not chainable.

Note also that the total number of steps in the cycle can be determined in one
of two ways (listed in order of precedence):

#. A value for total_steps is explicitly provided.
#. A number of epochs (epochs) and a number of steps per epoch
   (steps_per_epoch) are provided.
   In this case, the number of total steps is inferred by
   total_steps = epochs * steps_per_epoch

You must either provide a value for total_steps or provide a value for both
epochs and steps_per_epoch.

Args:
    optimizer (Optimizer): Wrapped optimizer.
    max_lr (float or list): Upper learning rate boundaries in the cycle
        for each parameter group.
    total_steps (int): The total number of steps in the cycle. Note that
        if a value is provided here, then it must be inferred by providing
        a value for epochs and steps_per_epoch.
        Default: None
    epochs (int): The number of epochs to train for. This is used along
        with steps_per_epoch in order to infer the total number of steps in the cycle
        if a value for total_steps is not provided.
        Default: None
    steps_per_epoch (int): The number of steps per epoch to train for. This is
        used along with epochs in order to infer the total number of steps in the
        cycle if a value for total_steps is not provided.
        Default: None
    pct_start (float): The percentage of the cycle (in number of steps) spent
        increasing the learning rate.
        Default: 0.3
    anneal_strategy (str): {'cos', 'linear'}
        Specifies the annealing strategy: ""cos"" for cosine annealing, ""linear"" for
        linear annealing.
        Default: 'cos'
    cycle_momentum (bool): If ``True``, momentum is cycled inversely
        to learning rate between 'base_momentum' and 'max_momentum'.
        Default: True
    base_momentum (float or list): Lower momentum boundaries in the cycle
        for each parameter group. Note that momentum is cycled inversely
        to learning rate; at the peak of a cycle, momentum is
        'base_momentum' and learning rate is 'max_lr'.
        Default: 0.85
    max_momentum (float or list): Upper momentum boundaries in the cycle
        for each parameter group. Functionally,
        it defines the cycle amplitude (max_momentum - base_momentum).
        Note that momentum is cycled inversely
        to learning rate; at the start of a cycle, momentum is 'max_momentum'
        and learning rate is 'base_lr'
        Default: 0.95
    div_factor (float): Determines the initial learning rate via
        initial_lr = max_lr/div_factor
        Default: 25
    final_div_factor (float): Determines the minimum learning rate via
        min_lr = initial_lr/final_div_factor
        Default: 1e4
    last_epoch (int): The index of the last batch. This parameter is used when
        resuming a training job. Since `step()` should be invoked after each
        batch instead of after each epoch, this number represents the total
        number of *batches* computed, not the total number of epochs computed.
        When last_epoch=-1, the schedule is started from the beginning.
        Default: -1

Example:
    >>> data_loader = torch.utils.data.DataLoader(...)
    >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)
    >>> scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(data_loader), epochs=10)
    >>> for epoch in range(10):
    >>>     for batch in data_loader:
    >>>         train_batch(...)
    >>>         scheduler.step()


.. _Super-Convergence\: Very Fast Training of Neural Networks Using Large Learning Rates:
    https://arxiv.org/abs/1708.07120
",1011,1099,4290,88
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,_enable_get_lr_call,,,,,
C:\Users\vaano\python_projects\pytorch\torch\optim\lr_scheduler.py,_enable_get_lr_call,,,,,
C:\Users\vaano\python_projects\pytorch\torch\optim\optimizer.py,_RequiredParameter,"
Singleton class representing a required parameter for an Optimizer.
",10,11,67,1
C:\Users\vaano\python_projects\pytorch\torch\optim\optimizer.py,Optimizer,"
Base class for all optimizers.

.. warning::
    Parameters need to be specified as collections that have a deterministic
    ordering that is consistent between runs. Examples of objects that don't
    satisfy those properties are sets and iterators over values of dictionaries.

Arguments:
    params (iterable): an iterable of :class:`torch.Tensor` s or
        :class:`dict` s. Specifies what Tensors should be optimized.
    defaults: (dict): a dict containing default values of optimization
        options (used when a parameter group doesn't specify them).
",18,30,564,12
C:\Users\vaano\python_projects\pytorch\torch\optim\rmsprop.py,RMSprop,"
Implements RMSprop algorithm.

Proposed by G. Hinton in his
`course <http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf>`_.

The centered version first appears in `Generating Sequences
With Recurrent Neural Networks <https://arxiv.org/pdf/1308.0850v5.pdf>`_.

The implementation here takes the square root of the gradient average before
adding epsilon (note that TensorFlow interchanges these two operations). The effective
learning rate is thus :math:`\alpha/(\sqrt{v} + \epsilon)` where :math:`\alpha`
is the scheduled learning rate and :math:`v` is the weighted moving average
of the squared gradient.

Arguments:
    params (iterable): iterable of parameters to optimize or dicts defining
        parameter groups
    lr (float, optional): learning rate (default: 1e-2)
    momentum (float, optional): momentum factor (default: 0)
    alpha (float, optional): smoothing constant (default: 0.99)
    eps (float, optional): term added to the denominator to improve
        numerical stability (default: 1e-8)
    centered (bool, optional) : if ``True``, compute the centered RMSProp,
        the gradient is normalized by an estimation of its variance
    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)
",6,31,1249,25
C:\Users\vaano\python_projects\pytorch\torch\optim\rprop.py,Rprop,"
Implements the resilient backpropagation algorithm.

Arguments:
    params (iterable): iterable of parameters to optimize or dicts defining
        parameter groups
    lr (float, optional): learning rate (default: 1e-2)
    etas (Tuple[float, float], optional): pair of (etaminus, etaplis), that
        are multiplicative increase and decrease factors
        (default: (0.5, 1.2))
    step_sizes (Tuple[float, float], optional): a pair of minimal and
        maximal allowed step sizes (default: (1e-6, 50))
",6,17,510,11
C:\Users\vaano\python_projects\pytorch\torch\optim\sgd.py,SGD,"
Implements stochastic gradient descent (optionally with momentum).

Nesterov momentum is based on the formula from
`On the importance of initialization and momentum in deep learning`__.

Args:
    params (iterable): iterable of parameters to optimize or dicts defining
        parameter groups
    lr (float): learning rate
    momentum (float, optional): momentum factor (default: 0)
    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)
    dampening (float, optional): dampening for momentum (default: 0)
    nesterov (bool, optional): enables Nesterov momentum (default: False)

Example:
    >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)
    >>> optimizer.zero_grad()
    >>> loss_fn(model(input), target).backward()
    >>> optimizer.step()

__ http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf

.. note::
    The implementation of SGD with Momentum/Nesterov subtly differs from
    Sutskever et. al. and implementations in some other frameworks.

    Considering the specific case of Momentum, the update can be written as

    .. math::
              v_{t+1} = \mu * v_{t} + g_{t+1} \\
              p_{t+1} = p_{t} - lr * v_{t+1}

    where p, g, v and :math:`\mu` denote the parameters, gradient,
    velocity, and momentum respectively.

    This is in contrast to Sutskever et. al. and
    other frameworks which employ an update of the form

    .. math::
         v_{t+1} = \mu * v_{t} + lr * g_{t+1} \\
         p_{t+1} = p_{t} - v_{t+1}

    The Nesterov version is analogously modified.
",6,49,1556,43
C:\Users\vaano\python_projects\pytorch\torch\optim\sparse_adam.py,SparseAdam,"
Implements lazy version of Adam algorithm suitable for sparse tensors.

In this variant, only moments that show up in the gradient get updated, and
only those portions of the gradient get applied to the parameters.

Arguments:
    params (iterable): iterable of parameters to optimize or dicts defining
        parameter groups
    lr (float, optional): learning rate (default: 1e-3)
    betas (Tuple[float, float], optional): coefficients used for computing
        running averages of gradient and its square (default: (0.9, 0.999))
    eps (float, optional): term added to the denominator to improve
        numerical stability (default: 1e-8)

.. _Adam\: A Method for Stochastic Optimization:
    https://arxiv.org/abs/1412.6980
",7,23,732,16
C:\Users\vaano\python_projects\pytorch\torch\quantization\fake_quantize.py,FakeQuantize,"
Simulate the quantize and dequantize operations in training time.
The output of this module is given by

x_out = (clamp(round(x/scale + zero_point), quant_min, quant_max)-zero_point)*scale



* :attr:`scale` defines the scale factor used for quantization.

* :attr:`zero_point` specifies the quantized value to which 0 in floating point maps to

* :attr:`quant_min` specifies the minimum allowable quantized value.

* :attr:`quant_max` specifies the maximum allowable quantized value.

* :attr:`fake_quant_enable` controls the application of fake quantization on tensors, note that
  statistics can still be updated.

* :attr:`observer_enable` controls statistics collection on tensors

* :attr:`dtype` specifies the quantized dtype that is being emulated with fake-quantization,
                allowable values are torch.qint8 and torch.quint8. The values of quant_min and
                quant_max should be chosen to be consistent with the dtype


Args:
    observer (module): Module for observing statistics on input tensors and calculating scale
                       and zero-point.
    quant_min (int): The minimum allowable quantized value.
    quant_max (int): The maximum allowable quantized value.
    observer_kwargs (optional): Arguments for the observer module

Attributes:
    observer (Module): User provided module that collects statistics on the input tensor and
                       provides a method to calculate scale and zero-point.
",7,42,1458,35
C:\Users\vaano\python_projects\pytorch\torch\quantization\observer.py,ObserverBase,"
Base observer Module.
Any observer implementation should derive from this class.

Concrete observers should follow the same API. In forward, they will update
the statistics of the observed Tensor. And they should provide a
`calculate_qparams` function that computes the quantization parameters given
the collected statistics.

Args:
    dtype: Quantized data type
",46,56,363,10
C:\Users\vaano\python_projects\pytorch\torch\quantization\observer.py,_ObserverBase,"
Internal common base for all qint/quint8 observers.

This base is for commonly used paramters used internally.
Users should use `~torch.quantization.observer.ObserverBase` as a base class
for custom observers.

Args:
    dtype: Quantized data type.
    qscheme: Quantization scheme to be used.
    reduce_range: Reduces the range of the quantized data type by 1 bit.
                  This is sometimes required to avoid instruction overflow.

.. warning::

    :attr:`dtype` can only take ``torch.qint8`` or ``torch.quint8``.

.. warning::

    :attr:`qscheme` can only take one of the following options:

    - ``torch.per_tensor_affine``
    - ``torch.per_tensor_symmetric``
    - ``torch.per_channel_affine``
    - ``torch.per_channel_symmetric``
",81,105,750,24
C:\Users\vaano\python_projects\pytorch\torch\quantization\observer.py,MinMaxObserver,"
Observer module for computing the quantization parameters based on the
running min and max values.

This observer uses the tensor min/max statistics to compute the quantization
parameters. The module records the running minimum and maximum of incoming
tensors, and uses this statistic to compute the quantization parameters.

Args:
    dtype: Quantized data type
    qscheme: Quantization scheme to be used
    reduce_range: Reduces the range of the quantized data type by 1 bit

Given running min/max as :math:`x_\text{min}` and :math:`x_\text{max}`,
scale :math:`s` and zero point :math:`z` are computed as:

The running minimum/maximum :math:`x_\text{min/max}` is computed as:

.. math::

    \begin{array}{ll}
    x_\text{min} &= \begin{cases}
        \min(X) & \text{if~}x_\text{min} = \text{None} \\
        \min\left(x_\text{min}, \min(X)\right) & \text{otherwise}
    \end{cases}\\
    x_\text{max} &= \begin{cases}
        \max(X) & \text{if~}x_\text{max} = \text{None} \\
        \max\left(x_\text{max}, \max(X)\right) & \text{otherwise}
    \end{cases}\\
    \end{array}

where :math:`X` is the observed tensor.

The scale :math:`s` and zero point :math:`z` are then computed as:

.. math::

    \begin{aligned}
        \text{if Symmetric:}&\\
        &s = 2 \max(|x_\text{min}|, x_\text{max}) /
            \left( Q_\text{max} - Q_\text{min} \right) \\
        &z = \begin{cases}
            0 & \text{if dtype is qint8} \\
            128 & \text{otherwise}
        \end{cases}\\
        \text{Otherwise:}&\\
            &s = \left( x_\text{max} - x_\text{min}  \right ) /
                \left( Q_\text{max} - Q_\text{min} \right ) \\
            &z = Q_\text{min} - \text{round}(x_\text{min} / s)
    \end{aligned}

where :math:`Q_\text{min}` and :math:`Q_\text{max}` are the minimum and
maximum of the quantized data type.

.. warning:: Only works with ``torch.per_tensor_symmetric`` quantization scheme

.. warning:: :attr:`dtype` can only take ``torch.qint8`` or ``torch.quint8``.

.. note:: If the running minimum equals to the running maximum, the scale
          and zero_point are set to 1.0 and 0.
",226,285,2120,59
C:\Users\vaano\python_projects\pytorch\torch\quantization\observer.py,MovingAverageMinMaxObserver,"
Observer module for computing the quantization parameters based on the
moving average of the min and max values.

This observer computes the quantization parameters based on the moving
averages of minimums and maximums of the incoming tensors. The module
records the average minimum and maximum of incoming tensors, and uses this
statistic to compute the quantization parameters.

Args:
    averaging_constant: Averaging constant for min/max.
    dtype: Quantized data type
    qscheme: Quantization scheme to be used
    reduce_range: Reduces the range of the quantized data type by 1 bit

The moving average min/max is computed as follows

.. math::

    \begin{array}{ll}
            x_\text{min} = \begin{cases}
                \min(X) & \text{if~}x_\text{min} = \text{None} \\
                (1 - c) x_\text{min} + c \min(X) & \text{otherwise}
            \end{cases}\\
            x_\text{max} = \begin{cases}
                \max(X) & \text{if~}x_\text{max} = \text{None} \\
                (1 - c) x_\text{max} + c \max(X) & \text{otherwise}
            \end{cases}\\
    \end{array}

where :math:`x_\text{min/max}` is the running average min/max, :math:`X` is
is the incoming tensor, and :math:`c` is the ``averaging_constant``.

The scale and zero point are then computed as in
:class:`~torch.quantization.observer.MinMaxObserver`.

.. note:: Only works with ``torch.per_tensor_affine`` quantization shceme.

.. note:: If the running minimum equals to the running maximum, the scale
          and zero_point are set to 1.0 and 0.
",356,395,1540,39
C:\Users\vaano\python_projects\pytorch\torch\quantization\observer.py,PerChannelMinMaxObserver,"
Observer module for computing the quantization parameters based on the
running per channel min and max values.

This observer uses the tensor min/max statistics to compute the per channel
quantization parameters. The module records the running minimum and maximum
of incoming tensors, and uses this statistic to compute the quantization
parameters.

Args:
    ch_axis: Channel axis
    dtype: Quantized data type
    qscheme: Quantization scheme to be used
    reduce_range: Reduces the range of the quantized data type by 1 bit

The quantization parameters are computed the same way as in
:class:`~torch.quantization.observer.MinMaxObserver`, with the difference
that the running min/max values are stored per channel.
Scales and zero points are thus computed per channel as well.

.. note:: If the running minimum equals to the running maximum, the scales
          and zero_points are set to 1.0 and 0.
",419,440,905,21
C:\Users\vaano\python_projects\pytorch\torch\quantization\observer.py,MovingAveragePerChannelMinMaxObserver,"
Observer module for computing the quantization parameters based on the
running per channel min and max values.

This observer uses the tensor min/max statistics to compute the per channel
quantization parameters. The module records the running minimum and maximum
of incoming tensors, and uses this statistic to compute the quantization
parameters.

Args:
    averaging_constant: Averaging constant for min/max.
    ch_axis: Channel axis
    dtype: Quantized data type
    qscheme: Quantization scheme to be used
    reduce_range: Reduces the range of the quantized data type by 1 bit

The quantization parameters are computed the same way as in
:class:`~torch.quantization.observer.MovingAverageMinMaxObserver`, with the
difference that the running min/max values are stored per channel.
Scales and zero points are thus computed per channel as well.

.. note:: If the running minimum equals to the running maximum, the scales
          and zero_points are set to 1.0 and 0.
",519,541,974,22
C:\Users\vaano\python_projects\pytorch\torch\quantization\observer.py,HistogramObserver,"
The module records the running histogram of tensor values along with
min/max values. ``calculate_qparams`` will calculate scale and zero_point.

Args:
    bins: Number of bins to use for the histogram
    upsample_rate: Factor by which the histograms are upsampled, this is
                   used to interpolate histograms with varying ranges across observations
    dtype: Quantized data type
    qscheme: Quantization scheme to be used
    reduce_range: Reduces the range of the quantized data type by 1 bit

The scale and zero point are computed as follows:

1. Create the histogram of the incoming inputs.
    The histogram is computed continuously, and the ranges per bin change
    with every new tensor observed.
2. Search the distribution in the histogram for optimal min/max values.
    The search for the min/max values ensures the minimization of the
    quantization error with respect to the floating point model.
3. Compute the scale and zero point the same way as in the
    :class:`~torch.quantization.MinMaxObserver`
",572,593,1034,21
C:\Users\vaano\python_projects\pytorch\torch\quantization\observer.py,RecordingObserver,"
The module is mainly for debug and records the tensor values during runtime.

Args:
    dtype: Quantized data type
    qscheme: Quantization scheme to be used
    reduce_range: Reduces the range of the quantized data type by 1 bit
",861,867,230,6
C:\Users\vaano\python_projects\pytorch\torch\quantization\observer.py,NoopObserver,"
Observer that doesn't do anything and just passes its configuration to the
quantized module's ``.from_float()``.

Primarily used for quantization to float16 which doesn't require determining
ranges.

Args:
    dtype: Quantized data type
",889,897,236,8
C:\Users\vaano\python_projects\pytorch\torch\quantization\observer.py,_PartialWrapper,,,,,
C:\Users\vaano\python_projects\pytorch\torch\quantization\qconfig.py,QConfig,"
Describes how to quantize a layer or a part of the network by providing
settings (observer classes) for activations and weights respectively.


Note that QConfig needs to contain observer **classes** (like MinMaxObserver) or a callable that returns
instances on invocation, not the concrete observer instances themselves.
Quantization preparation function will instantiate observers multiple times for each of the layers.


Observer classes have usually reasonable default arguments, but they can be overwritten with `with_args`
method (that behaves like functools.partial):

  my_qconfig = QConfig(activation=MinMaxObserver.with_args(dtype=torch.qint8), 
  weight=default_observer.with_args(dtype=torch.qint8))
",8,22,711,14
C:\Users\vaano\python_projects\pytorch\torch\quantization\qconfig.py,QConfigDynamic,"
Describes how to dynamically quantize a layer or a part of the network by providing
settings (observer classe) for weights.

It's like QConfig, but for dynamic quantization.

Note that QConfigDynamic needs to contain observer **classes** (like MinMaxObserver) or a callable that returns
instances on invocation, not the concrete observer instances themselves.
Quantization function will instantiate observers multiple times for each of the layers.

Observer classes have usually reasonable default arguments, but they can be overwritten with `with_args`
method (that behaves like functools.partial):

  my_qconfig = QConfigDynamic(weight=default_observer.with_args(dtype=torch.qint8))
",42,55,684,13
C:\Users\vaano\python_projects\pytorch\torch\quantization\stubs.py,QuantStub,"
Quantize stub module, before calibration, this is same as an observer,
it will be swapped as `nnq.Quantize` in `convert`.

Args:
    qconfig: quantization configuration for the tensor,
        if qconfig is not provided, we will get qconfig from parent modules
",5,11,260,6
C:\Users\vaano\python_projects\pytorch\torch\quantization\stubs.py,DeQuantStub,"
Dequantize stub module, before calibration, this is same as identity,
this will be swapped as `nnq.DeQuantize` in `convert`.
",22,24,124,2
C:\Users\vaano\python_projects\pytorch\torch\quantization\stubs.py,QuantWrapper,"
A wrapper class that wraps the input module, adds QuantStub and
DeQuantStub and surround the call to module with call to quant and dequant
modules.

This is used by the `quantization` utility functions to add the quant and
dequant modules, before `convert` function `QuantStub` will just be observer,
it observes the input tensor, after `convert`, `QuantStub`
will be swapped to `nnq.Quantize` which does actual quantization. Similarly
for `DeQuantStub`.
",33,42,454,9
C:\Users\vaano\python_projects\pytorch\torch\quantization\_quantize_script.py,ConvPackedParams,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\checkpoint.py,CheckpointFunction,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\cpp_extension.py,BuildExtension,"
A custom :mod:`setuptools` build extension .

This :class:`setuptools.build_ext` subclass takes care of passing the
minimum required compiler flags (e.g. ``-std=c++14``) as well as mixed
C++/CUDA compilation (and support for CUDA files in general).

When using :class:`BuildExtension`, it is allowed to supply a dictionary
for ``extra_compile_args`` (rather than the usual list) that maps from
languages (``cxx`` or ``nvcc``) to a list of additional compiler flags to
supply to the compiler. This makes it possible to supply different flags to
the C++ and CUDA compiler during mixed compilation.
",224,235,595,11
C:\Users\vaano\python_projects\pytorch\torch\utils\file_baton.py,FileBaton,"
A primitive, file-based synchronization utility.
",13,14,48,1
C:\Users\vaano\python_projects\pytorch\torch\utils\hooks.py,RemovableHandle,"
A handle which provides the capability to remove a hook.
",8,9,56,1
C:\Users\vaano\python_projects\pytorch\torch\utils\mkldnn.py,MkldnnLinear,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\mkldnn.py,MkldnnConv2d,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\mkldnn.py,MkldnnBatchNorm2d,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\throughput_benchmark.py,ExecutionStats,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\throughput_benchmark.py,ThroughputBenchmark,"
This class is a wrapper around a c++ component throughput_benchmark::ThroughputBenchmark
responsible for executing a PyTorch module (nn.Module or ScriptModule)
under an inference server like load. It can emulate multiple calling threads
to a single module provided. In the future we plan to enhance this component
to support inter and intra-op parallelism as well as multiple models
running in a single process.

Please note that even though nn.Module is supported, it might incur an overhead
from the need to hold GIL every time we execute Python code or pass around
inputs as Python objects. As soon as you have a ScriptModule version of your
model for inference deployment it is better to switch to using it in this
benchmark.

Example::

    >>> from torch.utils import ThroughputBenchmark
    >>> bench = ThroughputBenchmark(my_module)
    >>> # Pre-populate benchmark's data set with the inputs
    >>> for input in inputs:
        # Both args and kwargs work, same as any PyTorch Module / ScriptModule
        bench.add_input(input[0], x2=input[1])
    >>> Inputs supplied above are randomly used during the execution
    >>> stats = bench.benchmark(
            num_calling_threads=4,
            num_warmup_iters = 100,
            num_iters = 1000,
        )
    >>> print(""Avg latency (ms): {}"".format(stats.latency_avg_ms))
    >>> print(""Number of iterations: {}"".format(stats.num_iters))
",63,92,1401,29
C:\Users\vaano\python_projects\pytorch\torch\utils\_cpp_extension_versioner.py,ExtensionVersioner,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\backcompat\__init__.py,Warning,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\data\dataloader.py,_DatasetKind,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\data\dataloader.py,_InfiniteConstantSampler,"
Analogous to ``itertools.repeat(None, None)``.
Used as sampler for :class:`~torch.utils.data.IterableDataset`.

Arguments:
    data_source (Dataset): dataset to sample from
",45,50,172,5
C:\Users\vaano\python_projects\pytorch\torch\utils\data\dataloader.py,DataLoader,"
Data loader. Combines a dataset and a sampler, and provides an iterable over
the given dataset.

The :class:`~torch.utils.data.DataLoader` supports both map-style and
iterable-style datasets with single- or multi-process loading, customizing
loading order and optional automatic batching (collation) and memory pinning.

See :py:mod:`torch.utils.data` documentation page for more details.

Arguments:
    dataset (Dataset): dataset from which to load the data.
    batch_size (int, optional): how many samples per batch to load
        (default: ``1``).
    shuffle (bool, optional): set to ``True`` to have the data reshuffled
        at every epoch (default: ``False``).
    sampler (Sampler, optional): defines the strategy to draw samples from
        the dataset. If specified, :attr:`shuffle` must be ``False``.
    batch_sampler (Sampler, optional): like :attr:`sampler`, but returns a batch of
        indices at a time. Mutually exclusive with :attr:`batch_size`,
        :attr:`shuffle`, :attr:`sampler`, and :attr:`drop_last`.
    num_workers (int, optional): how many subprocesses to use for data
        loading. ``0`` means that the data will be loaded in the main process.
        (default: ``0``)
    collate_fn (callable, optional): merges a list of samples to form a
        mini-batch of Tensor(s).  Used when using batched loading from a
        map-style dataset.
    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors
        into CUDA pinned memory before returning them.  If your data elements
        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,
        see the example below.
    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,
        if the dataset size is not divisible by the batch size. If ``False`` and
        the size of dataset is not divisible by the batch size, then the last batch
        will be smaller. (default: ``False``)
    timeout (numeric, optional): if positive, the timeout value for collecting a batch
        from workers. Should always be non-negative. (default: ``0``)
    worker_init_fn (callable, optional): If not ``None``, this will be called on each
        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as
        input, after seeding and before data loading. (default: ``None``)


.. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`
             cannot be an unpicklable object, e.g., a lambda function. See
             :ref:`multiprocessing-best-practices` on more details related
             to multiprocessing in PyTorch.

.. note:: ``len(dataloader)`` heuristic is based on the length of the sampler used.
          When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,
          ``len(dataset)`` (if implemented) is returned instead, regardless
          of multi-process loading configurations, because PyTorch trust
          user :attr:`dataset` code in correctly handling multi-process
          loading to avoid duplicate data. See `Dataset Types`_ for more
          details on these two types of datasets and how
          :class:`~torch.utils.data.IterableDataset` interacts with `Multi-process data loading`_.
",61,115,3249,54
C:\Users\vaano\python_projects\pytorch\torch\utils\data\dataloader.py,_BaseDataLoaderIter,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\data\dataloader.py,_SingleProcessDataLoaderIter,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\data\dataloader.py,_MultiProcessingDataLoaderIter,"
Iterates once over the DataLoader's dataset, as specified by the sampler
NOTE [ Data Loader Multiprocessing Shutdown Logic ]
    
    Preliminary:
    
    Our data model looks like this (queues are indicated with curly brackets):
    
                   main process                              ||
                        |                                    ||
                  {index_queue}                              ||
                        |                                    ||
                 worker processes                            ||     DATA
                        |                                    ||
               {worker_result_queue}                         ||     FLOW
                        |                                    ||
         pin_memory_thread of main process                   ||   DIRECTION
                        |                                    ||
                  {data_queue}                               ||
                        |                                    ||
                   data output                               \/
    
    P.S. `worker_result_queue` and `pin_memory_thread` part may be omitted if
         `pin_memory=False`.
    
    
    Terminating multiprocessing logic requires very careful design. In
    particular, we need to make sure that
    
      1. The iterator gracefully exits the workers when its last reference is
         gone or it is depleted.
    
         In this case, the workers should be gracefully exited because the
         main process may still need to continue to run, and we want cleaning
         up code in the workers to be executed (e.g., releasing GPU memory).
         Naturally, we implement the shutdown logic in `__del__` of
         DataLoaderIterator.
    
         We delay the discussion on the logic in this case until later.
    
      2. The iterator exits the workers when the loader process and/or worker
         processes exits normally or with error.
    
         We set all workers and `pin_memory_thread` to have `daemon=True`.
    
         You may ask, why can't we make the workers non-daemonic, and
         gracefully exit using the same logic as we have in `__del__` when the
         iterator gets deleted (see 1 above)?
    
         First of all, `__del__` is **not** guaranteed to be called when
         interpreter exits. Even if it is called, by the time it executes,
         many Python core library resources may alreay be freed, and even
         simple things like acquiring an internal lock of a queue may hang.
         Therefore, in this case, we actually need to prevent `__del__` from
         being executed, and rely on the automatic termination of daemonic
         children. Thus, we register an `atexit` hook that sets a global flag
         `_utils.python_exit_status`. Since `atexit` hooks are executed in the
         reverse order of registration, we are guaranteed that this flag is
         set before library resources we use are freed. (Hooks freeing those
         resources are registered at importing the Python core libraries at
         the top of this file.) So in `__del__`, we check if
         `_utils.python_exit_status` is set or `None` (freed), and perform
         no-op if so.
    
         Another problem with `__del__` is also related to the library cleanup
         calls. When a process ends, it shuts the all its daemonic children
         down with a SIGTERM (instead of joining them without a timeout).
         Simiarly for threads, but by a different mechanism. This fact,
         together with a few implementation details of multiprocessing, forces
         us to make workers daemonic. All of our problems arise when a
         DataLoader is used in a subprocess, and are caused by multiprocessing
         code which looks more or less like this:
    
             try:
                 your_function_using_a_dataloader()
             finally:
                 multiprocessing.util._exit_function()
    
         The joining/termination mentioned above happens inside
         `_exit_function()`. Now, if `your_function_using_a_dataloader()`
         throws, the stack trace stored in the exception will prevent the
         frame which uses `DataLoaderIter` to be freed. If the frame has any
         reference to the `DataLoaderIter` (e.g., in a method of the iter),
         its  `__del__`, which starts the shutdown procedure, will not be
         called. That, in turn, means that workers aren't notified. Attempting
         to join in `_exit_function` will then result in a hang.
    
         For context, `_exit_function` is also registered as an `atexit` call.
         So it is unclear to me (@ssnl) why this is needed in a finally block.
         The code dates back to 2008 and there is no comment on the original
         PEP 371 or patch https://bugs.python.org/issue3050 (containing both
         the finally block and the `atexit` registration) that explains this.
    
         Another choice is to just shutdown workers with logic in 1 above
         whenever we see an error in `next`. This isn't ideal because
           a. It prevents users from using try-catch to resume data loading.
           b. It doesn't prevent hanging if users have references to the
              iterator.
    
      3. All processes exit if any of them die unexpectedly by fatal signals.
    
         As shown above, the workers are set as daemonic children of the main
         process. However, automatic cleaning-up of such child processes only
         happens if the parent process exits gracefully (e.g., not via fatal
         signals like SIGKILL). So we must ensure that each process will exit
         even the process that should send/receive data to/from it were
         killed, i.e.,
    
           a. A process won't hang when getting from a queue.
    
              Even with carefully designed data dependencies (i.e., a `put()`
              always corresponding to a `get()`), hanging on `get()` can still
              happen when data in queue is corrupted (e.g., due to
              `cancel_join_thread` or unexpected exit).
    
              For child exit, we set a timeout whenever we try to get data
              from `data_queue`, and check the workers' status on each timeout
              and error.
              See `_DataLoaderiter._get_batch()` and
              `_DataLoaderiter._try_get_data()` for details.
    
              Additionally, for child exit on non-Windows platforms, we also
              register a SIGCHLD handler (which is supported on Windows) on
              the main process, which checks if any of the workers fail in the
              (Python) handler. This is more efficient and faster in detecting
              worker failures, compared to only using the above mechanism.
              See `DataLoader.cpp` and `_utils/signal_handling.py` for details.
    
              For `.get()` calls where the sender(s) is not the workers, we
              guard them with timeouts, and check the status of the sender
              when timeout happens:
                + in the workers, the `_utils.worker.ManagerWatchdog` class
                  checks the status of the main process.
                + if `pin_memory=True`, when getting from `pin_memory_thread`,
                  check `pin_memory_thread` status periodically until `.get()`
                  returns or see that `pin_memory_thread` died.
    
           b. A process won't hang when putting into a queue;
    
              We use `mp.Queue` which has a separate background thread to put
              objects from an unbounded buffer array. The background thread is
              daemonic and usually automatically joined when the process
              exits.
    
              However, in case that the receiver has ended abruptly while
              reading from the pipe, the join will hang forever. Therefore,
              for both `worker_result_queue` (worker -> main process/pin_memory_thread)
              and each `index_queue` (main process -> worker), we use
              `q.cancel_join_thread()` in sender process before any `q.put` to
              prevent this automatic join.
    
              Moreover, having all queues called `cancel_join_thread` makes
              implementing graceful shutdown logic in `__del__` much easier.
              It won't need to get from any queue, which would also need to be
              guarded by periodic status checks.
    
              Nonetheless, `cancel_join_thread` must only be called when the
              queue is **not** going to be read from or write into by another
              process, because it may hold onto a lock or leave corrupted data
              in the queue, leading other readers/writers to hang.
    
              `pin_memory_thread`'s `data_queue` is a `queue.Queue` that does
              a blocking `put` if the queue is full. So there is no above
              problem, but we do need to wrap the `put` in a loop that breaks
              not only upon success, but also when the main process stops
              reading, i.e., is shutting down.
    
    
    Now let's get back to 1:
      how we gracefully exit the workers when the last reference to the
      iterator is gone.
    
    To achieve this, we implement the following logic along with the design
    choices mentioned above:
    
    `workers_done_event`:
      A `multiprocessing.Event` shared among the main process and all worker
      processes. This is used to signal the workers that the iterator is
      shutting down. After it is set, they will not send processed data to
      queues anymore, and only wait for the final `None` before exiting.
      `done_event` isn't strictly needed. I.e., we can just check for `None`
      from the input queue, but it allows us to skip wasting resources
      processing data if we are already shutting down.
    
    `pin_memory_thread_done_event`:
      A `threading.Event` for a similar purpose to that of
      `workers_done_event`, but is for the `pin_memory_thread`. The reason
      that separate events are needed is that `pin_memory_thread` reads from
      the output queue of the workers. But the workers, upon seeing that
      `workers_done_event` is set, only wants to see the final `None`, and is
      not required to flush all data in the output queue (e.g., it may call
      `cancel_join_thread` on that queue if its `IterableDataset` iterator
      happens to exhaust coincidentally, which is out of the control of the
      main process). Thus, since we will exit `pin_memory_thread` before the
      workers (see below), two separete events are used.
    
    NOTE: In short, the protocol is that the main process will set these
          `done_event`s and then the corresponding processes/threads a `None`,
          and that they may exit at any time after receiving the `None`.
    
    NOTE: Using `None` as the final signal is valid, since normal data will
          always be a 2-tuple with the 1st element being the index of the data
          transferred (different from dataset index/key), and the 2nd being
          either the dataset key or the data sample (depending on which part
          of the data model the queue is at).
    
    [ worker processes ]
      While loader process is alive:
        Get from `index_queue`.
          If get anything else,
             Check `workers_done_event`.
               If set, continue to next iteration
                       i.e., keep getting until see the `None`, then exit.
               Otherwise, process data:
                   If is fetching from an `IterableDataset` and the iterator
                       is exhausted, send an `_IterableDatasetStopIteration`
                       object to signal iteration end. The main process, upon
                       receiving such an object, will send `None` to this
                       worker and not use the corresponding `index_queue`
                       anymore.
          If timed out,
             No matter `workers_done_event` is set (still need to see `None`)
             or not, must continue to next iteration.
      (outside loop)
      If `workers_done_event` is set,  (this can be False with `IterableDataset`)
        `data_queue.cancel_join_thread()`.  (Everything is ending here:
                                             main process won't read from it;
                                             other workers will also call
                                             `cancel_join_thread`.)
    
    [ pin_memory_thread ]
      No need to check main thread. If this thread is alive, the main loader
      thread must be alive, because this thread is set as daemonic.
      While `pin_memory_thread_done_event` is not set:
        Get from `index_queue`.
          If timed out, continue to get in the next iteration.
          Otherwise, process data.
          While `pin_memory_thread_done_event` is not set:
            Put processed data to `data_queue` (a `queue.Queue` with blocking put)
            If timed out, continue to put in the next iteration.
            Otherwise, break, i.e., continuing to the out loop.
    
      NOTE: we don't check the status of the main thread because
              1. if the process is killed by fatal signal, `pin_memory_thread`
                 ends.
              2. in other cases, either the cleaning-up in __del__ or the
                 automatic exit of daemonic thread will take care of it.
                 This won't busy-wait either because `.get(timeout)` does not
                 busy-wait.
    
    [ main process ]
      In the DataLoader Iter's `__del__`
        b. Exit `pin_memory_thread`
             i.   Set `pin_memory_thread_done_event`.
             ii   Put `None` in `worker_result_queue`.
             iii. Join the `pin_memory_thread`.
             iv.  `worker_result_queue.cancel_join_thread()`.
    
        c. Exit the workers.
             i.   Set `workers_done_event`.
             ii.  Put `None` in each worker's `index_queue`.
             iii. Join the workers.
             iv.  Call `.cancel_join_thread()` on each worker's `index_queue`.
    
           NOTE: (c) is better placed after (b) because it may leave corrupted
                 data in `worker_result_queue`, which `pin_memory_thread`
                 reads from, in which case the `pin_memory_thread` can only
                 happen at timeing out, which is slow. Nonetheless, same thing
                 happens if a worker is killed by signal at unfortunate times,
                 but in other cases, we are better off having a non-corrupted
                 `worker_result_queue` for `pin_memory_thread`.
    
      NOTE: If `pin_memory=False`, there is no `pin_memory_thread` and (b)
            can be omitted
    
    NB: `done_event`s isn't strictly needed. E.g., we can just check for
        `None` from `index_queue`, but it allows us to skip wasting resources
        processing indices already in `index_queue` if we are already shutting
        down.",392,393,72,1
C:\Users\vaano\python_projects\pytorch\torch\utils\data\dataset.py,Dataset,"
An abstract class representing a :class:`Dataset`.

All datasets that represent a map from keys to data samples should subclass
it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a
data sample for a given key. Subclasses could also optionally overwrite
:meth:`__len__`, which is expected to return the size of the dataset by many
:class:`~torch.utils.data.Sampler` implementations and the default options
of :class:`~torch.utils.data.DataLoader`.

.. note::
  :class:`~torch.utils.data.DataLoader` by default constructs a index
  sampler that yields integral indices.  To make it work with a map-style
  dataset with non-integral indices/keys, a custom sampler must be provided.
",9,22,704,13
C:\Users\vaano\python_projects\pytorch\torch\utils\data\dataset.py,IterableDataset,"
An iterable Dataset.

All datasets that represent an iterable of data samples should subclass it.
Such form of datasets is particularly useful when data come from a stream.

All subclasses should overwrite :meth:`__iter__`, which would return an
iterator of samples in this dataset.

When a subclass is used with :class:`~torch.utils.data.DataLoader`, each
item in the dataset will be yielded from the :class:`~torch.utils.data.DataLoader`
iterator. When :attr:`num_workers > 0`, each worker process will have a
different copy of the dataset object, so it is often desired to configure
each copy independently to avoid having duplicate data returned from the
workers. :func:`~torch.utils.data.get_worker_info`, when called in a worker
process, returns information about the worker. It can be used in either the
dataset's :meth:`__iter__` method or the :class:`~torch.utils.data.DataLoader` 's
:attr:`worker_init_fn` option to modify each copy's behavior.

Example 1: splitting workload across all workers in :meth:`__iter__`::

    >>> class MyIterableDataset(torch.utils.data.IterableDataset):
    ...     def __init__(self, start, end):
    ...         super(MyIterableDataset).__init__()
    ...         assert end > start, ""this example code only works with end >= start""
    ...         self.start = start
    ...         self.end = end
    ...
    ...     def __iter__(self):
    ...         worker_info = torch.utils.data.get_worker_info()
    ...         if worker_info is None:  # single-process data loading, return the full iterator
    ...             iter_start = self.start
    ...             iter_end = self.end
    ...         else:  # in a worker process
    ...             # split workload
    ...             per_worker = int(math.ceil((self.end - self.start) / float(worker_info.num_workers)))
    ...             worker_id = worker_info.id
    ...             iter_start = self.start + worker_id * per_worker
    ...             iter_end = min(iter_start + per_worker, self.end)
    ...         return iter(range(iter_start, iter_end))
    ...
    >>> # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].
    >>> ds = MyIterableDataset(start=3, end=7)

    >>> # Single-process loading
    >>> print(list(torch.utils.data.DataLoader(ds, num_workers=0)))
    [3, 4, 5, 6]

    >>> # Mult-process loading with two worker processes
    >>> # Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].
    >>> print(list(torch.utils.data.DataLoader(ds, num_workers=2)))
    [3, 5, 4, 6]

    >>> # With even more workers
    >>> print(list(torch.utils.data.DataLoader(ds, num_workers=20)))
    [3, 4, 5, 6]

Example 2: splitting workload across all workers using :attr:`worker_init_fn`::

    >>> class MyIterableDataset(torch.utils.data.IterableDataset):
    ...     def __init__(self, start, end):
    ...         super(MyIterableDataset).__init__()
    ...         assert end > start, ""this example code only works with end >= start""
    ...         self.start = start
    ...         self.end = end
    ...
    ...     def __iter__(self):
    ...         return iter(range(self.start, self.end))
    ...
    >>> # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].
    >>> ds = MyIterableDataset(start=3, end=7)

    >>> # Single-process loading
    >>> print(list(torch.utils.data.DataLoader(ds, num_workers=0)))
    [3, 4, 5, 6]
    >>>
    >>> # Directly doing multi-process loading yields duplicate data
    >>> print(list(torch.utils.data.DataLoader(ds, num_workers=2)))
    [3, 3, 4, 4, 5, 5, 6, 6]

    >>> # Define a `worker_init_fn` that configures each dataset copy differently
    >>> def worker_init_fn(worker_id):
    ...     worker_info = torch.utils.data.get_worker_info()
    ...     dataset = worker_info.dataset  # the dataset copy in this worker process
    ...     overall_start = dataset.start
    ...     overall_end = dataset.end
    ...     # configure the dataset to only process the split workload
    ...     per_worker = int(math.ceil((overall_end - overall_start) / float(worker_info.num_workers)))
    ...     worker_id = worker_info.id
    ...     dataset.start = overall_start + worker_id * per_worker
    ...     dataset.end = min(dataset.start + per_worker, overall_end)
    ...

    >>> # Mult-process loading with the custom `worker_init_fn`
    >>> # Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].
    >>> print(list(torch.utils.data.DataLoader(ds, num_workers=2, worker_init_fn=worker_init_fn)))
    [3, 5, 4, 6]

    >>> # With even more workers
    >>> print(list(torch.utils.data.DataLoader(ds, num_workers=20, worker_init_fn=worker_init_fn)))
    [3, 4, 5, 6]
",36,136,4648,100
C:\Users\vaano\python_projects\pytorch\torch\utils\data\dataset.py,TensorDataset,"
Dataset wrapping tensors.

Each sample will be retrieved by indexing tensors along the first dimension.

Arguments:
    *tensors (Tensor): tensors that have the same size of the first dimension.
",149,155,194,6
C:\Users\vaano\python_projects\pytorch\torch\utils\data\dataset.py,ConcatDataset,"
Dataset as a concatenation of multiple datasets.

This class is useful to assemble different existing datasets.

Arguments:
    datasets (sequence): List of datasets to be concatenated
",169,175,184,6
C:\Users\vaano\python_projects\pytorch\torch\utils\data\dataset.py,ChainDataset,"
Dataset for chainning multiple :class:`IterableDataset` s.

This class is useful to assemble different existing dataset streams. The
chainning operation is done on-the-fly, so concatenating large-scale
datasets with this class will be efficient.

Arguments:
    datasets (iterable of IterableDataset): datasets to be chained together
",217,225,333,8
C:\Users\vaano\python_projects\pytorch\torch\utils\data\dataset.py,Subset,"
Subset of a dataset at specified indices.

Arguments:
    dataset (Dataset): The whole Dataset
    indices (sequence): Indices in the whole set selected for subset
",245,250,163,5
C:\Users\vaano\python_projects\pytorch\torch\utils\data\distributed.py,DistributedSampler,"
Sampler that restricts data loading to a subset of the dataset.

It is especially useful in conjunction with
:class:`torch.nn.parallel.DistributedDataParallel`. In such case, each
process can pass a DistributedSampler instance as a DataLoader sampler,
and load a subset of the original dataset that is exclusive to it.

.. note::
    Dataset is assumed to be of constant size.

Arguments:
    dataset: Dataset used for sampling.
    num_replicas (optional): Number of processes participating in
        distributed training.
    rank (optional): Rank of the current process within num_replicas.
    shuffle (optional): If true (default), sampler will shuffle the indices
",8,24,670,16
C:\Users\vaano\python_projects\pytorch\torch\utils\data\sampler.py,Sampler,"
Base class for all Samplers.

Every Sampler subclass has to provide an :meth:`__iter__` method, providing a
way to iterate over indices of dataset elements, and a :meth:`__len__` method
that returns the length of the returned iterators.

.. note:: The :meth:`__len__` method isn't strictly required by
          :class:`~torch.utils.data.DataLoader`, but is expected in any
          calculation involving the length of a :class:`~torch.utils.data.DataLoader`.
",6,15,460,9
C:\Users\vaano\python_projects\pytorch\torch\utils\data\sampler.py,SequentialSampler,"
Samples elements sequentially, always in the same order.

Arguments:
    data_source (Dataset): dataset to sample from
",52,56,118,4
C:\Users\vaano\python_projects\pytorch\torch\utils\data\sampler.py,RandomSampler,"
Samples elements randomly. If without replacement, then sample from a shuffled dataset.
If with replacement, then user can specify :attr:`num_samples` to draw.

Arguments:
    data_source (Dataset): dataset to sample from
    replacement (bool): samples are drawn with replacement if ``True``, default=``False``
    num_samples (int): number of samples to draw, default=`len(dataset)`. This argument
        is supposed to be specified only when `replacement` is ``True``.
",69,77,472,8
C:\Users\vaano\python_projects\pytorch\torch\utils\data\sampler.py,SubsetRandomSampler,"
Samples elements randomly from a given list of indices, without replacement.

Arguments:
    indices (sequence): a sequence of indices
",114,118,134,4
C:\Users\vaano\python_projects\pytorch\torch\utils\data\sampler.py,WeightedRandomSampler,"
Samples elements from ``[0,..,len(weights)-1]`` with given probabilities (weights).

Args:
    weights (sequence)   : a sequence of weights, not necessary summing up to one
    num_samples (int): number of samples to draw
    replacement (bool): if ``True``, samples are drawn with replacement.
        If not, they are drawn without replacement, which means that when a
        sample index is drawn for a row, it cannot be drawn again for that row.

Example:
    >>> list(WeightedRandomSampler([0.1, 0.9, 0.4, 0.7, 3.0, 0.6], 5, replacement=True))
    [0, 0, 0, 1, 0]
    >>> list(WeightedRandomSampler([0.9, 0.4, 0.05, 0.2, 0.3, 0.1], 5, replacement=False))
    [0, 1, 4, 3, 2]
",131,145,680,14
C:\Users\vaano\python_projects\pytorch\torch\utils\data\sampler.py,BatchSampler,"
Wraps another sampler to yield a mini-batch of indices.

Args:
    sampler (Sampler): Base sampler.
    batch_size (int): Size of mini-batch.
    drop_last (bool): If ``True``, the sampler will drop the last batch if
        its size would be less than ``batch_size``

Example:
    >>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))
    [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]
    >>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True))
    [[0, 1, 2], [3, 4, 5], [6, 7, 8]]
",167,180,533,13
C:\Users\vaano\python_projects\pytorch\torch\utils\data\_utils\fetch.py,_BaseDatasetFetcher,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\data\_utils\fetch.py,_IterableDatasetFetcher,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\data\_utils\fetch.py,_MapDatasetFetcher,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\data\_utils\worker.py,WorkerInfo,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\data\_utils\worker.py,ManagerWatchdog,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\data\_utils\worker.py,ManagerWatchdog,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\hipify\hipify_python.py,InputError,"Exception raised for errors in the input.
 ",47,47,1,1
C:\Users\vaano\python_projects\pytorch\torch\utils\hipify\hipify_python.py,bcolors,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\hipify\hipify_python.py,Trie,"
Regex::Trie in Python. Creates a Trie out of a list of words. The trie can be exported to a Regex pattern.
The corresponding Regex should match much faster than a simple Regex union.
",526,528,182,2
C:\Users\vaano\python_projects\pytorch\torch\utils\tensorboard\writer.py,FileWriter,"
Writes protocol buffers to event files to be consumed by TensorBoard.

The `FileWriter` class provides a mechanism to create an event file in a
given directory and add summaries and events to it. The class updates the
file contents asynchronously. This allows a training program to call methods
to add data to the file directly from the training loop, without slowing down
training.
",34,41,382,7
C:\Users\vaano\python_projects\pytorch\torch\utils\tensorboard\writer.py,SummaryWriter,"
Writes entries directly to event files in the log_dir to be
consumed by TensorBoard.

The `SummaryWriter` class provides a high-level API to create an event file
in a given directory and add summaries and events to it. The class updates the
file contents asynchronously. This allows a training program to call methods
to add data to the file directly from the training loop, without slowing down
training.
",155,163,405,8
C:\Users\vaano\python_projects\pytorch\torch\utils\tensorboard\_pytorch_graph.py,NodeBase,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\tensorboard\_pytorch_graph.py,NodePy,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\tensorboard\_pytorch_graph.py,NodePyIO,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\tensorboard\_pytorch_graph.py,NodePyOP,,,,,
C:\Users\vaano\python_projects\pytorch\torch\utils\tensorboard\_pytorch_graph.py,GraphPy,"
Helper class to convert torch.nn.Module to GraphDef proto and visualization
with TensorBoard.

GraphDef generation operates in two passes:

In the first pass, all nodes are read and saved to two lists.
One list is for input/output nodes (nodes_io), which only have inbound
or outbound connections, but not both. Another list is for internal
operator nodes (nodes_op). The first pass also saves all scope name
appeared in the nodes in scope_name_appeared list for later processing.

In the second pass, scope names are fully applied to all nodes.
debugNameToScopedName is a mapping from a node's ID to its fully qualified
scope name. e.g. Net1/Linear[0]/1. Unfortunately torch.jit doesn't have
totally correct scope output, so this is nontrivial. The function
populate_namespace_from_OP_to_IO and find_common_root are used to
assign scope name to a node based on the connection between nodes
in a heuristic kind of way. Bookkeeping is done with shallowest_scope_name
and scope_name_appeared.
",97,116,990,19
